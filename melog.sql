/*
 Navicat Premium Data Transfer

 Source Server         : melog
 Source Server Type    : MySQL
 Source Server Version : 50637
 Source Host           : 39.104.127.25:3306
 Source Schema         : melog

 Target Server Type    : MySQL
 Target Server Version : 50637
 File Encoding         : 65001

 Date: 18/02/2020 21:07:43
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for melog_article
-- ----------------------------
DROP TABLE IF EXISTS `melog_article`;
CREATE TABLE `melog_article`  (
  `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '文档ID',
  `cate_id` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '栏目ID',
  `user_id` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '用户ID',
  `title` varchar(150) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '标题',
  `writer` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '作者',
  `source` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '来源',
  `source_url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '来源链接',
  `click` int(255) UNSIGNED NOT NULL DEFAULT 0 COMMENT '点击',
  `keywords` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '关键词',
  `description` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '简介',
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '内容',
  `add_time` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '添加时间',
  `update_time` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '更新时间',
  `comment_total` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '评论总数',
  `is_comment` tinyint(1) NOT NULL DEFAULT 0 COMMENT '是否允许评论',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `click`(`click`) USING BTREE,
  INDEX `cate_id`(`cate_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 27 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of melog_article
-- ----------------------------
INSERT INTO `melog_article` VALUES (1, 1, 0, '记一次项目经历，纯 CSS 实现大量小块儿绘制', '雨思', 'me', '', 13, '测试,文章', '离上次写文章已经挺久了，期间因为跟着项目一起换了组，一直非常忙。现在做的项目是公司内部全部组要用的 viewer 库. Viewer 需要的功能非常的多，其中的一个就是需要提供一些常用的绘图API功能， 比如用户鼠标移动画箭头，画圈圈，高光选中文本等等。', '离上次写文章已经挺久了，期间因为跟着项目一起换了组，一直非常忙。现在做的项目是公司内部全部组要用的 viewer 库.  Viewer 需要的功能非常的多，其中的一个就是需要提供一些常用的绘图API功能， 比如用户鼠标移动画箭头，画圈圈，高光选中文本等等。\r\n\r\n## 挑战\r\n\r\n目前遇到的挑战就是在 canvas, svg, dom + css 之间如何选择的问题，canvas 绘图的方案已经有了成品，我们可以直接拿过来添加到现有的 Viewer 上面。但是基于以下考虑，主要用哪种技术迟迟不能下定论。\r\n\r\n### Canvas 纠结点：\r\n\r\n1） 各部门合作问题，如果采用 canvas, 其他部门需要添加自定义图形操作的时候就需要他们了解 Canvas 开发 重绘到 Viewer 已有的 Canvas 上面。 \r\n2） Canvas 会失去很多 Element 原生的属性，比如文字选中，aria标签, 事件等。\r\n3） Viewer 的文件可能会非常的大，并且可能会有成千上万个页面，每个页面管理自己的绘图。如果每个页面一个Canvas, 性能会非常差(采用了 View Virtualization 思想，只渲染视图需要的元素，这里是做了个极限假设)。如果所有的图形都绘制在一个Canvas上面，需要根据视图区域的页面属性重绘图形计算，开发成本会增加非常多。  \r\n4）Canvas 只能用于最底层，否则会覆盖其他元素（Viewer上面的层非常多，需要绘图层能管理事件，同时不丢失其他层的事件）。\r\n\r\n于是老大就给几天时间，让我们尽情地先试着用其他的方式画一下各种图形，比较一下优劣（最后，我们应该会几样技术结合起来用）。其中一个案例就是高光选中文本，后端传会传一堆需要高光块儿大小位置，前端画出高光部分。 像这种非常多小面积的绘图，Canvas是最合适不过的了，不过这几天时间就是看看有没有还有什么其他的方案。大概就长这样，高光是无数个小块儿。\r\n<span class=\"img-wrap\">![hightlight.jpg](/img/bVbA7v1 \"hightlight.jpg\")</span>\r\n\r\n### 寻找方案\r\n\r\nCanvas 画高光的方案已经有了，我们首先想到的就是每一个块儿给个 span 渲染，但因为需要高光的块儿可能会非常多，并且可能会是动态的。哪么这就涉及到 DOM 的频繁操作，性能非常不好。后来采用createDocumentFragment，添加到DOM，性能明显提升。\r\n\r\n我当时有个非常大胆的想法，要是只用一个span,然后所有的块儿都添加成背景可不可以实现（考虑到现在的css3已经有了多背景重叠技术）。找路子的时候千万次觉得不可能，结果实现之后再返回去看，其实原理非常的简单。全部采用css， 用linear-gradient画块儿（采用linear-gradient， 是因为它可以背景重叠，如果有更好的方法欢迎指教），background-position, background-size分别给每个块儿定位，结束！性能当然是惊人的好，因为根本没有涉及到元素的增加删除，只是css重绘（Viewer 有大量消耗性能的scroll监听，操作等情况下都能无缝操作，Canvas 有非常微小地快闪）。这一试，仿佛大概了新世界，很多大量，简单的图形绘制完全可以尝试纯css实现，上代码。\r\n\r\nAngular template\r\n\r\n    &lt;span class=\"layer-content\" [style.background]=\"_background\" [style.backgroundSize]=\"_backgroundSize\" [style.backgroundPosition]=\"_backgroundPosition\"&gt;&lt;/span&gt;`</pre>\r\n\r\n    Angular ts file\r\n\r\n    <pre>`    this._subscription = this.highlights$.subscribe((highlights) =&gt; {\r\n          let background = ``;\r\n          let backgroundSize = ``;\r\n          let backgroundPosition = ``;\r\n          for (let i = 0; i &lt; highlights.length; i++) {\r\n            const { x, y, width, height } = highlights[i];\r\n            // add connection comma when i is not the last one.\r\n            const comma = (i &lt; highlights.length - 1) ? \', \' : \'\';\r\n            // 0px transparent to fill gradient syntax.\r\n            background += `linear-gradient(CurrentColor 100%, transparent 0px)${comma}`;\r\n            backgroundSize += `${width}px ${height}px${comma}`;\r\n            backgroundPosition += `${x}px ${y}px${comma}`;\r\n          }\r\n          this._background = this.sanitizer.bypassSecurityTrustStyle(background);\r\n          this._backgroundSize = backgroundSize;\r\n          this._backgroundPosition = backgroundPosition;\r\n        });`</pre>\r\n\r\n    Css\r\n\r\n    <pre>`span.layer-content {\r\n      z-index: 0;\r\n      display: inline-block;\r\n      width: 100%;\r\n      height: 100%;\r\n      background-repeat: no-repeat !important;\r\n    }\r\n\r\n期间看了些 Canvas, Svg 比较的文章，其中一篇觉得比较有意思的分享给大家。 \r\n\r\n[https://www.yworks.com/blog/s...](https://www.yworks.com/blog/svg-canvas-webgl)\r\n\r\n如果大家有其他好的方案，欢迎指教\r\n\r\n--- 完----', 1, 0, 0, 0);
INSERT INTO `melog_article` VALUES (2, 1, 0, 'Spring Boot2 系列教程(二十八)Spring Boot 整', '雨思', 'i', '', 103, '系统', '这篇文章是松哥的原创，但是在第一次发布的时候，忘了标记原创，结果被好多号转发，导致我后来整理的时候自己没法标记原创了。写了几百篇原创技术干货了，有一两篇忘记标记原创进而造成的一点点小小损失也能接受，不过还是要和小伙伴们说明一下。', '> 这篇文章是松哥的原创，但是在第一次发布的时候，忘了标记原创，结果被好多号转发，导致我后来整理的时候自己没法标记原创了。写了几百篇原创技术干货了，有一两篇忘记标记原创进而造成的一点点小小损失也能接受，不过还是要和小伙伴们说明一下。\r\n\r\n在传统的单服务架构中，一般来说，只有一个服务器，那么不存在 Session 共享问题，但是在分布式/集群项目中，Session 共享则是一个必须面对的问题，先看一个简单的架构图：\r\n\r\n<span class=\"img-wrap\">![](/img/remote/1460000021200962)</span>\r\n\r\n在这样的架构中，会出现一些单服务中不存在的问题，例如客户端发起一个请求，这个请求到达 Nginx 上之后，被 Nginx 转发到 Tomcat A 上，然后在 Tomcat A 上往 session 中保存了一份数据，下次又来一个请求，这个请求被转发到 Tomcat B  上，此时再去 Session 中获取数据，发现没有之前的数据。对于这一类问题的解决，思路很简单，就是将各个服务之间需要共享的数据，保存到一个公共的地方（主流方案就是 Redis）：\r\n\r\n<span class=\"img-wrap\">![](/img/remote/1460000021200961)</span>\r\n\r\n当所有 Tomcat 需要往 Session 中写数据时，都往 Redis 中写，当所有 Tomcat 需要读数据时，都从 Redis 中读。这样，不同的服务就可以使用相同的 Session 数据了。\r\n\r\n这样的方案，可以由开发者手动实现，即手动往 Redis 中存储数据，手动从 Redis 中读取数据，相当于使用一些 Redis 客户端工具来实现这样的功能，毫无疑问，手动实现工作量还是蛮大的。\r\n\r\n一个简化的方案就是使用 Spring Session 来实现这一功能，Spring Session 就是使用 Spring 中的代理过滤器，将所有的 Session 操作拦截下来，自动的将数据 同步到 Redis 中，或者自动的从 Redis 中读取数据。\r\n\r\n对于开发者来说，所有关于 Session 同步的操作都是透明的，开发者使用 Spring Session，一旦配置完成后，具体的用法就像使用一个普通的 Session 一样。\r\n\r\n# 1 实战\r\n\r\n## 1.1 创建工程\r\n\r\n首先 创建一个 Spring Boot 工程，引入 Web、Spring Session 以及 Redis:\r\n\r\n<span class=\"img-wrap\">![](/img/remote/1460000021200963)</span>\r\n\r\n创建成功之后，pom.xml 文件如下：\r\n\r\n    &lt;dependencies&gt;\r\n        &lt;dependency&gt;\r\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\r\n            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;\r\n        &lt;/dependency&gt;\r\n        &lt;dependency&gt;\r\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\r\n            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\r\n        &lt;/dependency&gt;\r\n        &lt;dependency&gt;\r\n            &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;\r\n            &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;\r\n        &lt;/dependency&gt;\r\n    &lt;/dependencies&gt;`</pre>\r\n\r\n    **注意：**\r\n\r\n    这里我使用的 Spring Boot 版本是 2.1.4 ，如果使用当前最新版 Spring Boot2.1.5 的话，除了上面这些依赖之外，需要额外添加 Spring Security 依赖（其他操作不受影响，仅仅只是多了一个依赖，当然也多了 Spring Security 的一些默认认证流程）。\r\n\r\n    ## 1.2 配置 Redis\r\n\r\n    <pre>`spring.redis.host=192.168.66.128\r\n    spring.redis.port=6379\r\n    spring.redis.password=123\r\n    spring.redis.database=0`</pre>\r\n\r\n    这里的 Redis ，我虽然配置了四行，但是考虑到端口默认就是 6379 ，database 默认就是 0，所以真正要配置的，其实就是两行。\r\n\r\n    ## 1.3 使用\r\n\r\n    配置完成后 ，就可以使用 Spring Session 了，其实就是使用普通的 HttpSession ，其他的 Session 同步到 Redis 等操作，框架已经自动帮你完成了：\r\n\r\n    <pre>`@RestController\r\n    public class HelloController {\r\n        @Value(\"${server.port}\")\r\n        Integer port;\r\n        @GetMapping(\"/set\")\r\n        public String set(HttpSession session) {\r\n            session.setAttribute(\"user\", \"javaboy\");\r\n            return String.valueOf(port);\r\n        }\r\n        @GetMapping(\"/get\")\r\n        public String get(HttpSession session) {\r\n            return session.getAttribute(\"user\") + \":\" + port;\r\n        }\r\n    }`</pre>\r\n\r\n    考虑到一会 Spring Boot 将以集群的方式启动 ，为了获取每一个请求到底是哪一个 Spring  Boot 提供的服务，需要在每次请求时返回当前服务的端口号，因此这里我注入了 server.port 。\r\n\r\n    接下来 ，项目打包：\r\n\r\n    <span class=\"img-wrap\">![](/img/remote/1460000021200964)</span>\r\n\r\n    打包之后，启动项目的两个实例：\r\n\r\n    <pre>`java -jar sessionshare-0.0.1-SNAPSHOT.jar --server.port=8080\r\n    java -jar sessionshare-0.0.1-SNAPSHOT.jar --server.port=8081`</pre>\r\n\r\n    然后先访问 `localhost:8080/set` 向 `8080` 这个服务的 `Session` 中保存一个变量，访问完成后，数据就已经自动同步到 `Redis`  中 了 ：\r\n\r\n    <span class=\"img-wrap\">![](/img/remote/1460000021200966)</span>\r\n\r\n    然后，再调用 `localhost:8081/get` 接口，就可以获取到 `8080` 服务的 `session` 中的数据：\r\n\r\n    <span class=\"img-wrap\">![](/img/remote/1460000021200965)</span>\r\n\r\n    此时关于 session 共享的配置就已经全部完成了，session 共享的效果我们已经看到了，但是每次访问都是我自己手动切换服务实例，因此，接下来我们来引入 Nginx ，实现服务实例自动切换。\r\n\r\n    ## 1.4 引入 Nginx\r\n\r\n    很简单，进入  Nginx 的安装目录的 conf 目录下（默认是在 `/usr/local/nginx/conf`），编辑 nginx.conf 文件:\r\n\r\n    <span class=\"img-wrap\">![](/img/remote/1460000021200967)</span>\r\n\r\n    在这段配置中：\r\n\r\n1.  upstream 表示配置上游服务器\r\n2.  javaboy.org 表示服务器集群的名字，这个可以随意取名字\r\n3.  upstream 里边配置的是一个个的单独服务\r\n4.  weight 表示服务的权重，意味者将有多少比例的请求从 Nginx 上转发到该服务上\r\n5.  location 中的 proxy_pass 表示请求转发的地址，`/` 表示拦截到所有的请求，转发转发到刚刚配置好的服务集群中\r\n6.  proxy_redirect 表示设置当发生重定向请求时，nginx 自动修正响应头数据（默认是 Tomcat 返回重定向，此时重定向的地址是 Tomcat 的地址，我们需要将之修改使之成为 Nginx 的地址）。\r\n\r\n    配置完成后，将本地的 Spring Boot 打包好的 jar 上传到 Linux ，然后在 Linux 上分别启动两个 Spring Boot 实例：\r\n\r\n    <pre>`nohup java -jar sessionshare-0.0.1-SNAPSHOT.jar --server.port=8080 &amp;\r\n    nohup java -jar sessionshare-0.0.1-SNAPSHOT.jar --server.port=8081 &amp;`</pre>\r\n\r\n    其中\r\n\r\n*   nohup 表示当终端关闭时，Spring Boot 不要停止运行\r\n*   &amp; 表示让 Spring Boot 在后台启动\r\n\r\n    配置完成后，重启 Nginx：\r\n\r\n    <pre>`/usr/local/nginx/sbin/nginx -s reload\r\n\r\nNginx 启动成功后，我们首先手动清除 Redis 上的数据，然后访问 `192.168.66.128/set` 表示向 `session` 中保存数据，这个请求首先会到达 `Nginx` 上，再由 `Nginx` 转发给某一个 `Spring Boot` 实例：\r\n\r\n<span class=\"img-wrap\">![](/img/remote/1460000021200968)</span>\r\n\r\n如上，表示端口为 `8081` 的 `Spring Boot` 处理了这个 `/set` 请求，再访问 `/get` 请求：\r\n\r\n<span class=\"img-wrap\">![](/img/remote/1460000021200969)</span>\r\n\r\n可以看到，`/get` 请求是被端口为 8080 的服务所处理的。\r\n\r\n# 2 总结\r\n\r\n本文主要向大家介绍了 Spring Session 的使用，另外也涉及到一些 Nginx 的使用 ，虽然本文较长，但是实际上 Spring Session 的配置没啥。\r\n\r\n我们写了一些代码，也做了一些配置，但是全都和 Spring Session 无关，配置是配置 Redis，代码就是普通的 HttpSession，和 Spring Session 没有任何关系！\r\n\r\n唯一和 Spring Session 相关的，可能就是我在一开始引入了 Spring Session 的依赖吧！\r\n\r\n如果大家没有在 SSM 架构中用过 Spring Session ，可能不太好理解我们在 Spring Boot 中使用 Spring Session 有多么方便，因为在 SSM 架构中，Spring Session 的使用要配置三个地方 ，一个是 web.xml 配置代理过滤器，然后在 Spring 容器中配置 Redis，最后再配置 Spring Session，步骤还是有些繁琐的，而 Spring Boot 中直接帮我们省去了这些繁琐的步骤！不用再去配置 Spring Session。\r\n\r\n好了 ，本文就说到这里，本文相关案例我已经上传到 GitHub ，大家可以自行下载:[https://github.com/lenve/javaboy-code-samples](https://github.com/lenve/javaboy-code-samples)\r\n\r\n### 扫码关注松哥，公众号后台回复 2TB，获取松哥独家 超2TB 免费 Java 学习干货\r\n\r\n<span class=\"img-wrap\">![](/img/remote/1460000020645461)</span>', 0, 0, 0, 0);
INSERT INTO `melog_article` VALUES (3, 1, 0, '现代前端库开发指南系列', '雨思', 'i', '', 333, '测试', '在前文中，我说过本系列文章的受众是在现代前端体系下能够熟练编写业务代码的同学，因此本文在介绍 webpack 配置时，仅提及构建一个库所特有的配置，其余配置请参考 webpack 官方文档。', '## 前言\r\n\r\n在前文中，我说过本系列文章的受众是在现代前端体系下能够熟练编写业务代码的同学，因此本文在介绍 webpack 配置时，仅提及构建一个库所特有的配置，其余配置请参考 webpack 官方文档。\r\n\r\n## 输出产物\r\n\r\n构建一个库与构建一个一般应用最大的不同点在于**构建完成后输出的产物**。\r\n\r\n一般应用构建完成后会输出：\r\n\r\n*   一个 html 文件\r\n*   一个 js 入口 chunk 、若干子 chunk\r\n*   若干 css 文件\r\n*   若干其它资源，如图片、字体文件等\r\n\r\n虽然输出的资源非常多，但实际上所有的依赖、加载关系都已经从 html 文件开始一层一层定下来了，换句话说，这个 html 文件实际上就是整个应用的入口。\r\n\r\n一个库构建完成后会输出：\r\n\r\n*   一个 CommonJS 格式的 js 文件\r\n*   一个未压缩的 UMD 格式的 js 文件\r\n*   一个已压缩的 UMD 格式的 js 文件\r\n*   可能包括若干的 css 文件\r\n*   可能包括若干的其它资源文件\r\n\r\n库的入口分别是上面罗列的 js 文件；你可能会奇怪，一个库怎么会有3个入口文件呢？莫急，且听我一一道来。\r\n\r\n### CommonJS\r\n\r\n**CommonJS** 是 Node.js 推行的一种模块化规范，主要语法包括`module.exports`、`require()`等；而我们在使用 webpack 引入 npm 包时，实际上是处于 Node.js 环境，由此可知，这个 CommonJS 格式的入口 js 文件（`&lt;库名称&gt;.common.js`）是供其它应用在 Node.js 环境下引入 npm 包使用的。由于在引用 npm 包时一般不会过多考虑 npm 包的体积（在构建自己的应用时如有需要可自行压缩），且为了方便调试，因此该 js 入口文件是没有经过压缩的。\r\n\r\n### UMD\r\n\r\n**UMD** 是一个模块化规范大杂烩，除了兼容 CommonJS 外，它还兼容 **AMD** 模块化规范，以及最传统的全局变量模式。\r\n\r\n这边稍微介绍一下 AMD 规范， AMD 全称 _Asyncchronous Module Definition_ ，一般应用在浏览器端（这是与 CommonJS规范最大的不同点），最著名的 AMD 加载器是 **RequireJS** 。目前由于 webpack 的流行， AMD 这一模块化方案已逐渐退出市场。\r\n\r\n**全局变量模式**就很好理解了，就是把库的入口挂载在一个全局变量（如`window.xxx`）上，页面上的任何位置都能随时取用，属于最传统的 js 插件加载方案。\r\n\r\n由上可知， UMD 格式的入口 js 文件，既可以用于引用 npm 包的场景（未压缩的版本，即`&lt;库名称&gt;.umd.js`），也可以直接用于浏览器端（已压缩的版本，即`&lt;库名称&gt;.umd.min.js`）。\r\n\r\n### 如何构建不同模块化规范的库文件\r\n\r\n目前， webpack 不支持同时生成多份入口 js 文件，因此需要分多次来进行构建。\r\n\r\n关键的 webpack 配置是：\r\n\r\n*   CommonJS：`output.libraryTarget: \"commonjs2\"`\r\n\r\n*   UMD：`output.libraryTarget: \"umd\"`\r\n\r\n对于 UMD ，我们还需要设置全局变量名称，即`output.library: \"LibraryName\"`。\r\n\r\n为了压缩构建出来的文件，最简单的方法是在 CLI 中调用 webpack 命令时带上 **mode** 参数，如`webpack --mode=production`；这是因为当 mode 的值为`production`时， webpack 会自动启用 **UglifyJsPlugin** 对源码进行压缩。\r\n\r\n## 输出版本信息\r\n\r\n我在某公司工作时，该公司对第三方依赖抓得很紧，所有在项目里使用的第三方依赖都必须申请且审核通过后才可使用；且申请时是精确到具体版本的，未申请的软件版本也一概不允许使用。某些第三方依赖无论在文件内容上，还是在文件名称上，都没有体现出版本号，这就对我们识别这类第三方依赖产生障碍，这是我们开发自己的库时需要引以为戒的。\r\n\r\n在构建库时，我们完全可以利用 webpack 把库的信息直接输出到文件内容里，有了这“身份信息”，用户使用起来也会格外安心。\r\n\r\n输出库版本信息的方法是使用 [webpack.BannerPlugin](https://www.webpackjs.com/plugins/banner-plugin/) ，最简单的使用方法如下：\r\n\r\n    const pgk = require(\'./package.json\');\r\n    const banner = `\r\n    ${pkg.name}\r\n    ${pkg.description}\\n\r\n    @version v${pkg.version}\r\n    @homepage ${pkg.homepage}\r\n    @repository ${pkg.repository.url}\\n\r\n    (c) 2019 Array-Huang\r\n    Released under the MIT License.\r\n    hash: [hash]\r\n    `;\r\n\r\n    /* webpack 配置 */\r\n    {\r\n        // ...其它配置\r\n        plugins: [\r\n            // ...其它 plugin 配置\r\n            new webpack.BannerPlugin(banner);\r\n        ]\r\n    }`</pre>\r\n\r\n    最终生成出来的效果是：\r\n\r\n    <pre>`/*!\r\n     * \r\n     * vue-directive-window\r\n     * Vue.js directive that enhance your Modal Window, support drag, resize and maximize.\r\n     * \r\n     * @version v0.7.5\r\n     * @homepage https://github.com/Array-Huang/vue-directive-window\r\n     * @repository git+https://github.com/Array-Huang/vue-directive-window.git\r\n     * \r\n     * (c) 2019 Array-Huang\r\n     * Released under the MIT License.\r\n     * hash: dc6c11a1e50821f4444a\r\n     * \r\n     */`</pre>\r\n\r\n    ## source map\r\n\r\n    如果库的用户是直接通过在浏览器里加载你的库来使用的话，那么提供一份 **source map** 文件是非常有必要的；这是因为你的库在经过 webpack 构建，甚至压缩后，与源代码已经大相径庭了，用户将难以在浏览器中进行调试；但如果你能为自己的库附上一份 source map ，浏览器开发者工具会调用 source map 来帮助解析，用户的调试体验会更接近于调试库的源码。\r\n\r\n    相应的 webpack 配置为：\r\n\r\n    <pre>`// webpack 配置\r\n    {\r\n        // ...其它配置\r\n        devtool: \'cheap-module-source-map\'\r\n    }`</pre>\r\n\r\n    webpack 支持多种类型的 source map ，不同类型的 source map 在生成速度、支持功能（如 babel ）、调试位置偏移等问题上均有不同表现，我这边只做推荐：\r\n\r\n*   开发环境：**cheap-module-eval-source-map**\r\n*   生产环境：**cheap-module-source-map**\r\n\r\n    关于其它类型的 source map ，请查看 webpack 官方文档的 [devtool](https://www.webpackjs.com/configuration/devtool/) 章节。\r\n\r\n    ## 排除第三方依赖\r\n\r\n    与一般应用不一样，在开发库的时候，我们应尽量避免引入第三方库（构建过程中使用的工具链除外），因为这些第三方库会让我们写的库的大小猛增；很可能会出现这样的情况：我们自己写的小功能只有几百行代码的逻辑，构建出来的库却有几百k，那这样的库意义就不大了。\r\n\r\n    但我们的确也很难避免使用第三方库，那该咋办呢？\r\n\r\n    <pre>`// webpack 配置\r\n    {\r\n        // ...其它配置\r\n        externals: {\r\n            lodash: {\r\n                commonjs: \'lodash\',\r\n                commonjs2: \'lodash\',\r\n                amd: \'lodash\',\r\n                root: \'_\'\r\n            }\r\n        }\r\n    }`</pre>\r\n\r\n    使用上述配置后，我们构建出来的库中就不会包含配置中指定的第三方库（例子中为`lodash`）了，下面来一一详解：\r\n\r\n*   `commonjs`和`commonjs2`项都是指明用户在 node.js 环境下使用当前库时，以 **CommonJS** 的方式来加载名为`lodash`的 npm 包。\r\n*   `amd`项表示在浏览器中加载运行本库时，本库会试图以 **AMD** 的方式来加载名为`lodash`的 AMD 模块。\r\n*   `root`项表示在浏览器中加载运行本库时，本库会试图取全局变量`window._`（通过`&lt;script&gt;`标签加载`lodash.js`时， lodash 会把自己注入到全局变量`window._`中）。\r\n\r\n    ### 与一般应用不一样的 externals 配置\r\n\r\n    在一般应用中，你或许会看到这样的 externals 配置：\r\n\r\n    <pre>`// webpack 配置\r\n    {\r\n        // ...其它配置\r\n        externals: {\r\n            lodash: \'_\'\r\n        }\r\n    }`</pre>\r\n\r\n    这样的 externals 配置方式意味着：无论在什么环境，都要取`_`这个全局变量；如果当前是在一般应用且确定已经使用`&lt;script&gt;`来加载指定的第三方库（比如 _jQuery_、 _Vue_ 等核心库，的确很常以这种方式来加载），当然大可直接这样用；但我们作为库的作者，应提供更宽松更灵活的使用方式。\r\n\r\n    ## 完整的 webpack 配置示例\r\n\r\n    由于构建不同模块化规范的库需要不同的 webpack 配置（其实也只是稍有不同）来进行多次构建，因此本文只针对**构建 UMD 格式且已压缩**这一场景来展示最简单的 webpack 配置示例；如果想知道如何更有效率地拼接 webpack 配置，请看 [micro-schema-validator](https://github.com/Array-Huang/micro-schema-validator) 项目的 [webpack 配置文件](https://github.com/Array-Huang/micro-schema-validator/blob/master/webpack.config.js)。\r\n\r\n    <pre>`// webpack.config.js\r\n    const webpack = require(\'webpack\');\r\n    const pkg = require(\'./package.json\'); // 把 package.json 作为信息源\r\n    const banner = `\r\n    ${pkg.name}\r\n    ${pkg.description}\\n\r\n    @version v${pkg.version}\r\n    @homepage ${pkg.homepage}\r\n    @repository ${pkg.repository.url}\\n\r\n    (c) 2019 Array-Huang\r\n    Released under the MIT License.\r\n    hash: [hash]\r\n    `;\r\n\r\n    module.exports = {\r\n      entry: `${__dirname}/index.js`,\r\n      devtool: \'cheap-module-source-map\',\r\n      output: {\r\n        path: `${__dirname}/dist`, // 定义输出的目录\r\n        filename: \'micro-schema-validator.min.js\', // 定义输出文件名\r\n        library: \'MicroSchemaValidator\', // 定义暴露到浏览器环境的全局变量名称\r\n        libraryTarget: \'umd\', // 指定遵循的模块化规范\r\n      },\r\n      /* 排除第三方依赖 */\r\n      externals: {\r\n        lodash: {\r\n            commonjs: \'lodash\',\r\n          commonjs2: \'lodash\',\r\n          amd: \'lodash\',\r\n          root: \'_\'\r\n        }\r\n      },\r\n      module: {\r\n        rules: [\r\n          {\r\n            test: /(\\.jsx|\\.js)$/,\r\n            loader: \'babel-loader\',\r\n            exclude: /(node_modules|bower_components)/\r\n          },\r\n          {\r\n            test: /(\\.jsx|\\.js)$/,\r\n            loader: \'eslint-loader\',\r\n            exclude: /(node_modules|bower_components)/\r\n          }\r\n        ]\r\n      },\r\n      plugins: [\r\n          new webpack.BannerPlugin(banner) // 输出项目信息\r\n      ]\r\n    };`</pre>\r\n\r\n    ## 利用 vue-cli 定制并管理 webpack 配置\r\n\r\n    对于 Vue 生态的库，如 Vue 组件、Vue 自定义指令等，可以使用 vue-cli （本文特指 vue-cli 3.0 后的版本）根据你的需求来定制 webpack 配置，可定制内容包括：\r\n\r\n*   是否启用 Babel\r\n*   是否接入 TypeScript 语法\r\n*   是否支持 PWA\r\n*   是否使用 Vue-Router 和 Vuex\r\n*   是否使用 CSS 预处理器，并可选择具体的 CSS 预处理器，包括 Sass / Less / Stylus\r\n*   是否使用 ESLint 和 Prettier\r\n*   是否接入单元测试和端对端测试(E2E)\r\n\r\n    定制完成后， vue-cli 将生成一个种子项目，该项目可执行（包括本地开发和构建生产环境的包）但没有实际内容（实际内容不还得由你来写嘛哈哈）。与一般的脚手架工具相比， vue-cli 除了可以生成 webpack 配置外，还将持续对其进行管理和维护，如：\r\n\r\n*   提供一个统一的自定义配置的入口；过往，我们为了达到自定义配置的目的，往往会直接在脚手架工具生成出来的 webpack 配置上直接进行修改，这样会导致修改点非常分散，难以让自定义的 webpack 配置在其它项目复用；而使用 vue-cli 后，所有对 webpack 配置的修改点都被集中管理起来了，需要复用的话，直接把这自定义配置文件(vue.config.js)迁移到别的项目即可。\r\n*   提供持续更新 webpack 配置的机制；假如现在有一个开源库，我为了达到自己的目的，肆意在库源码上修改，那么当我需要升级该开源库的时候可就犯难了，因为这会把我之前做的修改都覆盖掉；同理可得，vue-cli 由于统一了自定义配置的入口，并且是在每次运行项目（运行项目也是通过执行 vue-cli 的命令而非 webpack）时动态渲染 webpack 配置的，因此项目的 webpack 配置可以随着 vue-cli 的升级而不断升级了。\r\n*   提供持续更新 webpack 工具链的机制；众所周知， webpack 工具链中包含了大量的第三方开源库，如 Babel 、ESLint 等，这些开源库也都是在不断更新当中，在这个过程中，必然会不断产生 Breaking Change ，所幸 vue-cli 通过自身升级——不断修改 webpack 配置来达到适配最新版第三方开源库的目的，而我们的项目也可以以极小的代价（升级 vue-cli 本身）来获取 webpack 工具链的不断更新。\r\n\r\n    ### vue-cli 自定义配置示例\r\n\r\n    摘自 [vue-directive-window](https://github.com/Array-Huang/vue-directive-window) 项目的 [vue.config.js](https://github.com/Array-Huang/vue-directive-window/blob/master/vue.config.js) 文件：\r\n\r\n    <pre>`const webpack = require(\'webpack\');\r\n    const pkg = require(\'./package.json\');\r\n\r\n    const banner = `\r\n    ${pkg.name}\r\n    ${pkg.description}\\n\r\n    @version v${pkg.version}\r\n    @homepage ${pkg.homepage}\r\n    @repository ${pkg.repository.url}\\n\r\n    (c) 2019 Array-Huang\r\n    Released under the MIT License.\r\n    hash: [hash]\r\n    `;\r\n\r\n    module.exports = {\r\n      chainWebpack: config =&gt; {\r\n        config.output.libraryExport(\'default\');\r\n        config.plugin(\'banner\').use(webpack.BannerPlugin, [\r\n          {\r\n            banner,\r\n            entryOnly: true,\r\n          },\r\n        ]);\r\n      },\r\n    };\r\n\r\n看起来是不是比上文中最基础的 webpack 配置还要简洁呢？当项目的架构逐渐丰富起来后，这个差距将不断拉大。\r\n\r\n## 系列文章目录（同步更新）\r\n\r\n<ul>\r\n<li>[《现代前端库开发指南系列（一）：融入现代前端生态》](https://segmentfault.com/a/1190000021176832)</li>\r\n<li>[《现代前端库开发指南系列（二）：使用 webpack 构建一个库》](https://segmentfault.com/a/1190000021199880)</li>', 1, 0, 0, 0);
INSERT INTO `melog_article` VALUES (4, 1, 0, '图解一致性哈希算法', '雨思', 'me', '', 13, '技术', '要了解一致性哈希，首先我们必须了解传统的哈希及其在大规模分布式系统中的局限性。简单地说，哈希就是一个键值对存储，在给定键的情况下，可以非常高效地找到所关联的值。假设我们要根据其邮政编码查找城市中的街道名称。一种最简单的实现方式是将此信息以哈希字典的形式进行存储 &amp;lt;Zip Code，Street Name&amp;gt;。', '要了解一致性哈希，首先我们必须了解传统的哈希及其在大规模分布式系统中的局限性。简单地说，哈希就是一个键值对存储，在给定键的情况下，可以非常高效地找到所关联的值。假设我们要根据其邮政编码查找城市中的街道名称。一种最简单的实现方式是将此信息以哈希字典的形式进行存储 `&lt;Zip Code，Street Name&gt;`。\r\n\r\n当数据太大而无法存储在一个节点或机器上时，问题变得更加有趣，系统中需要多个这样的节点或机器来存储它。比如，使用多个 Web 缓存中间件的系统。**那如何确定哪个 key 存储在哪个节点上？针对该问题，最简单的解决方案是使用哈希取模来确定。** 给定一个 key，先对 key 进行哈希运算，将其除以系统中的节点数，然后将该 key 放入该节点。同样，在获取 key 时，对 key 进行哈希运算，再除以节点数，然后转到该节点并获取值。上述过程对应的哈希算法定义如下：\r\n\r\n    node_number = hash(key) % N # 其中 N 为节点数。`</pre>\r\n\r\n    下图描绘了多节点系统中的传统的哈希取模算法，基于该算法可以实现简单的负载均衡。\r\n\r\n    <span class=\"img-wrap\">![traditional-hashing.png](/img/bVbA7as \"traditional-hashing.png\")</span>\r\n\r\n    > **阅读更多关于 Angular、TypeScript、Node.js/Java 、Spring 等技术文章，欢迎访问我的个人博客 ——[全栈修仙之路](http://www.semlinker.com/)**\r\n\r\n    ### 一、传统哈希取模算法的局限性\r\n\r\n    下面我们来分析一下传统的哈希及其在大规模分布式系统中的局限性。这里我们直接使用我之前所写文章 [布隆过滤器你值得拥有的开发利器](https://segmentfault.com/a/1190000021136424) 中定义的 SimpleHash 类，然后分别对 **semlinker、kakuqo 和 test ** 3 个键进行哈希运算并取余，具体代码如下：\r\n\r\n    <pre>`public class SimpleHash {\r\n        private int cap;\r\n        private int seed;\r\n\r\n        public SimpleHash(int cap, int seed) {\r\n            this.cap = cap;\r\n            this.seed = seed;\r\n        }\r\n\r\n        public int hash(String value) {\r\n            int result = 0;\r\n            int len = value.length();\r\n            for (int i = 0; i &lt; len; i++) {\r\n                result = seed * result + value.charAt(i);\r\n            }\r\n            return (cap - 1) &amp; result;\r\n        }\r\n\r\n        public static void main(String[] args) {\r\n            SimpleHash simpleHash = new SimpleHash(2 &lt;&lt; 12, 8);\r\n            System.out.println(\"node_number=hash(\\\"semlinker\\\") % 3 -&gt; \" + \r\n              simpleHash.hash(\"semlinker\") % 3);\r\n            System.out.println(\"node_number=hash(\\\"kakuqo\\\") % 3 -&gt; \" + \r\n              simpleHash.hash(\"kakuqo\") % 3);\r\n            System.out.println(\"node_number=hash(\\\"test\\\") % 3 -&gt; \" + \r\n              simpleHash.hash(\"test\") % 3);\r\n        }\r\n    }`</pre>\r\n\r\n    以上代码成功运行后，在控制台会输出以下结果：\r\n\r\n    <pre>`node_number=hash(\"semlinker\") % 3 -&gt; 1\r\n    node_number=hash(\"kakuqo\") % 3 -&gt; 2\r\n    node_number=hash(\"test\") % 3 -&gt; 0`</pre>\r\n\r\n    基于以上的输出结果，我们可以创建以下表格：\r\n\r\n    <span class=\"img-wrap\">![ch-three-nodes-hash.jpg](/img/bVbA7aw \"ch-three-nodes-hash.jpg\")</span>\r\n\r\n    #### 1.1 节点减少的场景\r\n\r\n    **在分布式多节点系统中，出现故障很常见。任何节点都可能在没有任何事先通知的情况下挂掉，针对这种情况我们期望系统只是出现性能降低，正常的功能不会受到影响。** 对于原始示例，当节点出现故障时会发生什么？原始示例中有的 3 个节点，假设其中 1 个节点出现故障，这时节点数发生了变化，节点个数从 3 减少为 2，此时表格的状态发生了变化：\r\n\r\n    <span class=\"img-wrap\">![ch-two-nodes-hash.jpg](/img/bVbA7ay \"ch-two-nodes-hash.jpg\")</span>\r\n\r\n    很明显节点的减少会导致键与节点的映射关系发生变化，这个变化对于新的键来说并不会产生任何影响，但对于已有的键来说，将导致节点映射错误，以 “semlinker” 为例，变化前系统有 3 个节点，该键对应的节点编号为 1，当出现故障时，节点数减少为 2 个，此时该键对应的节点编号为 0。\r\n\r\n    #### 1.2 节点增加的场景\r\n\r\n    **在分布式多节点系统中，对于某些场景比如节日大促，就需要对服务节点进行扩容，以应对突发的流量。** 对于原始示例，当增加节点会发生什么？原始示例中有的 3 个节点，假设进行扩容临时增加了 1 个节点，这时节点数发生了变化，节点个数从 3 增加为 4 个，此时表格的状态发生了变化：\r\n\r\n    <span class=\"img-wrap\">![ch-four-nodes-hash.jpg](/img/bVbA7az \"ch-four-nodes-hash.jpg\")</span>\r\n\r\n    很明显节点的增加也会导致键与节点的映射关系发生变化，这个变化对于新的键来说并不会产生任何影响，但对于已有的键来说，将导致节点映射错误，同样以 “semlinker” 为例，变化前系统有 3 个节点，该键对应的节点编号为 1，当增加节点时，节点数增加为 4 个，此时该键对应的节点编号为 2。\r\n\r\n    当集群中节点的数量发生变化时，之前的映射规则就可能发生变化。如果集群中每个机器提供的服务没有差别，这不会有什么影响。**但对于分布式缓存这种的系统而言，映射规则失效就意味着之前缓存的失效，若同一时刻出现大量的缓存失效，则可能会出现 “缓存雪崩”，这将会造成灾难性的后果。**\r\n\r\n    **要解决此问题，我们必须在其余节点上重新分配所有现有键，这可能是非常昂贵的操作，并且可能对正在运行的系统产生不利影响。当然除了重新分配所有现有键的方案之外，还有另一种更好的方案即使用一致性哈希算法。**\r\n\r\n    ### 二、一致性哈希算法\r\n\r\n    一致性哈希算法在 1997 年由麻省理工学院提出，是一种特殊的哈希算法，在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系。一致性哈希解决了简单哈希算法在分布式[哈希表](https://baike.baidu.com/item/%E5%93%88%E5%B8%8C%E8%A1%A8/5981869)（Distributed Hash Table，DHT）中存在的动态伸缩等问题 。\r\n\r\n    #### 2.1 一致性哈希算法优点\r\n\r\n*   可扩展性。一致性哈希算法保证了增加或减少服务器时，数据存储的改变最少，相比传统哈希算法大大节省了数据移动的开销 。\r\n*   更好地适应数据的快速增长。采用一致性哈希算法分布数据，当数据不断增长时，部分虚拟节点中可能包含很多数据、造成数据在虚拟节点上分布不均衡，此时可以将包含数据多的虚拟节点分裂，这种分裂仅仅是将原有的虚拟节点一分为二、不需要对全部的数据进行重新哈希和划分。\r\n    虚拟节点分裂后，如果物理服务器的负载仍然不均衡，只需在服务器之间调整部分虚拟节点的存储分布。这样可以随数据的增长而动态的扩展物理服务器的数量，且代价远比传统哈希算法重新分布所有数据要小很多。\r\n\r\n    #### 2.2 一致性哈希算法与哈希算法的关系\r\n\r\n    一致性哈希算法是在哈希算法基础上提出的，在动态变化的分布式环境中，哈希算法应该满足的几个条件：平衡性、单调性和分散性。\r\n\r\n*   平衡性：是指 hash 的结果应该平均分配到各个节点，这样从算法上解决了负载均衡问题。\r\n*   单调性：是指在新增或者删减节点时，不影响系统正常运行。\r\n*   分散性：是指数据应该分散地存放在分布式集群中的各个节点（节点自己可以有备份），不必每个节点都存储所有的数据。\r\n\r\n    ### 三、一致性哈希算法原理\r\n\r\n    一致性哈希算法通过一个叫作一致性哈希环的数据结构实现。这个环的起点是 0，终点是 2^32 - 1，并且起点与终点连接，故这个环的整数分布范围是 [0,  2^32-1]，如下图所示：\r\n\r\n    <span class=\"img-wrap\">![hash-ring.jpg](/img/bVbA7aA \"hash-ring.jpg\")</span>\r\n\r\n    #### 3.1 将对象放置到哈希环\r\n\r\n    假设我们有 \"semlinker\"、\"kakuqo\"、\"lolo\"、\"fer\" 四个对象，分别简写为 o1、o2、o3 和 o4，然后使用哈希函数计算这个对象的 hash 值，值的范围是 [0,  2^32-1]：\r\n\r\n    <span class=\"img-wrap\">![hash-ring-hash-objects.jpg](/img/bVbA7aB \"hash-ring-hash-objects.jpg\")</span>\r\n\r\n    图中对象的映射关系如下：\r\n\r\n    <pre>`hash(o1) = k1; hash(o2) = k2;\r\n    hash(o3) = k3; hash(o4) = k4;`</pre>\r\n\r\n    #### 3.2 将服务器放置到哈希环\r\n\r\n    接着使用同样的哈希函数，我们将服务器也放置到哈希环上，可以选择服务器的 IP 或主机名作为键进行哈希，这样每台服务器就能确定其在哈希环上的位置。这里假设我们有 3 台缓存服务器，分别为 cs1、cs2 和 cs3：\r\n\r\n    <span class=\"img-wrap\">![hash-ring-hash-servers.jpg](/img/bVbA7aG \"hash-ring-hash-servers.jpg\")</span>\r\n\r\n    图中服务器的映射关系如下：\r\n\r\n    <pre>`hash(cs1) = t1; hash(cs2) = t2; hash(cs3) = t3; # Cache Server`</pre>\r\n\r\n    #### 3.3 为对象选择服务器\r\n\r\n    **将对象和服务器都放置到同一个哈希环后，在哈希环上顺时针查找距离这个对象的 hash 值最近的机器，即是这个对象所属的机器。** 以 o2 对象为例，顺序针找到最近的机器是 cs2，故服务器 cs2 会缓存 o2 对象。而服务器 cs1 则缓存 o1，o3 对象，服务器 cs3 则缓存 o4 对象。\r\n\r\n    <span class=\"img-wrap\">![hash-ring-objects-servers.jpg](/img/bVbA7aH \"hash-ring-objects-servers.jpg\")</span>\r\n\r\n    #### 3.4 服务器增加的情况\r\n\r\n    假设由于业务需要，我们需要增加一台服务器 cs4，经过同样的 hash 运算，该服务器最终落于 t1 和 t2 服务器之间，具体如下图所示：\r\n\r\n    <span class=\"img-wrap\">![hash-ring-add-server.jpg](/img/bVbA7aI \"hash-ring-add-server.jpg\")</span>\r\n\r\n    对于上述的情况，只有 t1 和 t2 服务器之间的对象需要重新分配。在以上示例中只有 o3 对象需要重新分配，即它被重新到 cs4 服务器。在前面我们已经分析过，如果使用简单的取模方法，当新添加服务器时可能会导致大部分缓存失效，而使用一致性哈希算法后，这种情况得到了较大的改善，因为只有少部分对象需要重新分配。\r\n\r\n    #### 3.5 服务器减少的情况\r\n\r\n    假设 cs3 服务器出现故障导致服务下线，这时原本存储于 cs3 服务器的对象 o4，需要被重新分配至 cs2 服务器，其它对象仍存储在原有的机器上。\r\n\r\n    <span class=\"img-wrap\">![hash-ring-remove-server.jpg](/img/bVbA7aJ \"hash-ring-remove-server.jpg\")</span>\r\n\r\n    #### 3.6 虚拟节点\r\n\r\n    到这里一致性哈希的基本原理已经介绍完了，但对于新增服务器的情况还存在一些问题。新增的服务器 cs4 只分担了 cs1 服务器的负载，服务器 cs2 和 cs3 并没有因为 cs4 服务器的加入而减少负载压力。如果 cs4 服务器的性能与原有服务器的性能一致甚至可能更高，那么这种结果并不是我们所期望的。\r\n\r\n    **针对这个问题，我们可以通过引入虚拟节点来解决负载不均衡的问题。即将每台物理服务器虚拟为一组虚拟服务器，将虚拟服务器放置到哈希环上，如果要确定对象的服务器，需先确定对象的虚拟服务器，再由虚拟服务器确定物理服务器。**\r\n\r\n    <span class=\"img-wrap\">![ch-virtual-nodes.jpg](/img/bVbA7aK \"ch-virtual-nodes.jpg\")</span>\r\n\r\n    图中 o1 和 o2 表示对象，v1 ~ v6 表示虚拟服务器，s1 ~ s3 表示物理服务器。\r\n\r\n    ### 四、一致性哈希算法实现\r\n\r\n    这里我们只介绍不带虚拟节点的一致性哈希算法实现：\r\n\r\n    <pre>`import java.util.SortedMap;\r\n    import java.util.TreeMap;\r\n\r\n    public class ConsistentHashingWithoutVirtualNode {\r\n        //待添加入Hash环的服务器列表\r\n        private static String[] servers = {\"192.168.0.1:8888\", \"192.168.0.2:8888\", \r\n          \"192.168.0.3:8888\"};\r\n\r\n        //key表示服务器的hash值，value表示服务器\r\n        private static SortedMap&lt;Integer, String&gt; sortedMap = new TreeMap&lt;Integer, String&gt;();\r\n\r\n        //程序初始化，将所有的服务器放入sortedMap中\r\n        static {\r\n            for (int i = 0; i &lt; servers.length; i++) {\r\n                int hash = getHash(servers[i]);\r\n                System.out.println(\"[\" + servers[i] + \"]加入集合中, 其Hash值为\" + hash);\r\n                sortedMap.put(hash, servers[i]);\r\n            }\r\n        }\r\n\r\n        //得到应当路由到的结点\r\n        private static String getServer(String key) {\r\n            //得到该key的hash值\r\n            int hash = getHash(key);\r\n            //得到大于该Hash值的所有Map\r\n            SortedMap&lt;Integer, String&gt; subMap = sortedMap.tailMap(hash);\r\n            if (subMap.isEmpty()) {\r\n                //如果没有比该key的hash值大的，则从第一个node开始\r\n                Integer i = sortedMap.firstKey();\r\n                //返回对应的服务器\r\n                return sortedMap.get(i);\r\n            } else {\r\n                //第一个Key就是顺时针过去离node最近的那个结点\r\n                Integer i = subMap.firstKey();\r\n                //返回对应的服务器\r\n                return subMap.get(i);\r\n            }\r\n        }\r\n\r\n        //使用FNV1_32_HASH算法计算服务器的Hash值\r\n        private static int getHash(String str) {\r\n            final int p = 16777619;\r\n            int hash = (int) 2166136261L;\r\n            for (int i = 0; i &lt; str.length(); i++)\r\n                hash = (hash ^ str.charAt(i)) * p;\r\n            hash += hash &lt;&lt; 13;\r\n            hash ^= hash &gt;&gt; 7;\r\n            hash += hash &lt;&lt; 3;\r\n            hash ^= hash &gt;&gt; 17;\r\n            hash += hash &lt;&lt; 5;\r\n\r\n            // 如果算出来的值为负数则取其绝对值\r\n            if (hash &lt; 0)\r\n                hash = Math.abs(hash);\r\n            return hash;\r\n        }\r\n\r\n        public static void main(String[] args) {\r\n            String[] keys = {\"semlinker\", \"kakuqo\", \"fer\"};\r\n            for (int i = 0; i &lt; keys.length; i++)\r\n                System.out.println(\"[\" + keys[i] + \"]的hash值为\" + getHash(keys[i])\r\n                        + \", 被路由到结点[\" + getServer(keys[i]) + \"]\");\r\n        }\r\n\r\n    }`</pre>\r\n\r\n    以上代码成功运行后，在控制台会输出以下结果：\r\n\r\n    <pre>`[192.168.0.1:8888]加入集合中, 其Hash值为1326271016\r\n    [192.168.0.2:8888]加入集合中, 其Hash值为1132535844\r\n    [192.168.0.3:8888]加入集合中, 其Hash值为115798597\r\n\r\n    [semlinker]的hash值为1549041406, 被路由到结点[192.168.0.3:8888]\r\n    [kakuqo]的hash值为463104755, 被路由到结点[192.168.0.2:8888]\r\n    [fer]的hash值为1677150790, 被路由到结点[192.168.0.3:8888]\r\n\r\n上面我们只介绍了不带虚拟节点的一致性哈希算法实现，如果有的小伙伴对带虚拟节点的一致性哈希算法感兴趣，可以参考 [一致性Hash(Consistent Hashing)原理剖析及Java实现](https://blog.csdn.net/suifeng629/article/details/81567777) 这篇文章。\r\n\r\n### 五、总结\r\n\r\n本文通过示例介绍了传统的哈希取模算法在分布式系统中的局限性，进而在针对该问题的解决方案中引出了一致性哈希算法。一致性哈希算法在 1997 年由麻省理工学院提出，是一种特殊的哈希算法，在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系。在介绍完一致性哈希算法的作用和优点等相关知识后，我们以图解的形式生动介绍了一致性哈希算法的原理，最后给出了不带虚拟节点的一致性哈希算法的 Java 实现。\r\n\r\n### 六、参考资源\r\n\r\n*   [百度百科 - 一致性哈希](https://baike.baidu.com/item/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C)\r\n*   [知乎 - 面试必备：什么是一致性 Hash 算法](https://zhuanlan.zhihu.com/p/34985026)\r\n*   [Leo - 一致性Hash-Consistent-Hashing 原理剖析](https://leehao.me/%E4%B8%80%E8%87%B4%E6%80%A7Hash-Consistent-Hashing-%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90/)\r\n*   [CSDN - 一致性Hash(Consistent Hashing)原理剖析及Java实现](https://blog.csdn.net/suifeng629/article/details/81567777)\r\n*   [Codeproject - consistent-hashing](https://www.codeproject.com/articles/56138/consistent-hashing)\r\n> 本人的全栈修仙之路订阅号，会定期分享 Angular、TypeScript、Node.js/Java 、Spring 相关文章，欢迎感兴趣的小伙伴订阅哈！\r\n\r\n<span class=\"img-wrap\">![full-stack-logo](https://segmentfault.com/img/remote/1460000020988140 \"full-stack-logo\")</span>', 2, 0, 0, 0);
INSERT INTO `melog_article` VALUES (6, 1, 0, 'webpack4 中的 React 全家桶配', '雨思', 'me', '', 44, '技术', '这篇文档 是我在听 吕小明老师的课程，吕老师结合以往的项目经验 加上自己本身对react webpack redux理解写下的总结文档，总共耗时一周总结下来的，希望能对读者能够有收获， 我是在这基础多些加工，希望对你们有所收藏', '<span class=\"img-wrap\">![图片描述](/img/bVbjGNY \"图片描述\")</span>\r\n\r\n## 最新React全家桶实战使用配置指南\r\n\r\n这篇文档 是我在听 [吕小明老师](https://www.nihaoshijie.com.cn/index.php/archives/793/)的课程，吕老师结合以往的项目经验 加上自己本身对react webpack redux理解写下的总结文档，总共耗时一周总结下来的，希望能对读者能够有收获， 我是在这基础多些加工，希望对你们有所收藏\r\n\r\n## 目录\r\n\r\n**[1.版本说明](#1)**\r\n\r\n**[2.目录结构](#2)**\r\n\r\n**[3.初始化项目](#3)**\r\n\r\n**[4.webpack](#4)**\r\n\r\n**[5.react](#5)**\r\n\r\n**[6.配置loader(sass,jsx))](#6)**\r\n\r\n**[7.引入babel](#7)**\r\n\r\n**[8.使用HtmlWebpackPlugin](#8)**\r\n\r\n**[9.redux](#9)**\r\n\r\n**[10.使用webpack-dev-server](#10)**\r\n\r\n**[11.多入口页面配置](#11)**\r\n\r\n**[12.如何理解entry point(bundle),chunk,module](#12)**\r\n\r\n**[13.多入口页面html配置](#13)**\r\n\r\n**[14.模块热替换（Hot Module Replacement）](#14)**\r\n\r\n**[15.使用ESLint](#15)**\r\n\r\n**[16.使用react-router](#16)**\r\n\r\n**[17.使用redux-thunk](#17)**\r\n\r\n**[18.使用axios和async/await](#18)**\r\n\r\n**[19.Code Splitting](#19)**\r\n\r\n**[20.使用CommonsChunkPlugin](#20)**\r\n\r\n* * *\r\n\r\n如果本文对你有所帮助，你需要服务器的可以看看下面的，我可以赚点小费，写文章不易，还望支持。\r\n\r\n**阿里云`双12`已开启，新老用户均可参与，2核1G云服务器仅需`79元`，，更多服务器配置及价格请关注：[Hi拼团](https://www.aliyun.com/minisite/goods?userCode=pxuujn3r&amp;share_source=copy_link)，或点此了解[“云上爆款1折特惠活动”](https://www.aliyun.com/minisite/goods?userCode=pxuujn3r&amp;share_source=copy_link)。同时，建议在购买阿里云相关产品前[先领取阿里云2000元代金券](https://www.aliyun.com/minisite/goods?userCode=pxuujn3r&amp;share_source=copy_link)会更优惠哦。**\r\n\r\n* * *\r\n\r\n## <a id=\"1\">版本说明</a>\r\n\r\n由于构建相关例如webpack，babel等更新的较快，所以本教程以下面各种模块的版本号为主，切勿轻易修改或更新版本。\r\n\r\n    \"dependencies\": {\r\n        \"babel-core\": \"^6.26.3\",\r\n        \"babel-eslint\": \"^8.2.3\",\r\n        \"babel-loader\": \"^7.1.4\",\r\n        \"babel-plugin-transform-async-to-generator\": \"^6.24.1\",\r\n        \"babel-plugin-transform-runtime\": \"^6.23.0\",\r\n        \"babel-preset-es2015\": \"^6.24.1\",\r\n        \"babel-preset-react\": \"^6.24.1\",\r\n        \"babel-preset-stage-0\": \"^6.24.1\",\r\n        \"babel-preset-stage-3\": \"^6.24.1\",\r\n        \"css-loader\": \"^0.28.11\",\r\n        \"eslint\": \"^4.19.1\",\r\n        \"eslint-loader\": \"^2.0.0\",\r\n        \"eslint-plugin-react\": \"^7.9.1\",\r\n        \"file-loader\": \"^1.1.11\",\r\n        \"history\": \"^4.7.2\",\r\n        \"html-webpack-plugin\": \"^3.2.0\",\r\n        \"react\": \"^16.4.0\",\r\n        \"react-dom\": \"^16.4.0\",\r\n        \"react-hot-loader\": \"^4.0.0\",\r\n        \"react-redux\": \"^5.0.7\",\r\n        \"react-router-dom\": \"^4.3.1\",\r\n        \"react-router-redux\": \"^5.0.0-alpha.9\",\r\n        \"redux\": \"^4.0.0\",\r\n        \"sass-loader\": \"^7.0.3\",\r\n        \"style-loader\": \"^0.21.0\",\r\n        \"url-loader\": \"^1.0.1\",\r\n        \"webpack\": \"^4.12.0\",\r\n        \"webpack-cli\": \"^3.0.3\",\r\n        \"webpack-dev-server\": \"^3.1.1\"\r\n    }\r\n    `</pre>\r\n\r\n    ## <a id=\"2\">目录结构</a>\r\n\r\n    开发和发布版本的配置文件是分开的，多入口页面的目录结构。\r\n\r\n    <pre>`react-family/\r\n        |\r\n        |──dist/                                    * 发布版本构建输出路径\r\n        |\r\n        |──dev/                                     * 调试版本构建输出路径\r\n        |\r\n        |──src/                                     * 工具函数\r\n        |     |\r\n        |     |—— component/                        * 各页面公用组件\r\n        |     |\r\n        |     |—— page/                             * 页面代码\r\n        |     |      |—— index/                     * 页面代码\r\n        |     |      |        |—— Main/             * 组件代码\r\n        |     |      |        |       |—— Main.jsx  * 组件jsx\r\n        |     |      |        |       |—— Main.scss * 组件css\r\n        |     |      |\r\n        |     |      |—— detail/                    * 页面代码\r\n        |     |\r\n        |     |—— static/                           * 静态文件js，css\r\n        |\r\n        |\r\n        |──webpack.config.build.js                  * 发布版本使用的webpack配置文件\r\n        |──webpack.config.dev.js                    * 调试版本使用的webpack配置文件\r\n        |──.eslint                                  * eslint配置文件\r\n        |__.babelrc                                 * babel配置文件\r\n\r\n        `</pre>\r\n\r\n    ## <a id=\"3\">初始化项目</a>\r\n\r\n    1.创建文件夹\r\n\r\n    <pre>`mkdir react-family-bucket\r\n\r\n    `</pre>\r\n\r\n    2.初始化npm\r\n\r\n    <pre>`cd react-family-bucket\r\n    npm init\r\n    `</pre>\r\n\r\n    如果有特殊需要，可以填入自己的配置，一路回车下来，会生成一个package.json，里面是你项目的基本信息，后面的npm依赖安装也会配置在这里。\r\n\r\n    ## <a id=\"4\">webpack</a>\r\n\r\n    1.安装webpack\r\n\r\n    <pre>`npm install webpack@4.12.0 --save\r\n    or\r\n    npm install webpack@4.12.0 --g\r\n    `</pre>\r\n\r\n    `--save` 是将当前webpack安装到react-family-bucket下的/node_modules。\r\n\r\n    `--g` 是将当前webpack安装到全局下面，可以在node的安装目录下找到全局的/node_modules。\r\n\r\n    2.配置webopack配置文件\r\n\r\n    <pre>`touch webpack.config.dev.js\r\n    `</pre>\r\n\r\n    3.新建一个app.js\r\n\r\n    <pre>`touch app.js\r\n    `</pre>\r\n\r\n    写入基本的webpack配置，可以[参考这里](https://webpack.js.org/)：\r\n\r\n    <pre>`const path = require(\'path\');\r\n    const srcRoot = \'./src\';\r\n    module.exports = {\r\n\r\n        // 输入配置\r\n        entry: [\r\n          \'./app.js\'\r\n        ],,\r\n\r\n        // 输出配置\r\n        output: {\r\n            path: path.resolve(__dirname, \'./dev\'),\r\n\r\n            filename: \'bundle.min.js\'\r\n        },\r\n    };\r\n\r\n    `</pre>\r\n\r\n    3.执行webpack命令\r\n\r\n    如果是全局安装：\r\n\r\n    <pre>`webpack --config webpack.config.dev.js\r\n\r\n    `</pre>\r\n\r\n    如果是当前目录安装：\r\n\r\n    <pre>`./node_modules/.bin/webpack --config webpack.config.dev.js\r\n    `</pre>\r\n\r\n    为了方便我们使用，可以在package.json中 `scripts` 添加执行命令：\r\n\r\n    <pre>`\"scripts\": {\r\n      \"dev\": \"./node_modules/.bin/webpack --config webpack.config.dev.js\",\r\n    },\r\n\r\n    `</pre>\r\n\r\n    执行npm run dev命令之后，会发现需要安装webpack-cli，**（webpack4之后需要安装这个）**\r\n\r\n    <pre>`npm install webpack-cli --save\r\n    `</pre>\r\n\r\n    安装后，执行 npm run dev 会发现控制台有个警告 ** `WARNING in configuration`**  ，去除WARNING in configuration 警告,在webpack.config.dev.js 增加一个配置即可：\r\n\r\n    <pre>`...\r\n    mode: \'development\'\r\n    ...\r\n\r\n    `</pre>\r\n\r\n    成功之后会在dev下面生成bundle.min.js代表正常。\r\n\r\n    如果想要动态监听文件变化需要在命令后面添加 --watch。\r\n\r\n    ## <a id=\"5\">react</a>\r\n\r\n    1.安装react\r\n\r\n    <pre>`npm install react react-dom --save\r\n    `</pre>\r\n\r\n    2.创建page目录和index页面文件：\r\n\r\n    <pre>`mkdir src\r\n    mkdir page\r\n    cd page\r\n    `</pre>\r\n\r\n    3.创建index\r\n\r\n    <pre>`\r\n    mkdir index\r\n    cd index &amp; touch index.js &amp; touch index.html\r\n\r\n    `</pre>\r\n\r\n    **index.js**\r\n\r\n    <pre>`import ReactDom from \'react-dom\';\r\n    import Main from \'./Main/Main.jsx\';\r\n\r\n    ReactDom.render(&lt;Main /&gt;, document.getElementById(\'root\'));\r\n    `</pre>\r\n\r\n    **index.html**\r\n\r\n    <pre>`&lt;!DOCTYPE html&gt;\r\n    &lt;html&gt;\r\n    &lt;head&gt;\r\n        &lt;title&gt;index&lt;/title&gt;\r\n        &lt;meta charset=\"utf-8\"&gt;\r\n        &lt;meta name=\"viewport\" content=\"width=device-width,initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no\"&gt;\r\n\r\n    &lt;/head&gt;\r\n    &lt;body&gt;\r\n    &lt;div id=\"root\"&gt;&lt;/div&gt;\r\n    &lt;/body&gt;\r\n    &lt;/html&gt;\r\n    `</pre>\r\n\r\n    4.创建Main组件\r\n\r\n    <pre>`import React from \'react\';\r\n\r\n    class Main extends React.Component {\r\n\r\n        constructor(props) {\r\n            super(props);\r\n        }\r\n\r\n        render() {\r\n            return (&lt;div&gt;Main&lt;/div&gt;);\r\n        }\r\n    }\r\n    export default Main;\r\n    `</pre>\r\n\r\n    5.修改webpack配置入口文件\r\n\r\n    <pre>`entry: [\r\n        path.resolve(srcRoot,\'./page/index/index.js\')\r\n    ],\r\n\r\n    `</pre>\r\n\r\n    ## <a id=\"6\">配置loader</a>\r\n\r\n    1.处理样式文件需要这些loader:\r\n\r\n*   [css-loader](https://github.com/webpack-contrib/css-loader)\r\n*   [sass-loader](https://github.com/webpack-contrib/sass-loader)\r\n*   [style-loader](https://github.com/webpack-contrib/style-loader)\r\n    <pre>`npm install css-loader sass-loader style-loader file-loader --save\r\n    `</pre>\r\n\r\n    配置：\r\n\r\n    <pre>`module: {\r\n        // 加载器配置\r\n        rules: [\r\n            { test: /\\.css$/, use: [\'style-loader\', \'css-loader\'], include: path.resolve(srcRoot)},\r\n            { test: /\\.scss$/, use: [\'style-loader\', \'css-loader\', \'sass-loader\'], include: path.resolve(srcRoot)}\r\n        ]\r\n    },\r\n    `</pre>\r\n\r\n    2.[url-loader](https://github.com/webpack-contrib/url-loader) 处理处理静态文件\r\n\r\n    <pre>`npm install url-loader --save\r\n    `</pre>\r\n\r\n    配置:\r\n\r\n    <pre>`module: {\r\n        // 加载器配置\r\n        rules: [\r\n            { test: /\\.(png|jpg|jpeg)$/, use: \'url-loader?limit=8192&amp;name=images/[name].[hash].[ext]\', include: path.resolve(srcRoot)}\r\n        ]\r\n    },\r\n    `</pre>\r\n\r\n    `limit:`表示超过多少就使用base64来代替，单位是byte\r\n\r\n    `name:`可以设置图片的路径，名称和是否使用hash 具体[参考这里](https://github.com/webpack-contrib/url-loader)\r\n\r\n    ## <a id=\"7\">引入babel</a>\r\n\r\n    [bebel](https://babeljs.io/)是用来解析es6语法或者是es7语法分解析器，让开发者能够使用新的es语法，同时支持jsx，vue等多种框架。\r\n\r\n    1.安装babel\r\n\r\n*   [babel-core](https://www.npmjs.com/package/babel-core)\r\n*   [babel-loader](https://www.npmjs.com/package/babel-loader)\r\n    <pre>`npm install babel-core babel-loader --save\r\n\r\n    `</pre>\r\n\r\n    配置：\r\n\r\n    <pre>`module: {\r\n        // 加载器配置\r\n        rules: [\r\n            { test: /\\.(js|jsx)$/, use: [{loader:\'babel-loader\'}] ,include: path.resolve(srcRoot)},\r\n        ]\r\n    },\r\n    `</pre>\r\n\r\n    2.babel配置文件：.babelrc\r\n\r\n    <pre>`touch .babelrc\r\n    `</pre>\r\n\r\n    配置：\r\n\r\n    <pre>`{\r\n        \"presets\": [\r\n            \"es2015\",\r\n            \"react\",\r\n            \"stage-0\"\r\n        ],\r\n        \"plugins\": []\r\n    }\r\n    `</pre>\r\n\r\n    babel支持自定义的预设(presets)或插件(plugins),只有配置了这两个才能让babel生效，单独的安装babel是无意义的。\r\n\r\n    `presets`：代表babel支持那种语法(就是你用那种语法写)，优先级是从下往上,state-0|1|2|..代表有很多没有列入标准的语法回已state-x表示,[参考这里](https://babeljs.io/docs/en/babel-preset-stage-0.html)\r\n\r\n    `plugins`:代表babel解析的时候使用哪些插件，作用和presets类似，优先级是从上往下。\r\n\r\n    依次安装：\r\n\r\n*   [babel-preset-es2015](https://www.npmjs.com/package/babel-preset-es2015)\r\n*   [babel-preset-react](https://www.npmjs.com/package/babel-preset-react)\r\n*   [babel-preset-stage-0](https://www.npmjs.com/package/babel-preset-stage-0)\r\n    <pre>`npm install babel-preset-es2015 babel-preset-react babel-preset-stage-0 --save\r\n    `</pre>\r\n\r\n    3.[babel-polyfill](https://babeljs.io/docs/en/babel-polyfill.html)是什么？\r\n\r\n    我们之前使用的babel，babel-loader 默认只转换新的 JavaScript 语法，而不转换新的 API。例如，Iterator、Generator、Set、Maps、Proxy、Reflect、Symbol、Promise 等全局对象，以及一些定义在全局对象上的方法（比如 Object.assign）都不会转译。如果想使用这些新的对象和方法，必须使用 babel-polyfill，为当前环境提供一个垫片。\r\n\r\n    <pre>`npm install --save babel-polyfill\r\n    `</pre>\r\n\r\n    4.[transform-runtime](https://babeljs.io/docs/en/babel-plugin-transform-runtime) 有什么区别？\r\n\r\n    当使用babel-polyfill时有一些问题：\r\n\r\n*   默认会引入所有babel支持的新语法，这样就会导致你的文件代码非常庞大。\r\n*   通过向全局对象和内置对象的prototype上添加方法来达成目的,造成全局变量污染。\r\n\r\n    这时就需要transform-runtime来帮我们有选择性的引入:\r\n\r\n    <pre>`npm install --save babel-plugin-transform-runtime\r\n    `</pre>\r\n\r\n    配置文件：\r\n\r\n    <pre>`\r\n    {\r\n      \"plugins\": [\r\n        [\"transform-runtime\", {\r\n          \"helpers\": false,\r\n          \"polyfill\": false,\r\n          \"regenerator\": true,\r\n          \"moduleName\": \"babel-runtime\"\r\n        }]\r\n      ]\r\n    }\r\n\r\n    `</pre>\r\n\r\n    ## <a id=\"8\">使用HtmlWebpackPlugin</a>\r\n\r\n    记得我们之前新建的index.html么 我们执行构建命令之后并没有将index.html打包到dev目录下 我们需要[HtmlWebpackPlugin](https://github.com/jantimon/html-webpack-plugin)来将我们output的js和html结合起来:\r\n\r\n    <pre>`npm install html-webpack-plugin --save\r\n    `</pre>\r\n\r\n    配置:\r\n\r\n    <pre>`const HtmlWebpackPlugin = require(\'html-webpack-plugin\');\r\n    ...\r\n    plugins: [\r\n        new HtmlWebpackPlugin({\r\n            filename: path.resolve(devPath, \'index.html\'),\r\n            template: path.resolve(srcRoot, \'./page/index/index.html\'),\r\n        })\r\n    ]\r\n    `</pre>\r\n\r\n    `filename:`可以设置html输出的路径和文件名\r\n    `template:`可以设置已哪个html文件为模版\r\n\r\n    更多参数配置可以[参考这里](https://github.com/jantimon/html-webpack-plugin)\r\n\r\n    ## <a id=\"9\">redux</a>\r\n\r\n    关于[redux](http://www.ruanyifeng.com/blog/2016/09/redux_tutorial_part_one_basic_usages.html)的使用可以参考阮一峰老师的入门[教程](http://www.ruanyifeng.com/blog/2016/09/redux_tutorial_part_one_basic_usages.html)\r\n\r\n    1.安装redux\r\n\r\n*   [redux](https://www.npmjs.com/package/redux)\r\n*   [react-redux](https://www.npmjs.com/package/react-redux)\r\n    <pre>`npm install redux react-redux --save\r\n    `</pre>\r\n\r\n    1.新建reducers，actions目录和文件\r\n\r\n    <pre>`|—— index/                          \r\n    |—— Main/                   * 组件代码\r\n    |       |—— Main.jsx        * 组件jsx\r\n    |       |—— Main.scss       * 组件css\r\n    |\r\n    |—— actions/ \r\n    |       |—— actionTypes.js  * action常量\r\n    |       |—— todoAction.js   * action\r\n    |\r\n    |—— reducers/ \r\n    |       |—— todoReducer.js  * reducer\r\n    |\r\n    |—— store.js\r\n    |\r\n    |—— index.js\r\n    `</pre>\r\n\r\n    2.修改代码，引入redux,这里以一个redux todo为demo例子：\r\n\r\n    index.js\r\n\r\n    <pre>`import ReactDom from \'react-dom\';\r\n    import React from \'react\';\r\n    import Main from \'./Main/Main.jsx\';\r\n    import store from \'./store.js\';\r\n    import { Provider } from \'react-redux\';\r\n\r\n    ReactDom.render(\r\n        &lt;Provider store={store}&gt;\r\n            &lt;Main /&gt;\r\n        &lt;/Provider&gt;\r\n    , document.getElementById(\'root\'));  \r\n\r\n    `</pre>\r\n\r\n    store.js\r\n\r\n    <pre>`import { createStore } from \'redux\';\r\n    import todoReducer from \'./reducers/todoReducer.js\';\r\n\r\n    const store = createStore(todoReducer);\r\n\r\n    export default store;  \r\n\r\n    `</pre>\r\n\r\n    tabReducer.js\r\n\r\n    <pre>`    import { ADD_TODO } from \'../actions/actionTypes.js\';\r\n\r\n        const initialState = {\r\n              todoList: []\r\n        };\r\n\r\n        const addTodo = (state, action) =&gt; {\r\n\r\n          return { ...state, todoList: state.todoList.concat(action.obj) }\r\n        }\r\n\r\n        const todoReducer = (state = initialState, action) =&gt; {\r\n          switch(action.type) {\r\n            case ADD_TODO: return addTodo(state, action);\r\n            default: return state;\r\n          }\r\n        };\r\n        export default todoReducer;\r\n    `</pre>\r\n\r\n    Main.jsx\r\n\r\n    <pre>`import React from \'react\';\r\n    import { connect } from \'react-redux\';\r\n    import { addTodo } from \'../actions/todoAction.js\';\r\n\r\n    class Main extends React.Component {\r\n\r\n        onClick(){\r\n            let text = this.refs.input;\r\n\r\n            this.props.dispatch(addTodo({\r\n                text: text.value\r\n            }))\r\n        }\r\n        render() {\r\n            return (\r\n                &lt;div&gt;\r\n                    &lt;input ref=\"input\" type=\"text\"&gt;&lt;/input&gt;\r\n                    &lt;button onClick={()=&gt;this.onClick()}&gt;提交&lt;/button&gt;\r\n                    &lt;ul&gt;\r\n                    {this.props.todoList.map((item, index)=&gt;{\r\n                        return &lt;li key={index}&gt;{item.text}&lt;/li&gt;\r\n                    })}\r\n                    &lt;/ul&gt;\r\n                &lt;/div&gt;\r\n            );\r\n        }\r\n    }\r\n\r\n    export default connect(\r\n        state =&gt; ({\r\n            todoList: state.todoList\r\n        })\r\n    )(Main);\r\n    `</pre>\r\n\r\n    todoAction.js\r\n\r\n    <pre>`import { ADD_TODO } from \'./actionTypes.js\';\r\n\r\n    export const addTodo = (obj) =&gt; {\r\n      return {\r\n        type: ADD_TODO,\r\n        obj: obj\r\n      };\r\n    };\r\n\r\n    `</pre>\r\n\r\n    ## <a id=\"10\">使用webpack-dev-server</a>\r\n\r\n    [webpack-dev-server](https://github.com/webpack/webpack-dev-server)是一个小型的Node.js Express服务器,它使用webpack-dev-middleware来服务于webpack的包。\r\n\r\n    1.安装\r\n\r\n    <pre>`npm install webpack-dev-server --save\r\n    `</pre>\r\n\r\n    修改在package.json中添加的执行命令：\r\n\r\n    <pre>`\"scripts\": {\r\n      \"dev\": \"./node_modules/.bin/webpack-dev-server --config webpack.config.dev.js\",\r\n    },\r\n\r\n    `</pre>\r\n\r\n    2.配置webpack配置文件：\r\n\r\n    <pre>`devServer: {\r\n        \"contentBase\": devPath,\r\n        \"compress\": true,\r\n    },\r\n\r\n    `</pre>\r\n\r\n    `contentBase`: 表示server文件的根目录\r\n    `compress`: 表示开启gzip\r\n\r\n    更多的配置文档[参考这里](https://webpack.docschina.org/configuration/dev-server/)\r\n\r\n*   webpack-dev-server默认情况下会将output的内容放在内存中，是看不到物理的文件的，如果想要看到物理的dev下面的文件可以安装[write-file-webpack-plugin](https://www.npmjs.com/package/webpack-dev-server)这个插件。\r\n*   webpack-dev-server默认会开启livereload功能\r\n\r\n    3.devtool功能：\r\n\r\n    具体来说添加了devtool: \'inline-source-map\'之后，利用source-map你在chrome控制台看到的source源码都是真正的源码，未压缩，未编译前的代码，没有添加，你看到的代码是真实的压缩过，编译过的代码，更多devtool的配置可以[参考这里](https://webpack.docschina.org/)。\r\n\r\n    ## <a id=\"11\">多入口文件配置</a>\r\n\r\n    在之前的配置中，都是基于单入口页面配置的，entry和output只有一个文件，但是实际项目很多情况下是多页面的，在配置多页面时，有2中方法可以选择：\r\n\r\n    1.在entry入口配置时，传入对象而不是单独数组,output时利用[name]关键字来区分输出文件例如：\r\n\r\n    <pre>`entry: {\r\n        index: [path.resolve(srcRoot,\'./page/index/index1.js\'),path.resolve(srcRoot,\'./page/index/index2.js\')],\r\n        detail: path.resolve(srcRoot,\'./page/detail/detail.js\'),\r\n        home: path.resolve(srcRoot,\'./page/home/home.js\'),\r\n    },\r\n    output: {\r\n        path: path.resolve(__dirname, \'./dev\'),\r\n\r\n        filename: \'[name].min.js\'\r\n    },\r\n    `</pre>\r\n\r\n    2.通过node动态遍历需要entry point的目录，来动态生成entry：\r\n\r\n    <pre>`const pageDir = path.resolve(srcRoot, \'page\');\r\n    function getEntry() {\r\n        let entryMap = {};\r\n\r\n        fs.readdirSync(pageDir).forEach((pathname)=&gt;{\r\n            let fullPathName = path.resolve(pageDir, pathname);\r\n            let stat = fs.statSync(fullPathName);\r\n            let fileName = path.resolve(fullPathName, \'index.js\');\r\n\r\n            if (stat.isDirectory() &amp;&amp; fs.existsSync(fileName)) {\r\n                entryMap[pathname] = fileName;\r\n            }\r\n\r\n        });\r\n\r\n        return entryMap;\r\n    }\r\n    {\r\n        ...\r\n        entry: getEntry()\r\n        ...\r\n    }`</pre>\r\n\r\n    本demo采用的是第二中写法，能够更加灵活。\r\n\r\n    ## <a id=\"12\">如何理解entry point(bundle),chunk,module</a>\r\n\r\n    在webpack中，如何理解entry point(bundle),chunk,module?\r\n\r\n    根据图上的表述，我这里简单说一下便于理解的结论：\r\n\r\n*   配置中每个文件例如index1.js,index2.js,detail.js,home.js都属于entry point.\r\n*   entry这个配置中，每个key值,index,detail,home都相当于chunk。\r\n*   我们在代码中的require或者import的都属于module，这点很好理解。\r\n*   chunk的分类比较特别，有entry chunk,initial chunk,normal chunk,参考这个文章\r\n*   正常情况下，一个chunk对应一个output,在使用了CommonsChunkPlugin或者require.ensure之后，chunk就变成了initial chunk,normal chunk，这时，一个chunk对应多个output。\r\n\r\n    理解这些概念对于后续使用webpack插件有很大的帮助。\r\n\r\n    ## <a id=\"13\">多入口页面html配置</a>\r\n\r\n    之前我们配置HtmlWebpackPlugin时，同样采用的是但页面的配置，这里我们将进行多页面改造,entryMap是上一步得到的entry：\r\n\r\n    <pre>`function htmlAarray(entryMap) {\r\n        let htmlAarray = [];\r\n\r\n        Object.keys(entryMap).forEach(function(key){\r\n            let fullPathName = path.resolve(pageDir, key);\r\n            let fileName = path.resolve(fullPathName, key + \'.html\')\r\n            if (fs.existsSync(fileName)) {\r\n                htmlAarray.push(new HtmlWebpackPlugin({\r\n                    chunks: key, // 注意这里的key就是chunk\r\n                    filename: key + \'.html\',\r\n                    template: fileName,\r\n                    inlineSource:  \'.(js|css)\'\r\n                }))\r\n            }\r\n        });\r\n\r\n        return htmlAarray;\r\n\r\n    }`</pre>\r\n    <pre>`修改plugin配置：plugins: [\r\n         ...\r\n    ].concat(htmlMap)\r\n\r\n    `</pre>\r\n\r\n    ## <a id=\"14\"> 模块热替换（Hot Module Replacement）</a>\r\n\r\n    [模块热替换](https://webpack.docschina.org/guides/hot-module-replacement)  (Hot Module Replacement 或 HMR)是 webpack 提供的最有用的功能之一。它允许在运行时更新各种模块，而无需进行完全刷新,很高大上有木有！  \r\n\r\n    下面说一下配置方法，它需要结合devServer使用：\r\n\r\n    <pre>`devServer: {\r\n        hot: true // 开启HMR\r\n    },\r\n    `</pre>\r\n\r\n    开启plugin：\r\n\r\n    <pre>`const webpack = require(\'webpack\');\r\n    plugins: [\r\n        new webpack.NamedModulesPlugin(),\r\n        new webpack.HotModuleReplacementPlugin(),\r\n    ].concat(htmlMap)\r\n    `</pre>\r\n\r\n    结合React一起使用：\r\n\r\n    1.安装[react-hot-loader](https://github.com/gaearon/react-hot-loader)\r\n\r\n    <pre>`npm install react-hot-loader --save\r\n    `</pre>\r\n\r\n    并新建一个Container.jsx:\r\n\r\n    <pre>`import React from \'react\';\r\n    import Main from \'./Main.jsx\';\r\n    import { hot } from \'react-hot-loader\'\r\n\r\n    class Container extends React.Component {\r\n\r\n        render() {\r\n            return &lt;Main /&gt;\r\n        }\r\n\r\n    }\r\n    export default hot(module)(Container);\r\n    `</pre>\r\n\r\n    结合redux：如果项目没有使用redux，可以无需配置后面2步\r\n\r\n    2.修改store.js新增下面代码，为了让reducer也能实时热替换\r\n\r\n    <pre>`if (module.hot) {\r\n        module.hot.accept(\'./reducers/todoReducer.js\', () =&gt; {\r\n          const nextRootReducer = require(\'./reducers/todoReducer.js\').default;\r\n          store.replaceReducer(nextRootReducer);\r\n        });\r\n    }\r\n    `</pre>\r\n\r\n    3.修改index.js\r\n\r\n    <pre>`import ReactDom from \'react-dom\';\r\n    import React from \'react\';\r\n    import Container from \'./Main/Container.jsx\';\r\n    import store from \'./store.js\';\r\n\r\n    import { Provider } from \'react-redux\';\r\n\r\n    ReactDom.render(\r\n        &lt;Provider store={store}&gt;\r\n            &lt;Container /&gt;\r\n        &lt;/Provider&gt;\r\n    , document.getElementById(\'root\'));\r\n    `</pre>\r\n\r\n    当控制台看到[WDS] Hot Module Replacement enabled.代表开启成功\r\n\r\n    ## <a id=\"15\"> 使用ESLint</a>\r\n\r\n    [ESLint](https://eslint.org/) 是众多 Javascript Linter 中的其中一种，其他比较常见的还有 [JSLint](https://www.jslint.com/) 跟 [JSHint](http://jshint.com/)，之所以用 ESLint 是因为他可以自由选择要使用哪些规则，也有很多现成的 plugin 可以使用，另外他对 ES6 还有 JSX 的支持程度跟其他 linter 相比之下也是最高的。\r\n\r\n    1.安装ESLint\r\n\r\n    <pre>`npm install eslint eslint-loader babel-eslint --save\r\n    `</pre>\r\n\r\n    其中eslint-loader是将webpack和eslint结合起来在webpack的配置文件中新增一个eslint-loader种，修改如下:\r\n\r\n    <pre>`{ test: /\\.(js|jsx)$/, use: [{loader:\'babel-loader\'},{loader:\'eslint-loader\'}] ,include: path.resolve(srcRoot)},   \r\n\r\n    `</pre>\r\n\r\n    2.新建.eslintrc配置文件,将parser配置成babel-eslint\r\n\r\n    <pre>`{\r\n        \"extends\": [\"eslint:recommended\"],\r\n\r\n        \"parser\": \"babel-eslint\",\r\n\r\n        \"globals\": {\r\n        },\r\n        \"rules\": {\r\n        }\r\n    } \r\n    `</pre>\r\n\r\n    3.安装eslint-plugin-react:\r\n\r\n    <pre>`npm install eslint-plugin-react --save\r\n    `</pre>\r\n\r\n*   说明一下，正常情况下每个eslint规则都是需要在rule下面配置，如果什么都不配置，其实本身eslint是不生效的。\r\n*   eslint本身有很多默认的规则模版，可以通过extends来配置，默认可以使用eslint:recommended。\r\n*   在使用react开发时可以安装eslint-plugin-react来告知使用react专用的规则来lint。\r\n\r\n    修改.eslintrc配置文件,增加rules，更多rules配置可以[参考这里](https://eslint.org/docs/rules/)\r\n\r\n    <pre>`{\r\n        \"extends\": [\"eslint:recommended\",\"plugin:react/recommended\"],\r\n\r\n        \"parser\": \"babel-eslint\",\r\n\r\n        \"globals\": {\r\n            \"window\": true,\r\n            \"document\": true,\r\n            \"module\": true,\r\n            \"require\": true\r\n        },\r\n        \"rules\": {\r\n            \"react/prop-types\" : \"off\",\r\n            \"no-console\" : \"off\"\r\n        }\r\n    }\r\n    `</pre>\r\n\r\n    ## <a id=\"16\"> 使用react-router </a>\r\n\r\n    react-router强大指出在于方便代码管理，结合redux使用更加强大，同时支持web，native更多[参考这里](https://reacttraining.com/react-router/)\r\n\r\n    1.安装[react-router-dom](https://github.com/ReactTraining/react-router/tree/master/packages/react-router-dom)\r\n\r\n    <pre>`npm install react-router-dom --save\r\n    `</pre>\r\n\r\n    2.如果项目中用了redux，可以安装[react-router-redux](https://github.com/reactjs/react-router-redux)\r\n\r\n    <pre>`npm install react-router-redux@next history --save\r\n    `</pre>\r\n\r\n    3.修改代码：\r\n\r\n    index.js\r\n\r\n    <pre>`import ReactDom from \'react-dom\';\r\n    import React from \'react\';\r\n    import Container from \'./Main/Container.jsx\';\r\n    import { store, history } from \'./store.js\';\r\n\r\n    import { Provider } from \'react-redux\';\r\n\r\n    import createHistory from \'history/createHashHistory\';\r\n    import { ConnectedRouter } from \'react-router-redux\';\r\n\r\n    const history = createHistory();\r\n\r\n    ReactDom.render(\r\n        &lt;Provider store={store}&gt;\r\n            &lt;ConnectedRouter history={history}&gt;\r\n                &lt;Container /&gt;\r\n            &lt;/ConnectedRouter&gt;\r\n        &lt;/Provider&gt;\r\n    , document.getElementById(\'root\'));\r\n    `</pre>\r\n\r\n    结合history,react-router一共有3中不同的router：\r\n\r\n*   [BrowserRouter](https://reacttraining.com/react-router/web/api/BrowserRouter)通过history/createBrowserHistory引入:当切换时，url会动态更新，底层使用的时html5的[pushState](https://blog.csdn.net/tianyitianyi1/article/details/7426606)。\r\n*   [HashRouter](https://reacttraining.com/react-router/web/api/HashRouter)通过history/createHashHistory引入:当切换时，动态修改hash，利用hashchange事件。\r\n*   [MemoryRouter](https://reacttraining.com/react-router/web/api/MemoryRouter) 通过history/createMemoryHistory引入:将路径，路由相关数据存入内存中，不涉及url相关更新，兼容性好。\r\n\r\n    更多配置可以[参考这里](https://reacttraining.com/react-router/)\r\n\r\n    4.如果想要在代码逻辑中获取当前的route路径需要引入router-reducer:\r\n\r\n    新建main.js:\r\n\r\n    <pre>`import { combineReducers } from \'redux\';\r\n    import { routerReducer } from \"react-router-redux\";\r\n    import todoReducer from \'./todoReducer.js\';\r\n\r\n    const reducers = combineReducers({\r\n      todoReducer,\r\n      router: routerReducer\r\n    });\r\n    export default reducers;\r\n\r\n    `</pre>\r\n\r\n    修改store.js:\r\n\r\n    <pre>`import { createStore } from \'redux\';\r\n    import mainReducer from \'./reducers/main.js\';\r\n\r\n    const store = createStore(mainReducer);\r\n\r\n    export default store;\r\n    `</pre>\r\n\r\n    然后就可以在this.props.router里面获取单相关的路径信息\r\n\r\n    5.如果需要自己通过action来触发router的跳转，需要引入routerMiddleware:\r\n\r\n    <pre>`import { createStore,applyMiddleware } from \'redux\';\r\n    import { routerMiddleware } from \"react-router-redux\";\r\n    const middleware = routerMiddleware(history);\r\n    const store = createStore(mainReducer,applyMiddleware(middleware));\r\n    `</pre>\r\n\r\n    6.使用Route和Link和withRouter:\r\n\r\n    先说说都是干嘛的：\r\n\r\n    <pre>`&lt;Route exact path=\"/\" component={Div1}&gt;&lt;/Route&gt;\r\n    &lt;Route path=\"/2\" component={Div2}&gt;&lt;/Route&gt;\r\n    `</pre>\r\n\r\n    <pre>`export default withRouter(connect(\r\n       state =&gt; ({\r\n          todoList: state.todoReducer.todoList\r\n       })\r\n    )(Main));`</pre>\r\n\r\n    如果你在使用hash时遇到Warning: Hash history cannot PUSH the same path; a new entry will not be added to the history stack错误，可以将push改为replace即：\r\n\r\n    <pre>`&lt;NavLink\r\n        replace={true}\r\n        to=\"/2\"\r\n        activeClassName=\"selected\"\r\n        &gt;切换到2号&lt;/NavLink&gt;`</pre>\r\n\r\n    7.设置初始化路由：\r\n\r\n    BrowserRouter和HashRouter:\r\n\r\n    <pre>`const history = createHistory();\r\n    history.push(\'2\');\r\n    `</pre>\r\n\r\n    MemoryRouter:\r\n\r\n    <pre>`const history = createMemoryHistory({\r\n        initialEntries: [\'/2\']\r\n    });\r\n\r\n    `</pre>\r\n\r\n    ## <a id=\"17\"> 使用redux-thunk </a>\r\n\r\n    [redux-thunk](https://www.npmjs.com/package/redux-thunk) 是一个比较流行的 redux 异步 action 中间件，比如 action 中有 setTimeout 或者通过 fetch通用远程 API 这些场景，那么久应该使用 redux-thunk 了。redux-thunk 帮助你统一了异步和同步 action 的调用方式，把异步过程放在 action 级别解决，对 component 没有影响。\r\n\r\n    1.安装redux-thunk:\r\n\r\n    <pre>`npm install redux-thunk --save\r\n    `</pre>\r\n\r\n    2.修改store.js:\r\n\r\n    <pre>`import { createStore,applyMiddleware } from \'redux\';\r\n    import thunk from \'redux-thunk\';\r\n    import mainReducer from \'./reducers/main\';\r\n    ...\r\n    const store = createStore(mainReducer, applyMiddleware(thunk));\r\n    ...\r\n    export default store;\r\n    `</pre>\r\n\r\n    3.在action.js使用redux-thunk：\r\n\r\n    <pre>`export const getData = (obj) =&gt; (dispatch, getState) =&gt; {\r\n      setTimeout(()=&gt;{\r\n        dispatch({\r\n            type: GET_DATA,\r\n            obj: obj\r\n        });\r\n      },1000);\r\n    };\r\n    `</pre>\r\n\r\n    ## <a id=\"18\"> 使用axios和async/await </a>\r\n\r\n    [axios](https://github.com/axios/axios) 是一个基于Promise 用于浏览器和 nodejs 的 HTTP 客户端：\r\n\r\n*   从浏览器中创建 XMLHttpRequest\r\n*   从 node.js 发出 http 请求\r\n*   支持 Promise API\r\n*   自动转换JSON数据\r\n\r\n    1.安装axios:\r\n\r\n    <pre>`npm install axios --save\r\n    `</pre>\r\n\r\n    2.在action中使用axios：\r\n\r\n    <pre>`import axios from \'axios\';\r\n    export const getData = (obj) =&gt; (dispatch, getState) =&gt; {\r\n        axios.get(\'/json/comments.json\').then((resp)=&gt;{\r\n            dispatch({\r\n                type: GET_DATA,\r\n                obj: resp\r\n            });\r\n        });\r\n    };\r\n    `</pre>\r\n\r\n    [async/await：](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Statements/async_function)\r\n\r\n    Javascript的回调地狱，相信很多人都知道，尤其是在node端，近些年比较流行的是Promise的解决方案，但是随着 Node 7 的发布，编程终级解决方案的 async/await应声而出。\r\n\r\n    <pre>`function resolveAfter2Seconds() {\r\n      return new Promise(resolve =&gt; {\r\n        setTimeout(() =&gt; {\r\n          resolve(\'resolved\');\r\n        }, 2000);\r\n      });\r\n    }\r\n\r\n    async function asyncCall() {\r\n      var result = await resolveAfter2Seconds();\r\n    }\r\n\r\n    asyncCall();`</pre>\r\n\r\n    async/await的用途是简化使用 promises 异步调用的操作，并对一组 Promises执行某些操作。await前提是方法返回的是一个Promise对象，正如Promises类似于结构化回调，async/await类似于组合生成器和 promises。\r\n\r\n    1.async/await需要安装[babel-plugin-transform-async-to-generator](https://www.npmjs.com/package/babel-plugin-transform-async-to-generator)。\r\n\r\n    <pre>`npm install babel-plugin-transform-async-to-generator --save\r\n    `</pre>\r\n\r\n    2.在.babelrc中增加配置：\r\n\r\n    <pre>`\"plugins\": [\r\n        \"transform-async-to-generator\"\r\n    ]\r\n    `</pre>\r\n\r\n    这样做仅仅是将async转换generator，如果你当前的浏览器不支持generator，你将会收到一个Uncaught ReferenceError: regeneratorRuntime is not defined的错误，你需要：\r\n\r\n    3.安装[babel-plugin-transform-runtime](https://www.npmjs.com/package/babel-plugin-transform-runtime):\r\n\r\n    <pre>`npm install babel-plugin-transform-async-to-generator --save\r\n    `</pre>\r\n\r\n    4.修改.babelrc中的配置(可以去掉之前配置的transform-async-to-generator)：\r\n\r\n    <pre>`\"plugins\": [\r\n        \"transform-runtime\"\r\n    ]\r\n    `</pre>\r\n\r\n    5.如果不想引入所有的polyfill(参考上面对babel的解释),可以增加配置：\r\n\r\n    <pre>`\"plugins\": [\r\n        \"transform-runtime\",\r\n            {\r\n                \"polyfill\": false,\r\n\r\n                \"regenerator\": true,\r\n            }\r\n    ]`</pre>\r\n\r\n    6.结合axios使用\r\n\r\n    <pre>`import axios from \'axios\';\r\n    export const getData = (obj) =&gt; async (dispatch, getState) =&gt; {\r\n        let resp = axios.get(\'/json/comments.json\');\r\n        dispatch({\r\n            type: GET_DATA,\r\n            obj: resp\r\n        });\r\n    };\r\n\r\n    `</pre>\r\n\r\n    ## <a id=\"19\"> Code Splitting</a>\r\n\r\n    1.对于webpack1，2之前，你可以使用require.ensure来控制一个组件的懒加载：\r\n\r\n    <pre>`require.ensure([], _require =&gt; {\r\n        let Component = _require(\'./Component.jsx\');\r\n    },\'lazyname\')\r\n    `</pre>\r\n\r\n    2.在webpack4中，官方已经不再推荐使用require.ensure来使用懒加载功能Dynamic Imports，取而代之的是ES6的import()方法：\r\n\r\n    <pre>`import(\r\n      /* webpackChunkName: \"my-chunk-name\" */\r\n      /* webpackMode: \"lazy\" */\r\n      \'module\'\r\n    );\r\n    `</pre>\r\n\r\n    不小小看注释里的代码，webpack在打包时会动态识别这里的代码来做相关的配置，例如chunk name等等。\r\n\r\n    3.[Prefetching/Preloading modules](https://webpack.js.org/guides/code-splitting/#prefetching-preloading-modules):\r\n\r\n    webpack 4.6.0+支持了Prefetching/Preloading的写法:\r\n\r\n    <pre>`import(/* webpackPreload: true */ \'ChartingLibrary\');\r\n    `</pre>\r\n\r\n    3.结合React-Router使用:\r\n\r\n    react-loadable对上述的功能做了封装，丰富了一些功能，结合React-Router起来使用更加方便。\r\n\r\n    <pre>`npm install react-loadable --save\r\n    `</pre>\r\n\r\n    在react-router里使用：\r\n\r\n    <pre>`function Loading() {\r\n      return &lt;div&gt;Loading...&lt;/div&gt;;\r\n    }\r\n\r\n    let Div2 = Loadable({\r\n      loader: () =&gt; import(\'./Div2\'), \r\n      loading: Loading,\r\n    });\r\n\r\n    &lt;Route path=\"/2\" component={Div2}&gt;&lt;/Route&gt;\r\n    `</pre>\r\n\r\n    ## <a id=\"20\"> 使用CommonsChunkPlugin</a>\r\n\r\n    CommonsChunkPlugin 插件，是一个可选的用于建立一个独立文件(又称作 chunk)的功能，这个文件包括多个入口 chunk 的公共模块。通过将公共模块拆出来，最终合成的文件能够在最开始的时候加载一次，便存起来到缓存中供后续使用。\r\n\r\n    1.在webpack4之前的用法：\r\n\r\n    <pre>`new webpack.optimize.CommonsChunkPlugin({\r\n        name: \'common\',\r\n        chunks: [\'page1\',\'page2\'],\r\n        minChunks: 3\r\n    })\r\n    `</pre>\r\n\r\n*   name: string: 提出出的名称\r\n*   chunks: string[]: webpack会从传入的chunk里面提取公共代码,默认从所有entry里提取\r\n*   minChunks: number|infinity|function(module,count)-&gt;boolean: 如果传入数字或infinity(默认值为3)，就是告诉webpack，只有当模块重复的次数大于等于该数字时，这个模块才会被提取出来。当传入为函数时，所有符合条件的chunk中的模块都会被传入该函数做计算，返回true的模块会被提取到目标chunk。\r\n\r\n    更多的参数配置，可以[参考这里](https://webpack.js.org/plugins/commons-chunk-plugin/#src/components/Sidebar/Sidebar.jsx)\r\n\r\n    2.在webpack4之后的用法：\r\n\r\n    <pre>`module.exports = {\r\n      //...\r\n      optimization: {\r\n        splitChunks: {\r\n          chunks: \'async\',\r\n          minSize: 30000,\r\n          minChunks: 1,\r\n          maxAsyncRequests: 5,\r\n          maxInitialRequests: 3,\r\n          automaticNameDelimiter: \'~\',\r\n          name: true,\r\n          cacheGroups: {\r\n            vendors: {\r\n              test: /[\\\\/]node_modules[\\\\/]/,\r\n              priority: -10\r\n            },\r\n            default: {\r\n              minChunks: 2,\r\n              priority: -20,\r\n              reuseExistingChunk: true\r\n            }\r\n          }\r\n        }\r\n      }\r\n    };\r\n\r\n*   splitChunks: 配置一个分离chunk(代替老版本的CommonsChunkPlugin)\r\n*   cacheGroups: 自定义配置主要使用它来决定生成的文件:\r\n*   test: 限制范围\r\n*   name: 生成文件名\r\n*   priority: 优先级\r\n*   minSize: number: 最小尺寸必须大于此值，默认30000B\r\n*   minChunks: 其他entry引用次数大于此值，默认1\r\n*   maxInitialRequests: entry文件请求的chunks不应该超过此值（请求过多，耗时）\r\n*   maxAsyncRequests: 异步请求的chunks不应该超过此值\r\n*   automaticNameDelimiter: 自动命名连接符\r\n*   chunks: 值为”initial”, “async”（默认） 或 “all”:\r\n*   initial: 入口chunk，对于异步导入的文件不处理\r\n*   async: 异步chunk，只对异步导入的文件处理\r\n*   all: 全部chunk\r\n\r\n* * *\r\n\r\n**编辑中可能存在的bug没法实时知道，事后为了解决这些bug,花了大量的时间进行log 调试，这边顺便给大家推荐一个好用的BUG监控工具 [Fundebug](https://www.fundebug.com/?utm_source=xiaozhi)。**\r\n\r\n* * *\r\n\r\n## 交流\r\n\r\n干货系列文章汇总如下，觉得不错点个Star，欢迎 加群 互相学习。\r\n\r\n> [https://github.com/qq44924588...](https://github.com/qq449245884/xiaozhi)\r\n\r\n我是小智，公众号「大迁世界」作者，**对前端技术保持学习爱好者。我会经常分享自己所学所看的干货**，在进阶的路上，共勉！\r\n\r\n关注公众号，后台回复**福利**，即可看到福利，你懂的。\r\n\r\n<span class=\"img-wrap\">![clipboard.png](https://segmentfault.com/img/bVbs6em?w=800&amp;h=400 \"clipboard.png\")</span>', 3, 0, 0, 0);
INSERT INTO `melog_article` VALUES (7, 1, 0, 'DOM 高级工程师不完全指南', '雨思', 'me', '', 63, '技术', '虽然绝大多数前端er都有这样的困扰，但本着基础为大的原则，手撕 DOM 应当是一个前端攻城狮的必备技能，这正是本文诞生的初衷 —— DOM 并没有那么难搞，如果能去充分利用它，那么你离爱上它就不远了。', '> 本文干货部分翻译自: [Use the DOM like a Pro](https://itnext.io/using-the-dom-like-a-pro-163a6c552eba)\r\n> 译者：kyrieliu(劉凯里)\r\n\r\n“前端框架真的太香了，香到我都不敢徒手撕 DOM 了！”\r\n\r\n虽然绝大多数前端er都有这样的困扰，但本着基础为大的原则，手撕 DOM 应当是一个前端攻城狮的必备技能，这正是本文诞生的初衷 —— DOM 并没有那么难搞，如果能去充分利用它，那么你离爱上它就不远了。\r\n\r\n三年前我初入前端坑的时候，发现了一个叫做 jQuery 的宝贝，她有一个神奇的 $ 函数，可以让我快速选中某一个或一组 DOM 元素，并提供链式调用以减少代码的冗余。虽然现在提到 jQuery 这个名词，你会觉得老土，“都 9102 年了你跟我说 Nokia？”。**土归土，但也是真的香。**尽管这几年风生水起的 Vue、React 加剧了 jQuery 的没落，但全世界仍有超过 6600 万个网站在使用 jQuery，占全球所有网站数量的 74%。\r\n\r\njQuery 也给业界留下了产生深远影响的“遗产”，W3C 就仿照其 $ 函数实现了 querySelector 和 querySelectorAll。而讽刺的是，也正是这两个原生方法的出现，大大加快了 jQuery 的没落，因为它们取代了前者最常用的功能 —— 快捷的选择 DOM 元素。\r\n\r\n虽然这两个新方法写起来有点长（问题不大，封装一哈），但是它们是真的贼好用。\r\n\r\n来，冲！\r\n\r\n## 获取 DOM 元素\r\n\r\n### 获取单个元素\r\n\r\n向 document.querySelector 中传入任何有效的 css 选择器，即可选中单个 DOM 元素：\r\n\r\n    document.querySelector(\'.element\')\r\n    document.querySelector(\'#element\')\r\n    document.querySelector(\'div\')\r\n    document.querySelector(\'[name=\"username\"]\')\r\n    document.querySelector(\'div + p &gt; span\')`</pre>\r\n\r\n    如果页面上没有指定的元素时，返回 null\r\n\r\n    ### 获取元素集合\r\n\r\n    使用 document.querySelectorAll 可以获取一个元素集合，它的传参和 document.querySelector 一毛一样。它会返回一个**静态的 NodeList **，如果没有元素被查找到，则会返回一个空的 NodeList 。\r\n\r\n    NodeList 是一个可遍历的对象（aka：伪数组），虽然和数组很像，但它确实不是数组，虽然可以利用 forEach 遍历它，但它并不具备数组的一些方法，比如 map、reduce、find。\r\n\r\n    那么问题来了，**如何将一个伪数组转化为数组呢？**ES6 为开发者提供了两个便利的选择：\r\n\r\n    <pre>`const arr = [...document.querySelectorAll(\'div\')]\r\n    // or\r\n    const alsoArr = Array.from(document.querySelectorAll(\'div\'))`</pre>\r\n\r\n    远古时代，开发者们常用 getElementsByTagName 和 getElementsByClassName 去获取元素集合，但不同于 querySelectorAll，它们获取的是一个**动态的 HTMLCollection**，这就意味着，它的结果会一直随着 DOM 的改变而改变。\r\n\r\n    ### 元素的局部搜索\r\n\r\n    当需要查找元素时，不一定每次都基于 document 去查找。开发者可以在任何 HTMLElement 上进行 DOM 元素的局部搜索：\r\n\r\n    <pre>`const container = document.querySelector(\'#container\')\r\n    container.querySelector(\'#target\')`</pre>\r\n\r\n    ### 打得字太多了啊喂！\r\n\r\n    事实证明，每个优秀的开发者都是很懒的。为了减少对宝贝键盘的损耗，我一般会这么干：\r\n\r\n    <pre>`const $ = document.querySelector.bind(document)`</pre>\r\n\r\n    保护机械键盘，从我做起。\r\n\r\n    ### 少年，爬上这棵 DOM 树\r\n\r\n    上述内容的主题是**查找 DOM 元素**，这是一个自上而下的过程：从父元素向其包含的子元素发起查询。\r\n\r\n    但没有一个 API 可以帮助开发者借由子元素向父元素发起查询。\r\n\r\n    迷惑之际，MDN 给我提供了一个宝藏方法：closest 。\r\n\r\n    > Starting with the [`Element`](https://developer.mozilla.org/en-US/docs/Web/API/Element) itself, the `closest()` method traverses parents (heading toward the document root) of the [`Element`](https://developer.mozilla.org/en-US/docs/Web/API/Element) until it finds a node that matches the provided selectorString. Will return itself or the matching ancestor. If no such element exists, it returns `null`.\r\n\r\n    也就是说，closest 方法可以从特定的 HTMLElement 向上发起查询，找到第一个符合指定 css 表达式的父元素（也可以是元素自身），如果找到了文档根节点还没有找到目标时，就会返回 null 。\r\n\r\n    ## 添加 DOM 元素\r\n\r\n    如果用原生 JavaScript 向 DOM 中添加一个或多个元素，一般开发者的内心都是抗拒的，为啥呢？假设向页面添加一个 a 标签：\r\n\r\n    <pre>`&lt;a href=\"/home\" class=\"active\"&gt;首页&lt;/a&gt;`</pre>\r\n\r\n    正常情况下，需要写出如下的代码：\r\n\r\n    <pre>`const link = document.createElement(\'a\')\r\n    link.setAttribute(\'href\', \'/home\')\r\n    link.className = \'active\'\r\n    link.textContent = \'首页\'\r\n\r\n    // finally\r\n    document.body.appendChild(link)`</pre>\r\n\r\n    真的麻烦。\r\n\r\n    而老大哥 jQuery 可以简化为：\r\n\r\n    <pre>`$(\'body\').append(\'&lt;a href=\"/home\" class=\"active\"&gt;首页&lt;/a&gt;\')`</pre>\r\n\r\n    但，各位观众，如今原生 JavaScript 也可以实现这一操作了：\r\n\r\n    <pre>`document.body.insertAdjacentHTML(\r\n        \'beforeend\',\r\n      \'&lt;a href=\"/home\" class=\"active\"&gt;首页&lt;/a&gt;\'\r\n    )`</pre>\r\n\r\n    这个方法允许你将任何有效的 HTML 字符串插入到一个 DOM 元素的四个位置，这四个位置由方法的第一个参数指定，分别是：\r\n\r\n*   \'beforebegin\': 元素之前\r\n*   \'afterbegin\': 元素内，位于现存的第一个子元素之前\r\n*   \'beforeend\': 元素内，位于现存的最后一个子元素之后\r\n*   \'afterend\': 元素之后\r\n    <pre>`&lt;!-- beforebegin --&gt;\r\n    &lt;div&gt;\r\n        &lt;!-- afterbegin --&gt;\r\n      &lt;span&gt;&lt;/span&gt;\r\n         &lt;!-- beforeend --&gt;\r\n    &lt;/div&gt;\r\n    &lt;!-- afterend --&gt;`</pre>\r\n\r\n    舒服了呀。\r\n\r\n    更舒服的是，它还有两个好兄弟，让开发者可以快速地插入 HTML 元素和字符串：\r\n\r\n    <pre>`// 插入 HTML 元素\r\n    document.body.insertAdjacentElement(\r\n        \'beforeend\',\r\n        document.createElement(\'a\')\r\n    )\r\n\r\n    // 插入文本\r\n    document.body.insertAdjacentText(\'afterbegin\', \'cool!\')`</pre>\r\n\r\n    ## 移动 DOM 元素\r\n\r\n    上面提到的兄弟方法 insertAdjacentElement 也可以用来对已存在的元素进行移动，换句话说：当传入该方法的是已存在于文档中的元素时，该元素仅仅只会被移动（而不是复制并移动）。\r\n\r\n    如果你有以下 HTML：\r\n\r\n    <pre>`&lt;div class=\"first\"&gt;\r\n      &lt;h1&gt;Title&lt;/h1&gt;\r\n    &lt;/div&gt;\r\n\r\n    &lt;div class=\"second\"&gt;\r\n      &lt;h2&gt;Subtitle&lt;/h2&gt;\r\n    &lt;/div&gt;`</pre>\r\n\r\n    然后操作一下，把 `&lt;h2&gt;` 搞到 `&lt;h1&gt;` 的后面去：\r\n\r\n    <pre>`const h1 = document.querySelector(\'h1\')\r\n    const h2 = document.querySelector(\'h2\')\r\n\r\n    h1.insertAdjacentElement(\'afterend\', h2)`</pre>\r\n\r\n    于是我们就得到了这样的结果：\r\n\r\n    <pre>`&lt;div class=\"first\"&gt;\r\n      &lt;h1&gt;Title&lt;/h1&gt;\r\n      &lt;h2&gt;Subtitle&lt;/h2&gt;\r\n    &lt;/div&gt;\r\n\r\n    &lt;div class=\"second\"&gt;\r\n\r\n    &lt;/div&gt;`</pre>\r\n\r\n    ## 替换 DOM 元素\r\n\r\n    replaceChild? 这是几年前的做法了，每当开发者需要替换两个 DOM 元素，除了需要拿到这必须的两个元素之外，还需要获取他们的直接父元素：\r\n\r\n    <pre>`parentNode.replaceChild(newNode, oldNode)`</pre>\r\n\r\n    而如今，开发者们可以使用 replaceWith 就可以完成两个元素之间的替换了：\r\n\r\n    <pre>`oldElement.replaceWith(newElement)`</pre>\r\n\r\n    从用法上来说，要比前者清爽一些。\r\n\r\n    需要注意的是：\r\n\r\n1.  如果传入的 newElement 已经存在于文档中，那么方法的执行结果将是 newElement 被移动并替换掉 oldElement\r\n2.  如果传入的 newElement 是一个字符串，那么它将作为一个 TextNode 替换掉原有的元素\r\n\r\n    ## 移除 DOM 元素\r\n\r\n    和替换元素的老方法相同，移除元素的老方法同样需要获取到目标元素的直接父元素：\r\n\r\n    <pre>`const target = document.querySelector(\'#target\')\r\n    target.parentNode.removeChild(target)`</pre>\r\n\r\n    现在只需要在目标元素上执行一次 remove 方法就 ok 了：\r\n\r\n    <pre>`const target = document.querySelector(\'#target\')\r\n    target.remove()`</pre>\r\n\r\n    ## 用 HTML 字符串创建 DOM 元素\r\n\r\n    细心的你一定发现了，上文提到的 insertAdjacent 方法允许开发者直接将一段 HTML 插入到文档当中，如果我们此刻只想生成一个 DOM 元素以备将来使用呢？\r\n\r\n    DOMParser 对象的 parseFromString 方法即可满足这样的需求。该方法可以实现将一串 HTML 或 XML 字符串转化为一个完整的 DOM 文档，也就是说，当我们需要获得预期的 DOM 元素时，需要从方法返回的 DOM 文档中获取这个元素：\r\n\r\n    <pre>`const createSingleElement = (domString) =&gt; {\r\n        const parser = new DOMParser()\r\n      return parser.parseFromString(domString, \'text/html\').body.firstChild\r\n    }\r\n\r\n    // usage\r\n    const element = createSingleElement(\'&lt;a href=\"./home\"&gt;Home&lt;/a&gt;\')`</pre>\r\n\r\n    ## 做一个检查 DOM 的小能手\r\n\r\n    标准的 DOM API 为开发者们提供了很多便利的方法去检查 DOM 。比如，matches 方法可以判断出一个元素是否匹配一个确定的选择器：\r\n\r\n    <pre>`// &lt;div class=\"say-hi\"&gt;Hello DOM!&lt;/div&gt;\r\n\r\n    const div = document.querySelector(\'div\')\r\n\r\n    div.matches(\'div\')      // true\r\n    div.matches(\'.say-hi\')  // true\r\n    div.matches(\'#hi\')      // false`</pre>\r\n\r\n    contains 方法可以检测出一个元素是否包含另一个元素（或者：一个元素是否是另一个元素的子元素）：\r\n\r\n    <pre>`// &lt;div&gt;&lt;h1&gt;Title&lt;/h1&gt;&lt;/div&gt;\r\n    // &lt;h2&gt;Subtitle&lt;/h2&gt;\r\n\r\n    const $ = document.querySelector.bind(document)\r\n    const div = $(\'div\')\r\n    const h1 = $(\'h1\')\r\n    const h2 = $(\'h2\')\r\n\r\n    div.contains(h1)   // true\r\n    div.contains(h2)   // false`</pre>\r\n\r\n    ### 一招鲜：compareDocumentPosition\r\n\r\n    compareDocumentPosition 是一个强大的 API ，它可以快速判断出两个 DOM 元素的位置关系，诸如：先于、跟随、是否包含。它返回一个整数，代表了两个元素之间的关系。\r\n\r\n    <pre>`// 还是用上面的例子哈\r\n    container.compareDocumentPosition(h1)   // 20\r\n    h1.compareDocumentPosition(container)   // 10\r\n    h1.compareDocumentPosition(h2)          // 4\r\n    h2.compareDocumentPosition(h1)          // 2`</pre>\r\n\r\n    标准语句：\r\n\r\n    <pre>`element.compareDocumentPosition(otherElement)`</pre>\r\n\r\n    返回值定义如下：\r\n\r\n*   1: 两个元素不再同一个文档内\r\n*   2: otherElement 在 element 之前\r\n*   4: otherElement 在 element 之后\r\n*   8: otherElement 包含 element\r\n*   16: otherElement 被 element 所包含\r\n\r\n    那么问题来了，为什么上面例子中第一行的结果是20、第二行的结果是10呢？\r\n\r\n    因为 h1 同时满足“被 container 所包含(16)” 和 “在 container 之后”，所以语句的执行结果是 16+4=20，同理可推出第二条语句的结果是 8+2=10。\r\n\r\n    ## DOM 观察者：MutationObserver\r\n\r\n    在处理用户交互的时候，当前页面的 DOM 元素通常会发生很多变化，而有些场景需要开发者们监听这些变化并在触发后执行相应的操作。MutationObserver 是浏览器提供的一个专门用来监听 DOM 变化的接口，它强大到几乎可以观测到一个元素的所有变化，可观测的对象包括：文本的改变、子节点的添加和移除和任何元素属性的变化。\r\n\r\n    如同往常一样，如果想构造任何一个对象，那就 new 它的构造函数：\r\n\r\n    <pre>`const observer = new MutationObserver(callback)`</pre>\r\n\r\n    传入构造函数的是一个回调函数，它会在被监听的 DOM 元素发生改变时执行，它的两个参数分别是：包含本次所有变更的列表 MutationRecords 和 observer 本身。其中，MutationRecords 的每一条都是一个变更记录，它是一个普通的对象，包含如下常用属性：\r\n\r\n    > *   type: 变更的类型，attributes / characterData / childList\r\n> *   target: 发生变更的 DOM 元素\r\n> *   addedNodes: 新增子元素组成的 NodeList\r\n> *   removedNodes: 已移除子元素组成的的 NodeList\r\n> *   attributeName: 值发生改变的属性名，如果不是属性变更，则返回 null\r\n> *   previousSibling: 被添加或移除的子元素之前的兄弟节点\r\n> *   nextSibling: 被添加或移除的子元素之后的兄弟节点\r\n\r\n    根据目前的信息，可以写一个 callback 函数了：\r\n\r\n    <pre>`const callback = (mutationRecords, observer) =&gt; {\r\n        mutationRecords.forEach({\r\n        type,\r\n        target,\r\n        attributeName,\r\n        oldValue,\r\n        addedNodes,\r\n        removedNodes,\r\n      } =&gt; {\r\n          switch(type) {\r\n          case \'attributes\':\r\n            console.log(`attribute ${attributeName} changed`)\r\n            console.log(`previous value: ${oldValue}`)\r\n            console.log(`current value: ${target.getAttribite(attributeName)}`)\r\n            break\r\n          case \'childList\':\r\n              console.log(\'child nodes changed\')\r\n            console.log(\'added: ${addedNodes}\')\r\n            console.log(\'removed: ${removedNodes}\')\r\n            break\r\n          // ...\r\n        }\r\n      })\r\n    }`</pre>\r\n\r\n    至此，我们有了一个 DOM 观察者 observer，也有了一个完整可用的 DOM 变化后的回调函数 callback，就差一个需要被观测的 DOM 元素了：\r\n\r\n    <pre>`const target = document.querySelector(\'#target\')\r\n    observer.observe(target, {\r\n        attributes: true,\r\n      attributeFilter: [\'class\'],\r\n      attributesOldValue: true,\r\n      childList: true,\r\n    })`</pre>\r\n\r\n    在上面的代码中，我们通过调用观察者对象的 observe 方法，对 id 为 target 的 DOM 元素进行了观测（第一个参数就是需要观测的目标元素），而第二个元素，我们传入了一个**配置对象**：开启对属性的观测 / 只观测 class 属性 / 属性变化时传递属性旧值 / 开启对子元素列表的观测。\r\n\r\n    配置对象支持如下字段：\r\n\r\n    > *   attributes: Boolean，是否监听元素属性的变化\r\n> *   attributeFilter: String[]，需要监听的特定属性名称组成的数组\r\n> *   attributeOldValue: Boolean，当监听元素的属性发生变化时，是否记录并传递属性的上一个值\r\n> *   characterData: Boolean，是否监听目标元素或子元素树中节点所包含的字符数据的变化\r\n> *   characterDataOldValue: Boolean，字符数据发生变化时，是否记录并传递其上一个值\r\n> *   childList: Boolean，是否监听目标元素添加或删除子元素\r\n> *   subtree: Boolean，是否扩展监视范围到目标元素下的整个子树的所有元素\r\n\r\n    当不再监听目标元素的变化时，调用 observer 的 disconnect 方法即可，如果需要的话，可以先调用 observer 的 takeRecords 方法从 observer 的通知队列中删除所有待处理的通知，并将它们返回到一个由 MutationRecord 对象组成的数组当中：\r\n\r\n    <pre>`const mutationRecords = observer.takeRecords()\r\n    callback(mutationRecords)\r\n    observer.disconnect()\r\n\r\n## 怕啥都不要怕 DOM\r\n\r\n尽管大部分 DOM API 的名字都很长（写起来很麻烦），但它们都是非常强大并且通用的。这些 API 往往旨在为开发者提供底层的构建单元，以便在此之上建立更为通用和简洁的抽象逻辑，因此从这个角度出发，它们必须提供一个完整的名称以变得足够明确和清晰。\r\n\r\n只要能发挥出这些 API 本应该发挥出的潜能，多敲几下键盘又何妨呢？\r\n\r\nDOM 是每个 JavsScript 开发者必不可少的知识，因为我们几乎每天都在使用它。莫怕，大胆激发自己操作 DOM 的洪荒之力吧，尽早成为一个 DOM 高级工程师。\r\n\r\n## 最后\r\n\r\n扫码捕获一只还算有趣的前端er\r\n<span class=\"img-wrap\">![扫码捕获一只还算有趣的前端er](/img/bVbA61N \"扫码捕获一只还算有趣的前端er\")</span>', 4, 0, 0, 0);
INSERT INTO `melog_article` VALUES (10, 1, 0, 'HSL&RGB互转', '雨思', 'me', '', 23, '技术', '参考文章 HSL to RGB RGB to HSL hsl转rgb {代码...} 2.rgb转hsl {代码...}', '> 参考文章\r\n\r\n1.  [HSL to RGB](https://www.rapidtables.com/convert/color/hsl-to-rgb.html)\r\n2.  [RGB to HSL](https://www.rapidtables.com/convert/color/rgb-to-hsl.html)\r\n\r\n## hsl转rgb\r\n\r\n    /**\r\n     *\r\n     * @param {Number} H 色相 [0,360)\r\n     * @param {Number} S 饱和度 [0,1]\r\n     * @param {Number} L 亮度 [0,1]\r\n     * @param {Boolean} stringMode 是否返回字符串模式\r\n     */\r\n    function HSL2RGB(H = 0, S = 0, L = 0, stringMode = false) {\r\n      const C = (1 - Math.abs(2 * L - 1)) * S\r\n      const X = C * (1 - Math.abs(((H / 60) % 2) - 1))\r\n      const m = L - C / 2\r\n      const vRGB = []\r\n      if (H &gt;= 0 &amp;&amp; H &lt; 60) {\r\n        vRGB.push(C, X, 0)\r\n      } else if (H &gt;= 60 &amp;&amp; H &lt; 120) {\r\n        vRGB.push(X, C, 0)\r\n      } else if (H &gt;= 120 &amp;&amp; H &lt; 180) {\r\n        vRGB.push(0, C, X)\r\n      } else if (H &gt;= 180 &amp;&amp; H &lt; 240) {\r\n        vRGB.push(0, X, C)\r\n      } else if (H &gt;= 240 &amp;&amp; H &lt; 300) {\r\n        vRGB.push(X, 0, C)\r\n      } else if (H &gt;= 300 &amp;&amp; H &lt; 360) {\r\n        vRGB.push(C, 0, X)\r\n      }\r\n      const [vR, vG, vB] = vRGB\r\n      const R = 255 * (vR + m)\r\n      const G = 255 * (vG + m)\r\n      const B = 255 * (vB + m)\r\n\r\n      if (stringMode) {\r\n        return `rgb(${R},${G},${B})`\r\n      }\r\n\r\n      return { R, G, B }\r\n    }`</pre>\r\n\r\n    ## 2.rgb转hsl\r\n\r\n    <pre>`/**\r\n     * @description rgb转化为hsl\r\n     * @param {Number} R [0,255]\r\n     * @param {Number} G [0,255]\r\n     * @param {Number} B [0,255]\r\n     * @param {Boolean} stringMode 是否返回字符串模式\r\n     */\r\n    function RGB2HSL(R = 0, G = 0, B = 0, stringMode = false) {\r\n      const _R = R / 255;\r\n      const _G = G / 255;\r\n      const _B = B / 255;\r\n      const Cmax = Math.max(_R, _G, _B);\r\n      const Cmin = Math.min(_R, _G, _B);\r\n      const V = Cmax - Cmin;\r\n\r\n      let H = 0;\r\n      if (V === 0) {\r\n        H = 0;\r\n      } else if (Cmax === _R) {\r\n        H = 60 * (((_G - _B) / V) % 6);\r\n      } else if (Cmax === _G) {\r\n        H = 60 * ((_B - _R) / V + 2);\r\n      } else if (Cmax === _B) {\r\n        H = 60 * ((_R - _G) / V + 4);\r\n      }\r\n\r\n      H = Math.floor(backCycle(H, 360));\r\n      const L = numberFixed((Cmax + Cmin) / 2);\r\n      const S = V === 0 ? 0 : numberFixed(V / (1 - Math.abs(2 * L - 1)));\r\n\r\n      if (stringMode) {\r\n        return `hsl(${H},${numberFixed(100 * S)}%,${numberFixed(100 * L)}%)`;\r\n      }\r\n\r\n      return { H, S, L };\r\n    }\r\n\r\n    // utils\r\n    function backCycle(num, cycle) {\r\n      let index = num % cycle;\r\n      if (index &lt; 0) {\r\n        index += cycle;\r\n      }\r\n      return index;\r\n    }\r\n    function numberFixed(num = 0, count = 3) {\r\n      const power = Math.pow(10, count);\r\n      return Math.floor(num * power) / power;\r\n    }\r\n    ', 2, 0, 0, 0);
INSERT INTO `melog_article` VALUES (11, 1, 0, '你知道你对 JSON Web Token 的认识存在误区吗', '雨思', 'me', '', 45, '技术', 'JSON Web Token (JWT) 其实目前已经广为软件开发者所熟知了，但是 JOSE (Javascript Object Signing and Encryption) 却鲜有人知道，我第一次知道它是在 Spring Security 的官方文档中，它改变了我对 JWT 的一些认识。目前国内能找到相关中文资料不是太多。所以我觉得有必要归纳一下。', '<span class=\"img-wrap\">![](/img/remote/1460000021198851)</span>\r\n\r\n## 1.前言\r\n\r\n**JSON Web Token (JWT)** 其实目前已经广为软件开发者所熟知了，但是 **JOSE (Javascript Object Signing and Encryption)** 却鲜有人知道，我第一次知道它是在 **Spring Security** 的官方文档中，它改变了我对 **JWT** 的一些认识。目前国内能找到相关中文资料不是太多。所以我觉得有必要归纳一下。\r\n\r\n## 2. JOSE 概述\r\n\r\n**JOSE** 是一种旨在提供在各方之间安全传递声明（claims）的方法的规范集。我们常用的 **JWT** 就包含了允许客户端访问特定应用下特定资源的声明。**JOSE** 制定了一系列的规范来达到此目的。目前该规范还在不断的发展，我们常用的包含以下几个 **RFC** :\r\n\r\n*   **JWS（RFC 7515）** -JSON Web签名，描述生成和处理签名消息\r\n*   **JWE（RFC 7516）** -JSON Web加密，描述了保护和处理加密 消息\r\n*   **JWK（RFC 7517）** -JSON Web密钥，描述 **Javascript** 对象签名和加密中加密密钥的 格式和处理\r\n*   **JWA（RFC 7518）** -JSON Web算法，描述了 **Javascript** 对象签名和加密中使用的 加密 算法\r\n*   **JWT（RFC 7519）** -JSON Web令牌，描述以 **JSON** 编码并由 **JWS** 或 **JWE** 保护的声明的表示形式\r\n\r\n## 3. 我们都看错了 JWT\r\n\r\n看了对 **JWT** 的描述中提到 “令牌以 **JWS** 或者 **JWE** 声明表示”。莫非我之前的认知是错误的吗？ 找了一些官方的资料研究了一番后，确实我之前的认知是不够全面的。\r\n\r\n官方定义：\r\n\r\n> JSON Web Token (JWT) is a compact URL-safe means of representing claims to be transferred between two parties\r\n\r\n直译过来：JSON Web令牌（JWT）是一种紧凑的URL安全方法，用于表示要在两方之间转移的声明。\r\n\r\n也就是说我们通常说的 **JWT** 实际上是一个对声明进行 **JOSE** 处理方式的统称。我们之前用的应该叫 **JWS(JSON Web Signature)**，是 **JWT** 的一种实现，除了 **JWS** , **JWT** 还有另一种实现 **JWE(JSON Web Encryption)** 。它们之间的关系应该是这样的：\r\n\r\n<span class=\"img-wrap\">![](/img/remote/1460000021198852)</span>\r\n\r\n## 4. 什么是 JWE\r\n\r\n**JWS** 我们就不说了，就是通常我们所说的 **JWT**。包括之前我在 [Spring Security 实战干货](https://www.felord.cn/categories/spring-security/) 中所涉及到的 **JWT** 都是 **JWS**。我们来说一下 **JWE** 。**JWS** 仅仅是对声明(claims)作了签名，保证了其不被篡改，但是其 **payload(中段负载)** 信息是暴露的。也就是 **JWS** 仅仅能保证数据的完整性而不能保证数据不被泄露。所以我以前也说过它不适合传递敏感数据。 \r\n**JWE** 的出现就是为了解决这个问题的。具体的可以看下图：\r\n\r\n<span class=\"img-wrap\">![](/img/remote/1460000021198853)</span>\r\n\r\n从上面可以看出 **JWE** 的生成非常繁琐，作为 Token 可能比较消耗资源和耗时。用作安全的数据传输途径应该不错。\r\n\r\n## 5. Spring Security jose 相关\r\n\r\n这里需要简单提一下 Spring Security 提供了 JOSE 有关的类库 `spring-security-oauth2-jose` ，你可以使用该类库来使用 **JOSE** 。如果 **Java** 开发者要在 **Spring Security** 安全框架中使用 **OAuth2.0** ，这个类库也是需要研究一下的。\r\n\r\n## 6. 总结\r\n\r\n今天我们对 **JOSE** 这个相对陌生的概念进行了认识，对 JOSE 规范集中的几个重要的 **RFC** 进行了列举。对之前的局限性认识也进行了纠正。为我们后续的 **OAuth2.0** 相关学习进行了铺垫。 \r\n\r\n`关注公众号：Felordcn 获取更多资讯`\r\n\r\n[个人博客：https://felord.cn](https://felord.cn)', 3, 0, 0, 0);
INSERT INTO `melog_article` VALUES (16, 1, 0, 'IPv4 地址已耗尽，IPv6 涅槃重生：腾讯云IPv6改造综述', '雨思', 'me', '', 67, '技术', '引言：近日，全球 IPv4 地址正式耗尽的消息刷遍各大技术媒体，IPv6 再一次被推到人们面前。IP，作为网络世界的通行证，其重要性不言而喻。IPv4 地址枯竭，IPv6 作为IPv4地址枯竭的解决方案，其在中国的发展历程是怎样的？产品环环相扣的腾讯云，是如何进行大规模 IPv6 改造的？「云加社区」特别策划「IPv6」系列专题，为...', '引言：近日，全球 IPv4 地址正式耗尽的消息刷遍各大技术媒体，IPv6 再一次被推到人们面前。IP，作为网络世界的通行证，其重要性不言而喻。IPv4 地址枯竭，IPv6 作为IPv4地址枯竭的解决方案，其在中国的发展历程是怎样的？产品环环相扣的腾讯云，是如何进行大规模 IPv6 改造的？「云加社区」特别策划「IPv6」系列专题，为你揭秘。关注「云加社区」公众号，回复“IP”，获取更多内容。（本文作者：秦振华，编辑：尾尾）\r\n\r\n一波三折：IPv6在中国的发展历程\r\nIP，作为网络世界的通行证，其重要性不言而喻。IPv4 在设计之初，没能考虑到后续互联网爆炸式的发展，更没能预测到物联网的发展，其有限的地址空间，必然带来地址枯竭的问题。IPv6能让世界上每一粒沙子都能拥有一个IP，它作为IPv4地址枯竭的解决方案，在20年前就已经和移动互联网一起走进了人们的视线。然而，由于种种原因，IPv6在华夏大地上却未能和移动互联网一起璀璨绽放。如今，5G时代拉开帷幕，国家再次吹响IPv6的集结号。近日，IPv4 地址正式耗尽，这一次，天时地利人和，IPv6必将重新焕发出勃勃生机。\r\n\r\n那么，IPv6在中国的发展历程是怎样的？IPv6能否成为中国下一代互联网的大动脉，为万物互联谱写出美丽的篇章呢？\r\n\r\n1.遥想1999年：不尽如人意\r\nRIPE NCC（负责欧洲、中东和中亚部分地区的地区互联网注册管理机构）于1999 年首次进行IPv6 分配，到2019年正好过去了20年。20年前，IPv6也进入了中国，在随后的几年，国家也曾试图大力推广IPv6，但是却因诸多因素导致IPv6发展不尽人意，IPv6仅在教育网得到了推广和使用，和大众生活息息相关的移动互联网却渐行渐远。中国IPv6的使用率常年维持在2%以下，与全球范围内以及亚太地区IPv6的火热发展之势形成鲜明对比。\r\n\r\n2.回首2017年：《推进互联网协议第六版（IPv6）规模部署行动计划》印发\r\n当大多数人慢慢淡忘IPv6的时候，国家和政府却始终坚持在背后默默的努力。2017年11月，中共中央办公厅 国务院办公厅印发《推进互联网协议第六版（IPv6）规模部署行动计划》：\r\n\r\n“大力发展基于IPv6的下一代互联网，有助于显著提升我国互联网的承载能力和服务水平，更好融入国际互联网，共享全球发展成果，有力支撑经济社会发展，赢得未来发展主动。\r\n\r\n推进IPv6规模部署是互联网技术产业生态的一次全面升级，深刻影响着网络信息技术、产业、应用的创新和变革。大力发展基于IPv6的下一代互联网，有助于提升我国网络信息技术自主创新能力和产业高端发展水平，高效支撑移动互联网、物联网、工业互联网、云计算、大数据、人工智能等新兴领域快速发展，不断催生新技术新业态，促进网络应用进一步繁荣，打造先进开放的下一代互联网技术产业生态。\r\n\r\n加快IPv6规模应用为解决网络安全问题提供了新平台，为提高网络安全管理效率和创新网络安全机制提供了新思路。大力发展基于IPv6的下一代互联网，有助于进一步创新网络安全保障手段，不断完善网络安全保障体系，显著增强网络安全态势感知和快速处置能力，大幅提升重要数据资源和个人信息安全保护水平，进一步增强互联网的安全可信和综合治理能力。”\r\n\r\n3.聚焦2019年：关键事件出现\r\n2018年，当5G已经逐渐成为街头巷尾一个时髦词汇的时候，比5G还重要的IPv6技术却还在角落苦苦挣扎。然而，到了2019年年底，IPv6不再沉默，有了突飞猛进的发展。\r\n\r\n2019年，出现了关于IPv6的几个关键事件：\r\n\r\n2019年4月，工业和信息化部印发了《关于开展2019年IPv6网络就绪专项行动的通知》（下称《通知》），《通知》明确了到2019年底中国IPv6的实现目标。如：获得IPv6地址的LTE终端比例达到90%；获得IPv6地址的固定宽带终端比例达到40%；LTE网络IPv6活跃连接数达到8亿；完成全部13个互联网骨干直联点IPv6改造；公有云厂商完成70%产品的IPv6改造。\r\n2019年7月，南沙开发区管委会和下一代互联网国家工程中心宣布成立的创新中心，并规划在南沙部署运营一台国际IPv6根服务器。\r\n2019年7月，推进IPv6规模部署专家委员会在2019中国互联网大会期间举办了2019中国IPv6发展论坛，并隆重发布了《中国IPv6发展状况》白皮书。\r\n2019年11月，欧洲网络协调中心（RIPE NCC）确认全球所有43亿个IPv4地址已全部分配完毕。\r\n\r\n二、突飞猛进：中国IPv6发展现状\r\n高铁建设八横八纵，而IPv6建设则是云、网、端三管齐下。运营商、公有云厂商、CDN厂商、互联网厂商、政府部门都是本次IPv6改造的中坚力量。大家从最初的观望和懵懂中逐渐变得主动，相互扶持又相互赶超。物联网时代悄然来临之际，处在互联网和5G全球领先位置的中国再次开始了浩浩荡荡的IPv6改造。\r\n\r\n于无声处听惊雷。经过短短两年的努力，中国IPv6改造已经取得了非常巨大的进展，尤其是电信运营商的网络基础设施已经完成了90%的改造，为IPv6的规模部署奠定了坚实的基础。   \r\n\r\n2019年7月，推进IPv6规模部署专家委员会发布的《中国IPv6发展状况报告》显示：\r\n\r\n“截至2019年5月，中国电信、中国移动和中国联通城域网出口总流量达398.43Gbps，LTE核心网总流量达508.87Gbps，骨干直联点总流量达75.74Gbps，国际出入口的IPv6总流量达到80.45Gbps。\r\n\r\n截至2019年6月，我国IPv6活跃用户数已达1.30亿。我国基础电信企业已分配IPv6地址的用户数达12.07亿。”\r\n截止到2019年12月4日，国家IPv6发展监测平台（[https://v6cngi.6aas.com](https://v6cngi.6aas.com)）显示，中国IPv6发展指数已经达到了49.67。\r\n\r\n三、渐入佳境：腾讯云IPv6改造\r\n1.困难重重：腾讯云产品环环相扣，IPv6改造挑战极大\r\n腾讯在IPv6已经具备多年的实践经验和技术积累，是国内IPv6的实践先行者。2011年腾讯和教育网合作搭建了自己的IPv6实验平台，用于旗下各个业务进行IPv6的实验和试点。\r\n\r\n但是，腾讯云的IPv6升级，面临着非常大的挑战：腾讯云有超过50个大类的产品、100多款子产品，涉及计算、存储、网络、数据库、安全、物联网、智能AI和大数据等等，有IaaS类产品，有PaaS类产品，还有SaaS类产品，产品迭代周期快，各个产品又相互依赖，尤其是对网络产品和平台的依赖。最大的难点是不同产品依赖的网络通信架构不同，尤其是对网络产品的依赖，而网络产品又依赖于底层网络，需要环环相扣，纵深前进。\r\n\r\n于是，项目组认真梳理关联关系，制定了详细的Roadmap和实施计划，并逐步按照这个计划执行。腾讯云产品整体改造的Roadmap主要分成了以下四个阶段。\r\n\r\n第1阶段：通过IPv6 NAT64过渡技术，结合DNS支撑IPv6平滑升级\r\n第2阶段：私有网络、子网、云服务器、弹性网卡、负载均衡、内容分发支持双栈\r\n第3阶段：DDoS高防、安全组、IP地址库、WAF、HTTPDNS支持双栈\r\n第4阶段：CDB、COS、API网关等IAAS类，安全、大数据、物联网等PAAS类产品支持双栈\r\n\r\n事实证明，这种纵深的打法非常有效，各个产品改造节奏清晰明快。在2019年6月前，我们完成了私有网络、子网、云服务器、弹性网卡、内容分发等产品的IPv6改造。\r\n\r\n在2019年9月前，我们完成了DDoS高防、安全组、IP地址库、WAF等产品的IPv6改造。\r\n\r\n2.厚积薄发：荣获科学技术一等奖\r\n厚积才能薄发，2019年11月19日，中国通信学会公布2019年“中国通信学会科学技术奖”评选结果，腾讯和中国移动、中国信通院、华为的联合项目《移动互联网IPv6技术攻关及规模应用》荣获一等奖大奖，其中基于IPv4/IPv6双栈的超大型云平台的分布式SDN云网络技术、基于四维一体的双栈智能防御体系DDoS等安全防御技术等创新技术获得高度认可。\r\n\r\n腾讯云目前已完成云主机、VPC网络、负载均衡、域名解析、内容分发、DDoS等40余款的IPv6产品改造工作，并计划在年底完成大数据、物联网、音视频等PaaS产品的IPv6改造。\r\n\r\n业务层面，腾讯云目前已支撑腾讯视频、腾讯新闻、QQ浏览器等云上应用接入IPv6的用户数超过1.5亿，腾讯已经成为全球拥有最多IPv6用户的企业之一。\r\n四、越战越勇：腾讯云平台IPv6改造的挑战与创新\r\n1.挑战\r\n所谓兵马未动，粮草先行，基础网络设施和支撑平台就是我们的粮草。IPv6产品改造前需要完成底层网络的改造。\r\n\r\n2012年腾讯在深圳的BGP出口接入教育网IPv6 BGP，为自有业务提供IPv6服务。后来又在深圳、上海、天津等和运营商进行了对接，用于业务测试。只是当时受限于运营商网络和用户数量低，IPv6业务并没有大规模上量。\r\n\r\n腾讯云目前已开放 25 个地理区域，运营 53 个可用区；仅国内就有数十个BGP出口、几十个园区需要改造，改造的工作量和难度非常大。但是很幸运的是，作为国内最早部署IPv6的先行者之一，腾讯云在核心网络和公网出口改造方面积累了比较多的经验。正是有了这些经验，让我们BGP出口改造进展较快，在2019年年初，已经基本完成国内主要出口的改造。在2019年下半年，我们又启动了部分海外公网出口的改造，力争能够在2019年年底完成部分海外城市的改造和产品上线，让出海企业更早的能够使用IPv6，迎接海外大量的IPv6用户。在BGP出口，我们和运营商通过BGPv6进行对接，而在内部的核心网的MPLS IPv6 VPN采用的是6VPE方案，流量模型和IPv4保持一致。\r\n\r\n在基础网络改造的同时，我们又进行了10个支撑平台的改造。支撑系统包括了管理系统、IPv6自动化部署系统、网络监控系统、服务器监控系统、公网质量探测系统、网络规划建设系统、CMDB资产管理系统。\r\n\r\nIPv6的优势是更大的地址空间和地址长度，但缺点是不易记忆，容易引入配置问题。在大规模基础资源的部署和实施，如果依赖人工方式操作存在明显的弊端。新的IPv6地址智能管理系统，通过可视化的平台和脚本工具实现IPv6地址录入、分配、配置、监控和回收的一体化智能作业；很好的解决了IPv6系统中部署实施和运维的难点，极大的降低整体的TCO。IP地址网管系统，和云平台、CMDB实现了联动，兼容overlay和underlay两部分的地址管理，并实现了基于业务属性的地址自动分配管理。\r\n\r\n不管是IPv6机房自动化交付还是IPv6流量管理，在大型云平台系统中，仍然面临的最大挑战是大流量数据的采集、存储以及多维度的实时分析和展示，同时硬件设备存在厂商差异性，如何能够采用标准的方案进行一体化的操作。所以在IPv6流量监控和数据分析中，首先通过对不同厂商的硬件资源进行适配，将监控和采集标准化；然后引入大规模数据处理设计的Kafka、Spark等数据，对实时分析的各维度数据叠加汇总，通过API和图形化Web界面提供查询服务。\r\n\r\n2.创新\r\n\r\nIPv6升级是大型云平台整体升级的一次非常重要的良机。所以我们不但要升级IPv6，还应该借助IPv6持续创新，解决IPv6的一些挑战，并实现云平台的整体升级。\r\n\r\n在大规模分布式云Overlay网络SDN控制器需要管理成百上千万的计算资源、IP地址资源和路由表项，支撑互联网通信、混合云通信、跨地域通信等多种场景。IPv6地址的引入不仅仅是带来超大规模IP地址数量和路由规格的问题，还对于多场景的通信模式、IP地址分配管理都提出了更多的挑战，因为IPv6不再区分内外网，也不再做NAT；我们基于IPv6开发了下一代SDN控制器，不但解决了IPv4/IPv6双栈网络的多场景通信以及双栈环境下的子机迁移、Fallback机制等，同时也面向IPv6的下一代支撑网络提供更加强大的管控能力，支撑千万级的用户VPC。在Overlay网络封装支持IPv6方面，Overlay包头（比如Vxlan，GRE等）都无法封装具有128bytes的IPv6地址，我们也通过映射技术很好的解决这个问题，并通过大规模分布式的SDN控制器完美的解决了路由表和映射表的规格和性能问题。\r\n\r\n面向IPv6的DDoS攻击、CC攻击和DNS劫持等安全问题，构建四维一体的双栈智能防御体系，自主研发支持IPv6的宙斯盾安全系统。通过云平台统一的API，将DDoS防护检测、网络虚拟防火墙、网关应用层安全代理、云主机IPv6协议层安全进行统一联动，构建四维一体的智能防御系统，实现自动检测、预警、隔离等全方位的安全防护。DDoS防御系统完成了检测中心、接入中心、攻击清洗中心、统一管理中心等多个系统模块的IPv6升级，提供基于应用层的漏洞检测和入侵防护，基于用户的安全接入认证。以往IPv4的DDoS安全检测是联合CMDB基于识别每一个IP地址进行防护策略，无法适应/56的用户IPv6地址空间，每一个用户的安全防护都涉及到2的56次个IP地址的存储和查询。宙斯盾安全系统基于新的大数据系统和IPv6识别算法，按照/56的地址段进行存储和查询，可以极大提升检测查询的速度并减小存储的压力\r\n\r\n在应用端的改造方面，腾讯自研业务积累丰富的经验，并积极向其他同行积极分享经验。在应用层APP改造方案中，腾讯多个自研业务基于Happy Eyeballs进行了优化，通过旁路配置接口，获取后台配置是否需要开启双栈网络优先IPv6的策略。当确认需要优先IPv6优先时，会发起对IPv6与IPv4接入赛马机制，通过配置对IPv6在赛马时进行一定的让步，以便达到IPv6优先的要求。当IPv6赛马胜出后,则用IPv6来请求后台；当IPv6接入访问失败时，则立刻fallback到IPv4访问。\r\n\r\n五、新的开始\r\nIPv6改造已经进入中场，但对于云厂商来说，这仅仅是一个开始，因为我们即将迎来更大规模的IPv6用户和IPv6流量的考验。\r\n\r\n或许此时此刻的你正在使用IPv6网络在阅读这篇文章，世界上最遥远的距离莫过于IPv6已经来到你身边，而你却对他视而不见。\r\n\r\n精彩预告\r\n产品环环相扣的腾讯云，是如何进行大规模 IPv6 改造的？「云加社区」特别策划「IPv6」系列专题，为你揭秘。下一篇内容，将为大家分享腾讯云IPv6私有网络及IPv6负载均衡操作最佳实践，欢迎关注。\r\n\r\n作者简介\r\n秦振华，腾讯云资深产品经理，目前负责腾讯云网络产品的策划工作，致力于推动IPv6、DPDK、智能网卡、100G等下一代网络新技术的落地。\r\n\r\n关注「云加社区」公众号，回复“IP”，获取更多IPv6相关内容。', 4, 0, 0, 0);
INSERT INTO `melog_article` VALUES (17, 1, 0, '医疗数据典型特征及架构发展方向研究', '雨思', 'me', '', 35, '技术', '医疗健康产业目前呈高速发展状态，处在互联网对医疗行业赋能的关键阶段，由于医疗行业数据的隐私性较强，通过传统方式很难获取公开的医疗健康数据进行研究，根据阿里云天池比赛赛题设置研究及提供的脱敏数据集着手进行分析是比较理想的手段。本文的目的在于对医院的信息系统流程进行思考，结合公开数据集对于医疗健康数...', '# 前言\r\n\r\n医疗健康产业目前呈高速发展状态，处在互联网对医疗行业赋能的关键阶段，由于医疗行业数据的隐私性较强，通过传统方式很难获取公开的医疗健康数据进行研究，根据阿里云天池比赛赛题设置研究及提供的脱敏数据集着手进行分析是比较理想的手段。本文的目的在于对医院的信息系统流程进行思考，结合公开数据集对于医疗健康数据特征进行分析，从而得出未来医疗健康产业数据架构模式的发展方向。\r\n\r\n# 医疗健康数据特征\r\n\r\n首先看一下天池比赛近期的两场比赛，都是针对医疗数据进行研究并进行挖掘的，采用脱敏数据，数据来源于实际病例因此参考价值较高：\r\n\r\n<span class=\"img-wrap\">![](/img/bVbA4Ug)</span>\r\n\r\n<span class=\"img-wrap\">![](/img/bVbA4Ui)</span>\r\n\r\n分析两个比赛提供的数据集形式，可以明显感到医疗数据集的特征为数据异构，即因为医疗检测手段的关系，数据图像化比例较高，但是因为训练数据集需要根据患者其他特征包括性别、年龄、身高、体重等进行统筹分析，因此也包含了一部分结构化数据，因此医疗数据集是典型的非结构化数据和结构化数据并存的异构数据集。\r\n\r\n# 常用预测算法分析\r\n\r\n医疗数据所需要的预测结果一般为分类，由于结果的主要目的并非直接作出定性结论而更多的是为医生提供参考因此二分类（即是或不是）和多分类（分为几类）都有实际价值。\r\n\r\n从宫颈癌风险智能诊断比赛要求结果看，初赛恶性细胞检测算法属于二分类问题，而复赛宫颈癌恶性细胞检测分类算法属于多分类问题即需要将检测结果分类成5类典型宫颈癌。\r\n\r\n数据处理方面，需要结合训练集图像输入和医生的手工标注信息和患者特征信息，因此深度学习算法的普遍使用成为必然，由于单张CT图片和标注信息只能属于一个患者因此JSON文件被采用作为记录文件形式是非常合适的，单张CT文件对应单个JSON文件相比结构化表单能够更好的记录数据。\r\n\r\n<span class=\"img-wrap\">![](/img/bVbA4Ur)</span>\r\n\r\n从数据量大小分析，数千份宫颈癌细胞学图片和对应异常鳞状上皮细胞位置标注，每张数据在20倍数字扫描仪下获取，大小300～400M。因此以训练集包含800张图片计算训练数据集大小约为273G，非结构化数据占了绝大部分。\r\n\r\n从心电人机智能大赛比赛要求结果看，心电异常事件分类属于多分类问题即需要将检测结果分类成训练集中的异常事件种类。4万个医疗心电样本。每个样本有8个导联，分别是I，II，V1，V2，V3，V4，V5和V6。单个样本采样频率为500 HZ，长度为10秒，单位电压为4.88微伏（microvolts）。因此在检测设备输出时已经将数据结构化，相比CT图片的特征提取和数据处理并不需要采用深度学习算法，常规数据预处理手段即能满足需求。\r\n\r\n从算法角度进行分析，针对图片进行计算需要用到深度学习算法，各类神经网络中RNN即卷积神经网络被使用频率较高，也是目前图像识别的主流算法。对两个比赛中选手公开的算法进行统计，宫颈癌风险智能诊断比赛所采用的算法几乎全部为基于神经网络的深度学习算法，差异无非是所采用的深度学习框架不同和基于神经网络衍生的算法采用不同。代表数据科学界对于未来非结构化医疗数据所采用的算法大方向上是统一的。心电人机智能大赛采用算法为机器学习分类算法，目前基于决策树的分类算法占据绝对主导地位，在决策树的基础上衍生的机器学习算法如RF即随机森林算法、GBDT算法和LIGHTLGBM算法又占了多数，LIGHTLGBM算法最普遍被使用。\r\n\r\n从交叉验证集调参和测试集验证效果评估来说，面向癌症算法和其他如心脏异常情况算法需要关注的角度不一样，癌症因为检测结果对于病员包括家属心理冲击很大，因此对于测准率和召回率的平衡问题需要非常关注，防止算法过拟合而造成的草木皆兵情况，同时也加大了医生复核的工作量。而心脏异常算法或是其他普通生化指标数据，则过拟合的问题没有那么严重，因为数据的体量到了一定的程度根据大数定理即使过拟合也会逐步的倾向于往较为准确的趋势发展。特别对于心脏异常情况判断，高测准率极其重要，因为数据的实时性强并且随时间变化价值下降速度较快，即使过拟合而误报，能让病员或家属重视总是没有错的。\r\n\r\n# 医疗数据处理架构方案\r\n\r\n根据以上对于医疗健康数据特征、所采用的数据挖掘算法分析结果，对于医疗数据处理所用的架构方案进行研究。\r\n\r\n医疗数据结构化和非结构化并存的特征造成需要使用CPU和GPU结合的异构计算。从医院现实条件来说，非结构化数据的来源主要为放射性检查设备等产生的图像，如CT每张图片的大小就约为350M,而生化指标包括心电指标能够以结构化数据呈现。非结构化数据的处理需要消耗大量GPU计算力，无法在现实情况下要求医院对于本地IDC机房进行大规模扩容并增加GPU集群。因此从架构上来说云-雾-边协同会是比较理想的架构方式。\r\n\r\n#### **1 边缘计算节点**\r\n\r\n各类检测设备附近的计算节点（包括设备自带的和医生查看结果的PC机）构成协同体系内边缘计算节点，但是现有技术条件下边缘计算的计算力相对偏弱，无法要求边缘节点进行大规模图像识别计算，因此边缘计算节点的主要任务是数据清洗并负责向雾端传送，由于医院的检查种类较多，各种报告和图像信息数据格式并不统一，因此预先在边缘端进行数据清洗有助于雾端和云端降低计算压力并帮助医院未来实现统一数据中台可能。\r\n\r\n#### **2 雾计算节点**\r\n\r\n医院现有本地IDC机房可以考虑作为雾计算节点，雾计算节点目前对于医疗行业尤其重要，虽然5G技术在时延上和传输速度上都满足大规模数据传输要求但是由于医院的环境较为复杂，如果边缘计算节点的数据需要直接传送到云端则在网络层会极其依赖无线通信手段，而无线通信特别是5G较高的频率在全方位全覆盖性的边缘计算节点与云端通信过程中是否会对医疗设备产生干扰和其他预料之外的问题需要在实际应用中再研究，短期内，边缘计算节点数据通过有线通信手段传送到雾计算节点是最合适的方法。\r\n\r\n雾计算节点的现实作用非常多，如集中边缘计算节点数据和区分应用场景并进行计算，特别如果个别医院本地IDC服务器集群配置较强则可以就地对于结构化数据进行挖掘、训练模型并进行预测工作而不必传送到云端。此外从通信角度，雾端作为统一数据出口向云端无线传输数据可以最大可能避免无线信号对于医疗设备可能的干扰作用。短期5G未普及情况或者费用较高的情况下可以采用本地IDC与云端专线通信方式作为过渡手段。\r\n\r\n在具有多个院区的医院中，不同地域的本地IDC作为雾端能够进行异地容灾建设。多个本地IDC机房在不同地域互为灾备，确保单一节点故障能够及时迁移确保业务不中断及存储数据的可用性和完整性。\r\n\r\n#### **3 云端**\r\n\r\n云计算平台能够很好的解决医院异构数据计算需求大但又短时间无法配置大规模GPU集群的现实情况，CT等放射性检查设施产生的高清图像文件及其他需要采用深度学习算法的数据可以统一通过雾端传输到云端进行计算，云计算弹性伸缩的优势在面对医院计算力需求随患者数量呈时间性波动的情况时也可以最大可能的减小医院异构计算成本，GPU集群的配置通过弹性伸缩在医院计算力需求大时自动扩充计算节点，而需求小时自动减小集群内虚拟机规模。\r\n\r\n* * *\r\n\r\n本文作者：朱祺\r\n\r\n[阅读原文](https://yq.aliyun.com/articles/737519?utm_content=g_1000091287)\r\n\r\n本文为云栖社区原创内容，未经允许不得转载。', 5, 0, 0, 0);
INSERT INTO `melog_article` VALUES (18, 1, 0, '搭上SpringBoot事务源码分析专车', '雨思', 'me', '', 54, '技术', '专车介绍 该趟专车是开往Spring Boot事务源码分析的专车 专车问题 为什么加上@Transactional注解就可以实现事务？ 分析事务源码之后我们可以学到什么？ 专车名词 事务 程序中通常使用事务来达到数据的一致性，从而避免脏数据 编程式事务 在业务方法开头开启事务，然后对我们的业务进行try-catch，假设没有异常则提交事务...', '## **专车介绍**\r\n\r\n该趟专车是开往Spring Boot事务源码分析的专车\r\n\r\n<span class=\"img-wrap\">![img](/img/remote/1460000021195661 \"img\")</span>\r\n\r\n## **专车问题**\r\n\r\n*   为什么加上@Transactional注解就可以实现事务？\r\n*   分析事务源码之后我们可以学到什么？\r\n\r\n## **专车名词**\r\n\r\n### 事务\r\n\r\n程序中通常使用事务来达到数据的一致性，从而避免脏数据\r\n\r\n### 编程式事务\r\n\r\n在业务方法开头开启事务，然后对我们的业务进行try-catch，假设没有异常则提交事务，如果出现异常，则在catch模块回滚事务\r\n\r\n### 声明式事务由来\r\n\r\n如果采用编程式事务，那么在任何需要事务的地方都要开启事务、try-catch、提交或者回滚事务，会导致重复编码、编写与业务无关的代码。基于Spring Aop思想，我们可以利用Aop的方式，对需要使用事务的方法进行增强，将公用的部分提取出来，那么就实现了声明式事务。\r\n\r\n### Spring提供的声明式事务\r\n\r\n在需要使用事务的业务方法上添加@Transactional注解，那么就可以使用事务的特性，要么成功，要么失败\r\n\r\n### Spring Aop核心概念\r\n\r\n*   切面：切面是由切点和通知组成\r\n*   切点：用来匹配符合条件类或方法\r\n*   通知：需要执行的操作\r\n\r\n## **专车分析**\r\n\r\n基于Spring Boot自动配置原理，我们应该寻找xxxAutoConfiguration自动配置类，此处要寻找和事务相关的，那么自然是TransactionAutoConfiguration\r\n\r\n### 自动配置\r\n\r\n打开TransactionAutoConfiguration自动配置类\r\n\r\n    @Configuration\r\n    @ConditionalOnBean(PlatformTransactionManager.class)\r\n    @ConditionalOnMissingBean(AbstractTransactionManagementConfiguration.class)\r\n    public static class EnableTransactionManagementConfiguration {\r\n\r\n        @Configuration\r\n        @EnableTransactionManagement(proxyTargetClass = false)\r\n        @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"false\", matchIfMissing = false)\r\n        public static class JdkDynamicAutoProxyConfiguration {\r\n\r\n        }\r\n\r\n        @Configuration\r\n        @EnableTransactionManagement(proxyTargetClass = true)\r\n        @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"true\", matchIfMissing = true)\r\n        public static class CglibAutoProxyConfiguration {\r\n\r\n        }\r\n\r\n    }`</pre>\r\n\r\n    可以看到开启事务管理器的注解@EnableTransactionManagement\r\n\r\n    <pre>`@Target(ElementType.TYPE)\r\n    @Retention(RetentionPolicy.RUNTIME)\r\n    @Documented\r\n    @Import(TransactionManagementConfigurationSelector.class)\r\n    public @interface EnableTransactionManagement {}`</pre>\r\n\r\n    查看TransactionManagementConfigurationSelector导入的类\r\n\r\n    <pre>`protected String[] selectImports(AdviceMode adviceMode) {\r\n        switch (adviceMode) {\r\n            case PROXY:\r\n                return new String[] {AutoProxyRegistrar.class.getName(),\r\n                        ProxyTransactionManagementConfiguration.class.getName()};\r\n            case ASPECTJ:\r\n                return new String[] {determineTransactionAspectClass()};\r\n            default:\r\n                return null;\r\n        }\r\n    }`</pre>\r\n\r\n    可以看到导入了AutoProxyRegistrar和ProxyTransactionManagementConfiguration\r\n\r\n    首先看看AutoProxyRegistrar，该类实现了ImportBeanDefinitionRegistrar\r\n\r\n    <pre>`public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {\r\n        boolean candidateFound = false;\r\n        Set&lt;String&gt; annoTypes = importingClassMetadata.getAnnotationTypes();\r\n        for (String annoType : annoTypes) {\r\n            AnnotationAttributes candidate = AnnotationConfigUtils.attributesFor(importingClassMetadata, annoType);\r\n            if (candidate == null) {\r\n                continue;\r\n            }\r\n            Object mode = candidate.get(\"mode\");\r\n            Object proxyTargetClass = candidate.get(\"proxyTargetClass\");\r\n            if (mode != null &amp;&amp; proxyTargetClass != null &amp;&amp; AdviceMode.class == mode.getClass() &amp;&amp;\r\n                    Boolean.class == proxyTargetClass.getClass()) {\r\n                candidateFound = true;\r\n                if (mode == AdviceMode.PROXY) {\r\n                    // 注册自动代理创建器\r\n                    AopConfigUtils.registerAutoProxyCreatorIfNecessary(registry);\r\n                    if ((Boolean) proxyTargetClass) {\r\n                        AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);\r\n                        return;\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }`</pre>\r\n\r\n    注册自动代理创建器，AopConfigUtils#registerAutoProxyCreatorIfNecessary\r\n\r\n    <pre>`public static BeanDefinition registerAutoProxyCreatorIfNecessary(\r\n                BeanDefinitionRegistry registry, @Nullable Object source) {\r\n        // 注册了InfrastructureAdvisorAutoProxyCreator到IOC容器中\r\n        return registerOrEscalateApcAsRequired(InfrastructureAdvisorAutoProxyCreator.class, registry, source);\r\n    }`</pre>\r\n\r\n    InfrastructureAdvisorAutoProxyCreator是AbstractAutoProxyCreator的子类，AbstractAutoProxyCreator又实现了BeanPostProcessor接口，那么在bean初始化完毕后就会调用postProcessAfterInstantiation()方法，postProcessAfterInstantiation()定义在AbstractAutoProxyCreator类中\r\n\r\n    ### BeanPostProcessor后置处理\r\n\r\n    打开AbstractAutoProxyCreator\r\n\r\n    <pre>`@Override\r\n    public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) {\r\n        if (bean != null) {\r\n            Object cacheKey = getCacheKey(bean.getClass(), beanName);\r\n            if (!this.earlyProxyReferences.contains(cacheKey)) {\r\n                // 如果满足条件对bean进行包裹\r\n                return wrapIfNecessary(bean, beanName, cacheKey);\r\n            }\r\n        }\r\n        return bean;\r\n    }`</pre>\r\n\r\n    该方法调用了wrapIfNecessary()方法\r\n\r\n    <pre>`protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) {\r\n        // Create proxy if we have advice.\r\n          // 获取bean的切面和通知\r\n        Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);\r\n          // 需要代理\r\n        if (specificInterceptors != DO_NOT_PROXY) {\r\n            this.advisedBeans.put(cacheKey, Boolean.TRUE);\r\n            // 创建代理\r\n            Object proxy = createProxy(\r\n                    bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));\r\n            this.proxyTypes.put(cacheKey, proxy.getClass());\r\n            return proxy;\r\n        }\r\n\r\n        this.advisedBeans.put(cacheKey, Boolean.FALSE);\r\n        return bean;\r\n    }`</pre>\r\n\r\n    根据注释的意思就是如果存在advice，那么就创建代理，\r\n\r\n    ### 寻找切面\r\n\r\n    进入AbstractAdvisorAutoProxyCreator#getAdvicesAndAdvisorsForBean\r\n\r\n    <pre>`protected Object[] getAdvicesAndAdvisorsForBean(\r\n                Class&lt;?&gt; beanClass, String beanName, @Nullable TargetSource targetSource) {\r\n        // 查找符合条件的切面\r\n        List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName);\r\n        // 不存在符合条件的切面，则不生成代理\r\n        if (advisors.isEmpty()) {\r\n            return DO_NOT_PROXY;\r\n        }\r\n        return advisors.toArray();\r\n    }`</pre>\r\n\r\n    该代码第一句最重要，如果不存在符合条件的切面，那么最终的结果返回null，根据上面分析的，如果为null就不创建代理，否则创建代理。接下来看看第一句的实现\r\n\r\n    <pre>`protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) {\r\n        // 获取所有候选的切面，也就是类型为Advisor的切面，此处获取到的候选切面为BeanFactoryTransactionAttributeSourceAdvisor\r\n        List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors();\r\n        // 从候选的切面中获取可以解析当前bean的切面，最终符合条件的切面为BeanFactoryTransactionAttributeSourceAdvisor\r\n        List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName);\r\n        extendAdvisors(eligibleAdvisors);\r\n        if (!eligibleAdvisors.isEmpty()) {\r\n            eligibleAdvisors = sortAdvisors(eligibleAdvisors);\r\n        }\r\n        return eligibleAdvisors;\r\n    }\r\n    `</pre>\r\n\r\n    为什么上面获取到的切面是BeanFactoryTransactionAttributeSourceAdvisor？是否还记得之前导入配置类的时候还有一个配置类没有分析？那就是ProxyTransactionManagementConfiguration\r\n\r\n    打开ProxyTransactionManagementConfiguration\r\n\r\n    <pre>`@Configuration\r\n    public class ProxyTransactionManagementConfiguration extends AbstractTransactionManagementConfiguration {\r\n\r\n        // 创建BeanFactoryTransactionAttributeSourceAdvisor\r\n        @Bean(name = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME)\r\n        @Role(BeanDefinition.ROLE_INFRASTRUCTURE)\r\n        public BeanFactoryTransactionAttributeSourceAdvisor transactionAdvisor() {\r\n            BeanFactoryTransactionAttributeSourceAdvisor advisor = new BeanFactoryTransactionAttributeSourceAdvisor();\r\n            advisor.setTransactionAttributeSource(transactionAttributeSource());\r\n            // 设置切面对应的通知，后面分析会用到\r\n            advisor.setAdvice(transactionInterceptor());\r\n            if (this.enableTx != null) {\r\n                advisor.setOrder(this.enableTx.&lt;Integer&gt;getNumber(\"order\"));\r\n            }\r\n            return advisor;\r\n        }\r\n\r\n        @Bean\r\n        @Role(BeanDefinition.ROLE_INFRASTRUCTURE)\r\n        public TransactionAttributeSource transactionAttributeSource() {\r\n            return new AnnotationTransactionAttributeSource();\r\n        }\r\n\r\n        // 创建通知\r\n        @Bean\r\n        @Role(BeanDefinition.ROLE_INFRASTRUCTURE)\r\n        public TransactionInterceptor transactionInterceptor() {\r\n            TransactionInterceptor interceptor = new TransactionInterceptor();\r\n            interceptor.setTransactionAttributeSource(transactionAttributeSource());\r\n            if (this.txManager != null) {\r\n                interceptor.setTransactionManager(this.txManager);\r\n            }\r\n            return interceptor;\r\n        }\r\n\r\n    }\r\n    `</pre>\r\n\r\n    通过上面的自动配置，可得知获取到的候选切面为什么是BeanFactoryTransactionAttributeSourceAdvisor\r\n\r\n    接下来看看如何从候选切面中找到可以解析当前bean的切面？\r\n\r\n    <pre>`protected List&lt;Advisor&gt; findAdvisorsThatCanApply(\r\n                List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; beanClass, String beanName) {\r\n\r\n        ProxyCreationContext.setCurrentProxiedBeanName(beanName);\r\n        try {\r\n            // 查找可以解析当前bean对应的切面\r\n            return AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass);\r\n        }\r\n        finally {\r\n            ProxyCreationContext.setCurrentProxiedBeanName(null);\r\n        }\r\n    }\r\n    `</pre>\r\n\r\n    查找可以解析当前bean对应的切面，AopUtils#findAdvisorsThatCanApply\r\n\r\n    <pre>`public static List&lt;Advisor&gt; findAdvisorsThatCanApply(List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; clazz) {\r\n        if (candidateAdvisors.isEmpty()) {\r\n            return candidateAdvisors;\r\n        }\r\n        List&lt;Advisor&gt; eligibleAdvisors = new ArrayList&lt;&gt;();\r\n        for (Advisor candidate : candidateAdvisors) {\r\n            if (candidate instanceof IntroductionAdvisor &amp;&amp; canApply(candidate, clazz)) {\r\n                eligibleAdvisors.add(candidate);\r\n            }\r\n        }\r\n        boolean hasIntroductions = !eligibleAdvisors.isEmpty();\r\n        for (Advisor candidate : candidateAdvisors) {\r\n            if (candidate instanceof IntroductionAdvisor) {\r\n                // already processed\r\n                continue;\r\n            }\r\n            // 当前切面是否可以解析bean\r\n            if (canApply(candidate, clazz, hasIntroductions)) {\r\n                eligibleAdvisors.add(candidate);\r\n            }\r\n        }\r\n        return eligibleAdvisors;\r\n    }\r\n    `</pre>\r\n\r\n    候选切面是否可以解析bean\r\n\r\n    <pre>`public static boolean canApply(Advisor advisor, Class&lt;?&gt; targetClass, boolean hasIntroductions) {\r\n        if (advisor instanceof IntroductionAdvisor) {\r\n            return ((IntroductionAdvisor) advisor).getClassFilter().matches(targetClass);\r\n        }\r\n        else if (advisor instanceof PointcutAdvisor) {\r\n            // 由上面分析知道最终的候选切面为BeanFactoryTransactionAttributeSourceAdvisor\r\n            // 该类实现了PointcutAdvisor\r\n            PointcutAdvisor pca = (PointcutAdvisor) advisor;\r\n            return canApply(pca.getPointcut(), targetClass, hasIntroductions);\r\n        }\r\n        else {\r\n            // It doesn\'t have a pointcut so we assume it applies.\r\n            return true;\r\n        }\r\n    }\r\n    `</pre>\r\n\r\n    候选切面是否可以解析bean\r\n\r\n    <pre>`public static boolean canApply(Pointcut pc, Class&lt;?&gt; targetClass, boolean hasIntroductions) {\r\n        Assert.notNull(pc, \"Pointcut must not be null\");\r\n        if (!pc.getClassFilter().matches(targetClass)) {\r\n            return false;\r\n        }\r\n\r\n        // 获取切面切点方法匹配对象，用来匹配方法是否符合\r\n        MethodMatcher methodMatcher = pc.getMethodMatcher();\r\n        if (methodMatcher == MethodMatcher.TRUE) {\r\n            // No need to iterate the methods if we\'re matching any method anyway...\r\n            return true;\r\n        }\r\n\r\n        IntroductionAwareMethodMatcher introductionAwareMethodMatcher = null;\r\n        if (methodMatcher instanceof IntroductionAwareMethodMatcher) {\r\n            introductionAwareMethodMatcher = (IntroductionAwareMethodMatcher) methodMatcher;\r\n        }\r\n\r\n        Set&lt;Class&lt;?&gt;&gt; classes = new LinkedHashSet&lt;&gt;();\r\n        if (!Proxy.isProxyClass(targetClass)) {\r\n            classes.add(ClassUtils.getUserClass(targetClass));\r\n        }\r\n        classes.addAll(ClassUtils.getAllInterfacesForClassAsSet(targetClass));\r\n\r\n        for (Class&lt;?&gt; clazz : classes) {\r\n            // 通过反射获取当前类所有的Method对象\r\n            Method[] methods = ReflectionUtils.getAllDeclaredMethods(clazz);\r\n            for (Method method : methods) {\r\n                if (introductionAwareMethodMatcher != null ?\r\n                        introductionAwareMethodMatcher.matches(method, targetClass, hasIntroductions) :\r\n                        // 匹配方法是否符合\r\n                        methodMatcher.matches(method, targetClass)) {\r\n                    return true;\r\n                }\r\n            }\r\n        }\r\n\r\n        return false;\r\n    }\r\n    `</pre>\r\n\r\n    匹配方法TransactionAttributeSourcePointcut#matches\r\n\r\n    <pre>`public boolean matches(Method method, Class&lt;?&gt; targetClass) {\r\n        if (TransactionalProxy.class.isAssignableFrom(targetClass) ||\r\n                PlatformTransactionManager.class.isAssignableFrom(targetClass) ||\r\n                PersistenceExceptionTranslator.class.isAssignableFrom(targetClass)) {\r\n            return false;\r\n        }\r\n        TransactionAttributeSource tas = getTransactionAttributeSource();\r\n        // 如果事务属性源对象为空或者事务属性对象不为null返回true，代表匹配成功；否则返回false，匹配失败\r\n        return (tas == null || tas.getTransactionAttribute(method, targetClass) != null);\r\n    }\r\n    `</pre>\r\n\r\n    获取事务属性对象，AbstractFallbackTransactionAttributeSource#getTransactionAttribute\r\n\r\n    <pre>`public TransactionAttribute getTransactionAttribute(Method method, @Nullable Class&lt;?&gt; targetClass) {\r\n        if (method.getDeclaringClass() == Object.class) {\r\n            return null;\r\n        }\r\n\r\n        // First, see if we have a cached value.\r\n        Object cacheKey = getCacheKey(method, targetClass);\r\n        TransactionAttribute cached = this.attributeCache.get(cacheKey);\r\n        if (cached != null) {\r\n            // Value will either be canonical value indicating there is no transaction attribute,\r\n            // or an actual transaction attribute.\r\n            if (cached == NULL_TRANSACTION_ATTRIBUTE) {\r\n                return null;\r\n            }\r\n            else {\r\n                return cached;\r\n            }\r\n        }\r\n        else {\r\n            // 计算事务属性对象\r\n            TransactionAttribute txAttr = computeTransactionAttribute(method, targetClass);\r\n            // Put it in the cache.\r\n            if (txAttr == null) {\r\n                this.attributeCache.put(cacheKey, NULL_TRANSACTION_ATTRIBUTE);\r\n            }\r\n            else {\r\n                String methodIdentification = ClassUtils.getQualifiedMethodName(method, targetClass);\r\n                if (txAttr instanceof DefaultTransactionAttribute) {\r\n                    ((DefaultTransactionAttribute) txAttr).setDescriptor(methodIdentification);\r\n                }\r\n                if (logger.isTraceEnabled()) {\r\n                    logger.trace(\"Adding transactional method \'\" + methodIdentification + \"\' with attribute: \" + txAttr);\r\n                }\r\n                this.attributeCache.put(cacheKey, txAttr);\r\n            }\r\n            return txAttr;\r\n        }\r\n    }\r\n    `</pre>\r\n\r\n    计算事务属性对象\r\n\r\n    <pre>`protected TransactionAttribute computeTransactionAttribute(Method method, @Nullable Class&lt;?&gt; targetClass) {\r\n        // Don\'t allow no-public methods as required.\r\n        if (allowPublicMethodsOnly() &amp;&amp; !Modifier.isPublic(method.getModifiers())) {\r\n            return null;\r\n        }\r\n\r\n        // The method may be on an interface, but we need attributes from the target class.\r\n        // If the target class is null, the method will be unchanged.\r\n        Method specificMethod = AopUtils.getMostSpecificMethod(method, targetClass);\r\n\r\n        // First try is the method in the target class.\r\n        // 首先根据Method对象获取事务属性对象\r\n        TransactionAttribute txAttr = findTransactionAttribute(specificMethod);\r\n        if (txAttr != null) {\r\n            return txAttr;\r\n        }\r\n\r\n        // Second try is the transaction attribute on the target class.\r\n        // 如果根据Method对象获取不到事务属性对象，那么根据Class来获取属性对象\r\n        txAttr = findTransactionAttribute(specificMethod.getDeclaringClass());\r\n        if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) {\r\n            return txAttr;\r\n        }\r\n\r\n        if (specificMethod != method) {\r\n            // Fallback is to look at the original method.\r\n            txAttr = findTransactionAttribute(method);\r\n            if (txAttr != null) {\r\n                return txAttr;\r\n            }\r\n            // Last fallback is the class of the original method.\r\n            txAttr = findTransactionAttribute(method.getDeclaringClass());\r\n            if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) {\r\n                return txAttr;\r\n            }\r\n        }\r\n\r\n        return null;\r\n    }\r\n    `</pre>\r\n\r\n    获取属性对象AnnotationTransactionAttributeSource#findTransactionAttribute\r\n\r\n    <pre>`protected TransactionAttribute findTransactionAttribute(Class&lt;?&gt; clazz) {\r\n        return determineTransactionAttribute(clazz);\r\n    }\r\n    `</pre>\r\n\r\n    决定事务属性对象\r\n\r\n    <pre>`protected TransactionAttribute determineTransactionAttribute(AnnotatedElement element) {\r\n        for (TransactionAnnotationParser annotationParser : this.annotationParsers) {\r\n            TransactionAttribute attr = annotationParser.parseTransactionAnnotation(element);\r\n            if (attr != null) {\r\n                return attr;\r\n            }\r\n        }\r\n        return null;\r\n    }\r\n    `</pre>\r\n\r\n    解析事务属性对象，SpringTransactionAnnotationParser#parseTransactionAnnotation\r\n\r\n    <pre>`public TransactionAttribute parseTransactionAnnotation(AnnotatedElement element) {\r\n        // 判断元素是否含有@Transactional注解，通过前面的分析我们可以得出如下结论：\r\n        // 1、首选判断类的方法上是否含有@Transactional注解，如果有就解析\r\n        // 2、如果所有的方法都不含有@Transactional注解，那么判断当前类是否含有@Transactional注解，如果有就解析\r\n        // 3、如果类或者类的某个方法含有@Transactional注解，那么事务属性对象就不为空，则说明次切面可以解析当前bean\r\n        AnnotationAttributes attributes = AnnotatedElementUtils.findMergedAnnotationAttributes(\r\n                element, Transactional.class, false, false);\r\n        if (attributes != null) {\r\n            return parseTransactionAnnotation(attributes);\r\n        }\r\n        else {\r\n            return null;\r\n        }\r\n    }\r\n    `</pre>\r\n\r\n    回到AbstractAutoProxyCreator#wrapIfNecessary\r\n\r\n    <pre>`protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) {\r\n        if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) {\r\n            return bean;\r\n        }\r\n        if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) {\r\n            return bean;\r\n        }\r\n        if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) {\r\n            this.advisedBeans.put(cacheKey, Boolean.FALSE);\r\n            return bean;\r\n        }\r\n\r\n        // Create proxy if we have advice.\r\n        // 此处有值返回，进行代理，否则不进行代理\r\n        Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);\r\n        // 需要进行代理\r\n        if (specificInterceptors != DO_NOT_PROXY) {\r\n            this.advisedBeans.put(cacheKey, Boolean.TRUE);\r\n            // 创建代理\r\n            Object proxy = createProxy(\r\n                    bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));\r\n            this.proxyTypes.put(cacheKey, proxy.getClass());\r\n            return proxy;\r\n        }\r\n\r\n        this.advisedBeans.put(cacheKey, Boolean.FALSE);\r\n        return bean;\r\n    }\r\n    `</pre>\r\n\r\n    ### 创建代理\r\n\r\n    创建代理AbstractAutoProxyCreator#createProxy\r\n\r\n    <pre>`protected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName,\r\n                @Nullable Object[] specificInterceptors, TargetSource targetSource) {\r\n\r\n        if (this.beanFactory instanceof ConfigurableListableBeanFactory) {\r\n            AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass);\r\n        }\r\n\r\n        // 创建代理工厂\r\n        ProxyFactory proxyFactory = new ProxyFactory();\r\n        proxyFactory.copyFrom(this);\r\n\r\n        if (!proxyFactory.isProxyTargetClass()) {\r\n            if (shouldProxyTargetClass(beanClass, beanName)) {\r\n                proxyFactory.setProxyTargetClass(true);\r\n            }\r\n            else {\r\n                evaluateProxyInterfaces(beanClass, proxyFactory);\r\n            }\r\n        }\r\n\r\n        // 构建切面，此处的切面为BeanFactoryTransactionAttributeSourceAdvisor\r\n        Advisor[] advisors = buildAdvisors(beanName, specificInterceptors);\r\n        // 设置切面\r\n        proxyFactory.addAdvisors(advisors);\r\n        proxyFactory.setTargetSource(targetSource);\r\n        customizeProxyFactory(proxyFactory);\r\n\r\n        proxyFactory.setFrozen(this.freezeProxy);\r\n        if (advisorsPreFiltered()) {\r\n            proxyFactory.setPreFiltered(true);\r\n        }\r\n\r\n        return proxyFactory.getProxy(getProxyClassLoader());\r\n    }\r\n    `</pre>\r\n\r\n    获取代理ProxyFactory#getProxy\r\n\r\n    <pre>`public Object getProxy(@Nullable ClassLoader classLoader) {\r\n        return createAopProxy().getProxy(classLoader);\r\n    }\r\n    `</pre>\r\n\r\n    创建aop代理\r\n\r\n    <pre>`protected final synchronized AopProxy createAopProxy() {\r\n        if (!this.active) {\r\n            activate();\r\n        }\r\n        // 此处的this实际上就是ProxyFactory\r\n        return getAopProxyFactory().createAopProxy(this);\r\n    }\r\n    `</pre>\r\n\r\n    aop代理工厂创建aop代理DefaultAopProxyFactory#createAopProxy\r\n\r\n    <pre>`public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException {\r\n        if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) {\r\n            Class&lt;?&gt; targetClass = config.getTargetClass();\r\n            if (targetClass == null) {\r\n                throw new AopConfigException(\"TargetSource cannot determine target class: \" +\r\n                        \"Either an interface or a target is required for proxy creation.\");\r\n            }\r\n            if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) {\r\n                return new JdkDynamicAopProxy(config);\r\n            }\r\n            // 创建cglib aop代理\r\n            return new ObjenesisCglibAopProxy(config);\r\n        }\r\n        else {\r\n            return new JdkDynamicAopProxy(config);\r\n        }\r\n    }\r\n    `</pre>\r\n\r\n    实例化ObjenesisCglibAopProxy对象\r\n\r\n    <pre>`public ObjenesisCglibAopProxy(AdvisedSupport config) {\r\n        super(config);\r\n    }\r\n    `</pre>\r\n\r\n    父类实例化\r\n\r\n    <pre>`public CglibAopProxy(AdvisedSupport config) throws AopConfigException {\r\n        Assert.notNull(config, \"AdvisedSupport must not be null\");\r\n        if (config.getAdvisors().length == 0 &amp;&amp; config.getTargetSource() == AdvisedSupport.EMPTY_TARGET_SOURCE) {\r\n            throw new AopConfigException(\"No advisors and no TargetSource specified\");\r\n        }\r\n        // 此处的config就是之前的ProxyFactory\r\n        this.advised = config;\r\n        this.advisedDispatcher = new AdvisedDispatcher(this.advised);\r\n    }\r\n    `</pre>\r\n\r\n    回到之前获取代理的地方\r\n\r\n    <pre>`public Object getProxy(@Nullable ClassLoader classLoader) {\r\n        return createAopProxy().getProxy(classLoader);\r\n    }\r\n    `</pre>\r\n\r\n    通过上面的分析可以得知createAopProxy()返回的是CglibAopProxy\r\n\r\n    通过CglibAopProxy获取代理，CglibAopProxy#getProxy\r\n\r\n    <pre>`public Object getProxy(@Nullable ClassLoader classLoader) {\r\n        if (logger.isTraceEnabled()) {\r\n            logger.trace(\"Creating CGLIB proxy: \" + this.advised.getTargetSource());\r\n        }\r\n\r\n        try {\r\n            Class&lt;?&gt; rootClass = this.advised.getTargetClass();\r\n            Assert.state(rootClass != null, \"Target class must be available for creating a CGLIB proxy\");\r\n\r\n            Class&lt;?&gt; proxySuperClass = rootClass;\r\n            if (ClassUtils.isCglibProxyClass(rootClass)) {\r\n                proxySuperClass = rootClass.getSuperclass();\r\n                Class&lt;?&gt;[] additionalInterfaces = rootClass.getInterfaces();\r\n                for (Class&lt;?&gt; additionalInterface : additionalInterfaces) {\r\n                    this.advised.addInterface(additionalInterface);\r\n                }\r\n            }\r\n\r\n            // Validate the class, writing log messages as necessary.\r\n            validateClassIfNecessary(proxySuperClass, classLoader);\r\n\r\n            // Configure CGLIB Enhancer...\r\n            // 创建Enhancer对象\r\n            Enhancer enhancer = createEnhancer();\r\n            if (classLoader != null) {\r\n                enhancer.setClassLoader(classLoader);\r\n                if (classLoader instanceof SmartClassLoader &amp;&amp;\r\n                        ((SmartClassLoader) classLoader).isClassReloadable(proxySuperClass)) {\r\n                    enhancer.setUseCache(false);\r\n                }\r\n            }\r\n            // 设置父类\r\n            enhancer.setSuperclass(proxySuperClass);\r\n            // 设置接口\r\n            enhancer.setInterfaces(AopProxyUtils.completeProxiedInterfaces(this.advised));\r\n            enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE);\r\n            enhancer.setStrategy(new ClassLoaderAwareUndeclaredThrowableStrategy(classLoader));\r\n\r\n            // 获取回调，重点分析\r\n            Callback[] callbacks = getCallbacks(rootClass);\r\n            Class&lt;?&gt;[] types = new Class&lt;?&gt;[callbacks.length];\r\n            for (int x = 0; x &lt; types.length; x++) {\r\n                types[x] = callbacks[x].getClass();\r\n            }\r\n            // fixedInterceptorMap only populated at this point, after getCallbacks call above\r\n            enhancer.setCallbackFilter(new ProxyCallbackFilter(\r\n                    this.advised.getConfigurationOnlyCopy(), this.fixedInterceptorMap, this.fixedInterceptorOffset));\r\n            // 设置回调类型\r\n            enhancer.setCallbackTypes(types);\r\n\r\n            // Generate the proxy class and create a proxy instance.\r\n            // 生成代理并创建代理实例\r\n            return createProxyClassAndInstance(enhancer, callbacks);\r\n        }\r\n        catch (CodeGenerationException | IllegalArgumentException ex) {\r\n            throw new AopConfigException(\"Could not generate CGLIB subclass of \" + this.advised.getTargetClass() +\r\n                    \": Common causes of this problem include using a final class or a non-visible class\",\r\n                    ex);\r\n        }\r\n        catch (Throwable ex) {\r\n            // TargetSource.getTarget() failed\r\n            throw new AopConfigException(\"Unexpected AOP exception\", ex);\r\n        }\r\n    }\r\n    `</pre>\r\n\r\n    获取回调\r\n\r\n    <pre>`private Callback[] getCallbacks(Class&lt;?&gt; rootClass) throws Exception {\r\n        // Parameters used for optimization choices...\r\n        boolean exposeProxy = this.advised.isExposeProxy();\r\n        boolean isFrozen = this.advised.isFrozen();\r\n        boolean isStatic = this.advised.getTargetSource().isStatic();\r\n\r\n        // Choose an \"aop\" interceptor (used for AOP calls).\r\n        // 实例化回调，在调用目标对象方法的时候执行\r\n        Callback aopInterceptor = new DynamicAdvisedInterceptor(this.advised);\r\n        return callbacks;\r\n    }\r\n    `</pre>\r\n\r\n    实例化回调部分\r\n\r\n    <pre>`private static class DynamicAdvisedInterceptor implements MethodInterceptor, Serializable {\r\n\r\n        private final AdvisedSupport advised;\r\n\r\n        public DynamicAdvisedInterceptor(AdvisedSupport advised) {\r\n            // 设置切面信息，也就是之前的ProxyFactory\r\n            this.advised = advised;\r\n        }\r\n\r\n        @Override\r\n        @Nullable\r\n        // 调用目标方法的时候执行\r\n        public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {\r\n            Object oldProxy = null;\r\n            boolean setProxyContext = false;\r\n            Object target = null;\r\n            TargetSource targetSource = this.advised.getTargetSource();\r\n            try {\r\n                if (this.advised.exposeProxy) {\r\n                    // Make invocation available if necessary.\r\n                    oldProxy = AopContext.setCurrentProxy(proxy);\r\n                    setProxyContext = true;\r\n                }\r\n                // Get as late as possible to minimize the time we \"own\" the target, in case it comes from a pool...\r\n                target = targetSource.getTarget();\r\n                Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null);\r\n                // 获取通知，此处的通知为TransactionInterceptor\r\n                List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);\r\n                Object retVal;\r\n                // Check whether we only have one InvokerInterceptor: that is,\r\n                // no real advice, but just reflective invocation of the target.\r\n                if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) {\r\n                    // We can skip creating a MethodInvocation: just invoke the target directly.\r\n                    // Note that the final invoker must be an InvokerInterceptor, so we know\r\n                    // it does nothing but a reflective operation on the target, and no hot\r\n                    // swapping or fancy proxying.\r\n                    Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);\r\n                    retVal = methodProxy.invoke(target, argsToUse);\r\n                }\r\n                else {\r\n                    // We need to create a method invocation...\r\n                    retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed();\r\n                }\r\n                retVal = processReturnType(proxy, target, method, retVal);\r\n                return retVal;\r\n            }\r\n            finally {\r\n                if (target != null &amp;&amp; !targetSource.isStatic()) {\r\n                    targetSource.releaseTarget(target);\r\n                }\r\n                if (setProxyContext) {\r\n                    // Restore old proxy.\r\n                    AopContext.setCurrentProxy(oldProxy);\r\n                }\r\n            }\r\n        }\r\n\r\n        @Override\r\n        public boolean equals(Object other) {\r\n            return (this == other ||\r\n                    (other instanceof DynamicAdvisedInterceptor &amp;&amp;\r\n                            this.advised.equals(((DynamicAdvisedInterceptor) other).advised)));\r\n        }\r\n\r\n        /**\r\n         * CGLIB uses this to drive proxy creation.\r\n         */\r\n        @Override\r\n        public int hashCode() {\r\n            return this.advised.hashCode();\r\n        }\r\n    }\r\n    `</pre>\r\n\r\n    调用invocation的处理方法，ReflectiveMethodInvocation#proceed\r\n\r\n    <pre>`public Object proceed() throws Throwable {\r\n        //    We start with an index of -1 and increment early.\r\n        if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) {\r\n            return invokeJoinpoint();\r\n        }\r\n\r\n        // 此处的通知TransactionInterceptor\r\n        Object interceptorOrInterceptionAdvice =\r\n                this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex);\r\n        if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) {\r\n            // Evaluate dynamic method matcher here: static part will already have\r\n            // been evaluated and found to match.\r\n            InterceptorAndDynamicMethodMatcher dm =\r\n                    (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice;\r\n            Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass());\r\n            if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) {\r\n                return dm.interceptor.invoke(this);\r\n            }\r\n            else {\r\n                // Dynamic matching failed.\r\n                // Skip this interceptor and invoke the next in the chain.\r\n                return proceed();\r\n            }\r\n        }\r\n        else {\r\n            // It\'s an interceptor, so we just invoke it: The pointcut will have\r\n            // been evaluated statically before this object was constructed.\r\n            // 调用TransactionInterceptor#invoke\r\n            return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this);\r\n        }\r\n    }\r\n    `</pre>\r\n\r\n    调用TransactionInterceptor#invoke\r\n\r\n    <pre>`public Object invoke(MethodInvocation invocation) throws Throwable {\r\n        // Work out the target class: may be {@code null}.\r\n        // The TransactionAttributeSource should be passed the target class\r\n        // as well as the method, which may be from an interface.\r\n        Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null);\r\n\r\n        // Adapt to TransactionAspectSupport\'s invokeWithinTransaction...\r\n        // 以事务的方式进行调用\r\n        return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed);\r\n    }\r\n    `</pre>\r\n\r\n    事务方式调用\r\n\r\n    <pre>`protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass,\r\n                final InvocationCallback invocation) throws Throwable {\r\n\r\n        // If the transaction attribute is null, the method is non-transactional.\r\n        TransactionAttributeSource tas = getTransactionAttributeSource();\r\n        final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null);\r\n        final PlatformTransactionManager tm = determineTransactionManager(txAttr);\r\n        final String joinpointIdentification = methodIdentification(method, targetClass, txAttr);\r\n\r\n        if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) {\r\n            // Standard transaction demarcation with getTransaction and commit/rollback calls.\r\n            // 创建事务信息对象\r\n            TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);\r\n            Object retVal = null;\r\n            try {\r\n                // This is an around advice: Invoke the next interceptor in the chain.\r\n                // This will normally result in a target object being invoked.\r\n                // 调用被代理对象方法\r\n                retVal = invocation.proceedWithInvocation();\r\n            }\r\n            catch (Throwable ex) {\r\n                // target invocation exception\r\n                // 业务方法执行异常，进行事务回滚\r\n                completeTransactionAfterThrowing(txInfo, ex);\r\n                throw ex;\r\n            }\r\n            finally {\r\n                // 清除事务信息对象\r\n                cleanupTransactionInfo(txInfo);\r\n            }\r\n            // 提交事务\r\n            commitTransactionAfterReturning(txInfo);\r\n            return retVal;\r\n        }\r\n\r\n        else {\r\n            final ThrowableHolder throwableHolder = new ThrowableHolder();\r\n\r\n            // It\'s a CallbackPreferringPlatformTransactionManager: pass a TransactionCallback in.\r\n            try {\r\n                Object result = ((CallbackPreferringPlatformTransactionManager) tm).execute(txAttr, status -&gt; {\r\n                    TransactionInfo txInfo = prepareTransactionInfo(tm, txAttr, joinpointIdentification, status);\r\n                    try {\r\n                        return invocation.proceedWithInvocation();\r\n                    }\r\n                    catch (Throwable ex) {\r\n                        if (txAttr.rollbackOn(ex)) {\r\n                            // A RuntimeException: will lead to a rollback.\r\n                            if (ex instanceof RuntimeException) {\r\n                                throw (RuntimeException) ex;\r\n                            }\r\n                            else {\r\n                                throw new ThrowableHolderException(ex);\r\n                            }\r\n                        }\r\n                        else {\r\n                            // A normal return value: will lead to a commit.\r\n                            throwableHolder.throwable = ex;\r\n                            return null;\r\n                        }\r\n                    }\r\n                    finally {\r\n                        cleanupTransactionInfo(txInfo);\r\n                    }\r\n                });\r\n\r\n                // Check result state: It might indicate a Throwable to rethrow.\r\n                if (throwableHolder.throwable != null) {\r\n                    throw throwableHolder.throwable;\r\n                }\r\n                return result;\r\n            }\r\n            catch (ThrowableHolderException ex) {\r\n                throw ex.getCause();\r\n            }\r\n            catch (TransactionSystemException ex2) {\r\n                if (throwableHolder.throwable != null) {\r\n                    logger.error(\"Application exception overridden by commit exception\", throwableHolder.throwable);\r\n                    ex2.initApplicationException(throwableHolder.throwable);\r\n                }\r\n                throw ex2;\r\n            }\r\n            catch (Throwable ex2) {\r\n                if (throwableHolder.throwable != null) {\r\n                    logger.error(\"Application exception overridden by commit exception\", throwableHolder.throwable);\r\n                }\r\n                throw ex2;\r\n            }\r\n        }\r\n    }\r\n\r\n到此事务的源码分析就结束了\r\n\r\n## **专车总结**\r\n\r\n*   导入AutoProxyRegistrar、ProxyTransactionManagementConfiguration配置类\r\n*   AutoProxyRegistrar用来注册InfrastructureAdvisorAutoProxyCreator到IOC中，InfrastructureAdvisorAutoProxyCreator实现了BeanPostProcessor\r\n*   执行BeanPostProcessor的后置处理\r\n*   获取由ProxyTransactionManagementConfiguration配置类创建的切面\r\n*   通过切面解析bean是否需要创建代理，需要就创建代理\r\n*   执行代理的回调，在回调中拿到通知\r\n*   执行通知，通知里面逻辑：开启事务、执行目标方法、提交或回滚事务\r\n\r\n## **专车回顾**\r\n\r\n回顾下开头的两个问题：\r\n\r\n*   为什么加上@Transactional注解就可以实现事务？\r\n*   分析事务源码之后我们可以学到什么？\r\n\r\n通过以上分析，第一个问题应该就迎刃而解了，那么通过以上学到的知识我们可以实现什么功能呢？在下一篇我们会在此基础上进行实战，通过@SystemLog注解实现系统日志功能。感谢各位撸友乘坐此趟专车，欢迎下次继续乘坐\r\n\r\n## 最后\r\n\r\n> 师长，【**java进阶架构师**】号主，短短一年在各大平台斩获15W+程序员关注，专注分享Java进阶、架构技术、高并发、微服务、BAT面试、redis专题、JVM调优、Springboot源码、mysql优化等20大进阶架构专题，关注【**java进阶架构师**】回复【**架构**】领取架构师完整视频一套。\r\n> \r\n> 转载说明：请务必注明来源（注明：来源于首发公众号：【java进阶架构师】）', 6, 0, 0, 0);
INSERT INTO `melog_article` VALUES (19, 1, 0, '全网最通俗易懂的Kafka入门！', '雨思', 'me', '', 32, '技术', '前言 只有光头才能变强。文本已收录至我的GitHub仓库，欢迎Star：[链接] 在这篇之前已经写过两篇基础文章了，强烈建议先去阅读： 什么是ZooKeeper？ 什么是消息队列？ 众所周知，消息队列的产品有好几种，这里我选择学习Kafka的原因，无他，公司在用。 我司使用的是Kafka和自研的消息队列(Kafka和RocketMQ)改版，于是我...', '## 前言\r\n\r\n> 只有光头才能变强。\r\n> \r\n> 文本已收录至我的GitHub仓库，欢迎Star：[https://github.com/ZhongFuCheng3y/3y](https://github.com/ZhongFuCheng3y/3y)\r\n\r\n在这篇之前已经写过两篇基础文章了，**强烈建议**先去阅读：\r\n\r\n*   [什么是ZooKeeper？](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247485115&amp;idx=1&amp;sn=5d269f40f820c82b460993669ca6242e&amp;chksm=ebd747badca0ceac9953f82e08b1d1a49498ebd4af77ec5d628a0682bb9f0ac5ab347411f654&amp;token=1741918942&amp;lang=zh_CN#rd)\r\n*   [什么是消息队列？](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247485080&amp;idx=1&amp;sn=f223feb9256727bde4387d918519766b&amp;chksm=ebd74799dca0ce8fa46223a33042a79fc16ae6ac246cb8f07e63a4a2bdce33d8c6dc74e8bd20&amp;token=1755043505&amp;lang=zh_CN#rd)\r\n\r\n众所周知，消息队列的产品有好几种，这里我选择学习Kafka的原因，无他，公司在用。\r\n\r\n> 我司使用的是Kafka和自研的消息队列(Kafka和RocketMQ)改版，于是我就想学学Kafka这款消息队列啦。本篇文章对Kafka入门，希望对大家有所帮助。\r\n\r\n本文知识点提前预览：\r\n\r\n<span class=\"img-wrap\">![提前预览](/img/remote/1460000021192183 \"提前预览\")</span>\r\n\r\n这篇文章花了我很长时间画图，目的是希望以最通俗易懂的方式带大家入门，如果觉得不错，**希望能给我点个赞**！\r\n\r\n[**我帮阿里云推广服务器89/年，229/3年，买来送自己，送女朋友马上过年再合适不过了，买了搭建个项目给面试官看也香，还可以熟悉技术栈，(老用户用家人账号买就好了，我用我女朋友的?）。扫码或者点击购买**](https://www.aliyun.com/minisite/goods?userCode=pfn5xpli&amp;share_source=copy_link)\r\n\r\n<span class=\"img-wrap\">![](/img/remote/1460000021185929)</span>\r\n\r\n[**搭建教程，从0开始一步一步带你搭建**?](https://mp.weixin.qq.com/s/MQqasjPs4Y-OCjQLuFj4ew)\r\n\r\n## 一、什么是Kafka？\r\n\r\n首先我们得去官网看看是怎么介绍Kafka的：\r\n\r\n*   [https://kafka.apache.org/intro](https://kafka.apache.org/intro)\r\n\r\n在收集资料学习的时候，已经发现有不少的前辈对官网的介绍进行翻译和总结了，所以我这里就不重复了，贴下地址大家自行去学习啦：\r\n\r\n*   [https://scala.cool/2018/03/learning-kafka-1/](https://scala.cool/2018/03/learning-kafka-1/)\r\n*   [https://colobu.com/2014/08/06/kafka-quickstart/](https://colobu.com/2014/08/06/kafka-quickstart/)\r\n\r\n我之前写过的[消息队列入门](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247485080&amp;idx=1&amp;sn=f223feb9256727bde4387d918519766b&amp;chksm=ebd74799dca0ce8fa46223a33042a79fc16ae6ac246cb8f07e63a4a2bdce33d8c6dc74e8bd20&amp;token=1755043505&amp;lang=zh_CN#rd)文章也提到了，要做一个消息队列可能要考虑到以下的问题：\r\n\r\n*   使用消息队列不可能是单机的（必然是分布式or集群）\r\n*   数据写到消息队列，可能会存在数据丢失问题，数据在消息队列需要**持久化**(磁盘？数据库？Redis？分布式文件系统？)\r\n*   想要保证消息（数据）是有序的，怎么做？\r\n*   为什么在消息队列中重复消费了数据\r\n\r\n下面我以Kafka为例对这些问题进行简单的解答，进而入门Kafka。\r\n\r\n## 1.1 Kafka入门\r\n\r\n众所周知，Kafka是一个消息队列，把消息放到队列里边的叫**生产者**，从队列里边消费的叫**消费者**。\r\n\r\n<span class=\"img-wrap\">![生产者和消费者](/img/remote/1460000021192185 \"生产者和消费者\")</span>\r\n\r\n一个消息中间件，队列不单单只有一个，我们往往会有多个队列，而我们生产者和消费者就得知道：把数据丢给哪个队列，从哪个队列消息。我们需要给队列取名字，叫做**topic**(相当于数据库里边**表**的概念)\r\n\r\n<span class=\"img-wrap\">![给队列取名字，专业名词叫topic](/img/remote/1460000021192182 \"给队列取名字，专业名词叫topic\")</span>\r\n\r\n现在我们给队列取了名字以后，生产者就知道往哪个队列丢数据了，消费者也知道往哪个队列拿数据了。我们可以有多个生产者**往同一个队列(topic)**丢数据，多个消费者**往同一个队列(topic)**拿数据\r\n\r\n<span class=\"img-wrap\">![](/img/remote/1460000021192181)</span>\r\n\r\n为了提高一个队列(topic)的**吞吐量**，Kafka会把topic进行分区(**Partition**)\r\n\r\n<span class=\"img-wrap\">![Kafka分区](/img/remote/1460000021192184 \"Kafka分区\")</span>\r\n\r\n所以，生产者实际上是往一个topic名为Java3y中的分区(**Partition**)丢数据，消费者实际上是往一个topic名为Java3y的分区(**Partition**)取数据\r\n\r\n<span class=\"img-wrap\">![生产者和消费者实际上操作的是分区](/img/remote/1460000021192186 \"生产者和消费者实际上操作的是分区\")</span>\r\n\r\n一台Kafka服务器叫做**Broker**，Kafka集群就是多台Kafka服务器：\r\n\r\n<span class=\"img-wrap\">![Kafka集群](/img/remote/1460000021192187 \"Kafka集群\")</span>\r\n\r\n一个topic会分为多个partition，实际上partition会**分布**在不同的broker中，举个例子：\r\n\r\n<span class=\"img-wrap\">![一个生产者丢数据给topic](/img/remote/1460000021192189 \"一个生产者丢数据给topic\")</span>\r\n\r\n由此得知：**Kafka是天然分布式的**。\r\n\r\n> 如果不了解分布式/集群，以及基本的分布式概念的同学，可以关注我的GitHub：[https://github.com/ZhongFuChe...](https://github.com/ZhongFuCheng3y/3y)\r\n> \r\n> 关键字：分布式、SpringCloud 保证能让你搞懂。觉得我写得不错，就给我**点个赞**！\r\n\r\n现在我们已经知道了往topic里边丢数据，实际上这些数据会分到不同的partition上，这些partition存在不同的broker上。分布式肯定会带来问题：“万一其中一台broker(Kafka服务器)出现网络抖动或者挂了，怎么办？”\r\n\r\nKafka是这样做的：我们数据存在不同的partition上，那kafka就把这些partition做**备份**。比如，现在我们有三个partition，分别存在三台broker上。每个partition都会备份，这些备份散落在**不同**的broker上。\r\n\r\n<span class=\"img-wrap\">![红色代表主分区，紫色代表备份分区](/img/remote/1460000021192188 \"红色代表主分区，紫色代表备份分区\")</span>\r\n\r\n红色块的partition代表的是**主**分区，紫色的partition块代表的是**备份**分区。生产者往topic丢数据，是与**主**分区交互，消费者消费topic的数据，也是与主分区交互。\r\n\r\n**备份分区仅仅用作于备份，不做读写。**如果某个Broker挂了，那就会选举出其他Broker的partition来作为主分区，这就实现了**高可用**。\r\n\r\n另外值得一提的是：当生产者把数据丢进topic时，我们知道是写在partition上的，那partition是怎么将其持久化的呢？（不持久化如果Broker中途挂了，那肯定会丢数据嘛)。\r\n\r\nKafka是将partition的数据写在**磁盘**的(消息日志)，不过Kafka只允许**追加写入**(顺序访问)，避免缓慢的随机 I/O 操作。\r\n\r\n*   Kafka也不是partition一有数据就立马将数据写到磁盘上，它会先**缓存**一部分，等到足够多数据量或等待一定的时间再批量写入(flush)。\r\n\r\n上面balabala地都是讲生产者把数据丢进topic是怎么样的，下面来讲讲消费者是怎么消费的。既然数据是保存在partition中的，那么**消费者实际上也是从partition中取**数据。\r\n\r\n<span class=\"img-wrap\">![从各个主分区取数据](/img/remote/1460000021192195 \"从各个主分区取数据\")</span>\r\n\r\n生产者可以有多个，消费者也可以有多个。像上面图的情况，是一个消费者消费三个分区的数据。多个消费者可以组成一个**消费者组**。\r\n\r\n<span class=\"img-wrap\">![消费者组](/img/remote/1460000021192192 \"消费者组\")</span>\r\n\r\n本来是一个消费者消费三个分区的，现在我们有消费者组，就可以**每个消费者去消费一个分区**（也是为了提高吞吐量）\r\n\r\n<span class=\"img-wrap\">![消费者组的每个消费者会去对应partition拿数据](/img/remote/1460000021192191 \"消费者组的每个消费者会去对应partition拿数据\")</span>\r\n\r\n按图上所示的情况，这里想要说明的是：\r\n\r\n*   如果消费者组中的某个消费者挂了，那么其中一个消费者可能就要消费两个partition了\r\n*   如果只有三个partition，而消费者组有4个消费者，那么一个消费者会空闲\r\n*   如果多加入一个**消费者组**，无论是新增的消费者组还是原本的消费者组，都能消费topic的全部数据。（消费者组之间从逻辑上它们是**独立**的）\r\n\r\n前面讲解到了生产者往topic里丢数据是存在partition上的，而partition持久化到磁盘是IO顺序访问的，并且是先写缓存，隔一段时间或者数据量足够大的时候才批量写入磁盘的。\r\n\r\n消费者在读的时候也很有讲究：正常的读磁盘数据是需要将内核态数据拷贝到用户态的，而Kafka 通过调用`sendfile() `直接从内核空间（DMA的）到内核空间（Socket的），**少做了一步拷贝**的操作。\r\n\r\n<span class=\"img-wrap\">![Kafka 读数据 巧妙](/img/remote/1460000021192193 \"Kafka 读数据 巧妙\")</span>\r\n\r\n有的同学可能会产生疑问：消费者是怎么知道自己消费到哪里的呀？Kafka不是支持**回溯**吗？那是怎么做的呀？\r\n\r\n*   比如上面也提到：如果一个消费者组中的某个消费者挂了，那挂掉的消费者所消费的分区可能就由存活的消费者消费。那**存活的消费者是需要知道挂掉的消费者消费到哪了**，不然怎么玩。\r\n\r\n这里要引出`offset`了，Kafka就是用`offset`来表示消费者的消费进度到哪了，每个消费者会都有自己的`offset`。说白了`offset`就是表示消费者的**消费进度**。\r\n\r\n在以前版本的Kafka，这个`offset`是由Zookeeper来管理的，后来Kafka开发者认为Zookeeper不合适大量的删改操作，于是把`offset`在broker以内部topic(`__consumer_offsets`)的方式来保存起来。\r\n\r\n每次消费者消费的时候，都会提交这个`offset`，Kafka可以让你选择是自动提交还是手动提交。\r\n\r\n既然提到了Zookeeper，那就多说一句。Zookeeper虽然在新版的Kafka中没有用作于保存客户端的`offset`，但是Zookeeper是Kafka一个重要的依赖。\r\n\r\n*   探测broker和consumer的添加或移除。\r\n*   负责维护所有partition的领导者/从属者关系（主分区和备份分区），如果主分区挂了，需要选举出备份分区作为主分区。\r\n*   维护topic、partition等元配置信息\r\n*   ....\r\n\r\n<span class=\"img-wrap\">![这张图来源胡夕老师的《Kafka核心技术与实战》](/img/remote/1460000021192190 \"这张图来源胡夕老师的《Kafka核心技术与实战》\")</span>\r\n\r\n## 最后\r\n\r\n通过这篇文章，文章开头那几个问题估计多多少少都懂一些啦。我来简要回答一下：\r\n\r\n> 使用消息队列不可能是单机的（必然是分布式or集群）\r\n\r\nKafka天然是分布式的，往一个topic丢数据，实际上就是往多个broker的partition存储数据\r\n\r\n> 数据写到消息队列，可能会存在数据丢失问题，数据在消息队列需要**持久化**(磁盘？数据库？Redis？分布式文件系统？)\r\n\r\nKafka会将partition以消息日志的方式(落磁盘)存储起来，通过 顺序访问IO和缓存(等到一定的量或时间)才真正把数据写到磁盘上，来提高速度。\r\n\r\n> 想要保证消息（数据）是有序的，怎么做？\r\n\r\nKafka会将数据写到partition，单个partition的写入是有顺序的。如果要保证全局有序，那只能写入一个partition中。如果要消费也有序，消费者也只能有一个。\r\n\r\n> 为什么在消息队列中重复消费了数据\r\n\r\n凡是分布式就无法避免网络抖动/机器宕机等问题的发生，很有可能消费者A读取了数据，还没来得及消费，就挂掉了。Zookeeper发现消费者A挂了，让消费者B去消费原本消费者A的分区，等消费者A重连的时候，发现已经重复消费同一条数据了。(各种各样的情况，消费者超时等等都有可能...)\r\n\r\n如果业务上不允许重复消费的问题，最好消费者那端做业务上的校验（如果已经消费过了，就不消费了）\r\n\r\n* * *\r\n\r\n这篇文章主要是Kafka入门，Kafka还涉及到别的概念，以及还有别的东西。在我感觉中，很多的面试题都跟配置有关，所以在解决某些问题的时候，**先看看能不能通过现有配置解决掉**（学多了框架，你就会发现很多官方的就已经支持解决了，你做的可能改改配置/参数就完事了）。\r\n\r\n> **本已收录至我的GitHub精选文章，欢迎Star**：[https://github.com/ZhongFuCheng3y/3y](https://github.com/ZhongFuCheng3y/3y)\r\n> \r\n> 乐于输出**干货**的Java技术公众号：**Java3y**。公众号内**有300多篇原创**技术文章、海量视频资源、精美脑图，**关注即可获取！**\r\n\r\n<span class=\"img-wrap\">![转发到朋友圈是对我最大的支持！](/img/remote/1460000021192194 \"转发到朋友圈是对我最大的支持！\")</span>\r\n\r\n非常感谢**人才**们能看到这里，如果这个文章写得还不错，觉得「三歪」我**有点东西**的话   **求点赞** **求关注️**  **求分享?** **求留言?** 对暖男我来说真的 **非常有用**！！！\r\n\r\n创作不易，各位的支持和认可，就是我创作的最大动力，我们下篇文章见！', 2, 0, 0, 0);
INSERT INTO `melog_article` VALUES (20, 1, 0, '90%的人会遇到性能问题，如何用1行代码快速定位？', '雨思', 'me', '', 67, '技术', '今天，齐光将会基于之前列举的众多指标，给出一些常见的调优分析思路，即：如何在众多异常性能指标中，找出最核心的那一个，进而定位性能瓶颈点，最后进行性能调优。整篇文章会按照代码、CPU、内存、网络、磁盘等方向进行组织，针对对某一各优化点，会有系统的「套路」总结，便于思路的迁移实践。', '<span class=\"img-wrap\">![](/img/bVbA4Ak)</span>\r\n\r\n> **阿里妹导读：**在[《如何回答性能优化的问题，才能打动阿里面试官？](https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&amp;mid=2247492338&amp;idx=1&amp;sn=1b261f2eda75163e0878d3b5e4373834&amp;chksm=e92adffdde5d56eb4720f9ee0b3b81795ee31bedb2ebe6a3112e0e1b538242e69076ff5aa715&amp;token=1454462344&amp;lang=zh_CN&amp;scene=21#wechat_redirect)[》](https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&amp;mid=2247492338&amp;idx=1&amp;sn=1b261f2eda75163e0878d3b5e4373834&amp;chksm=e92adffdde5d56eb4720f9ee0b3b81795ee31bedb2ebe6a3112e0e1b538242e69076ff5aa715&amp;token=1454462344&amp;lang=zh_CN&amp;scene=21#wechat_redirect)中，主要是介绍了应用常见性能瓶颈点的分布，及如何初判若干指标是否出现了异常。\r\n\r\n今天，齐光将会基于之前列举的众多指标，给出一些常见的调优分析思路，即：如何在众多异常性能指标中，找出最核心的那一个，进而定位性能瓶颈点，最后进行性能调优。整篇文章会按照代码、CPU、内存、网络、磁盘等方向进行组织，针对对某一各优化点，会有系统的「套路」总结，便于思路的迁移实践。\r\n\r\n## **1. 代码相关**\r\n\r\n遇到性能问题，首先应该做的是检查否与业务代码相关——不是通过阅读代码解决问题，而是通过日志或代码，排除掉一些与业务代码相关的低级错误。**性能优化的最佳位置，是应用内部。**\r\n\r\n譬如，查看业务日志，检查日志内容里是否有大量的报错产生，应用层、框架层的一些性能问题，大多数都能从日志里找到端倪（日志级别设置不合理，导致线上疯狂打日志）；再者，检查代码的主要逻辑，如 for 循环的不合理使用、NPE、正则表达式、数学计算等常见的一些问题，都可以通过简单地修改代码修复问题。\r\n\r\n**别动辄就把性能优化和缓存、异步化、JVM 调优等名词挂钩，复杂问题可能会有简单解，「二八原则」在性能优化的领域里里依然有效**。当然了，了解一些基本的「代码常用踩坑点」，可以加速我们问题分析思路的过程，从 CPU、内存、JVM 等分析到的一些瓶颈点优化思路，也有可能在代码这里体现出来。\r\n\r\n下面是一些高频的，容易造成性能问题的编码要点。\r\n\r\n1）正则表达式非常消耗 CPU（如贪婪模式可能会引起回溯），慎用字符串的 split()、replaceAll() 等方法；正则表达式表达式一定预编译。\r\n\r\n2）String.intern() 在低版本（Java 1.6 以及之前）的 JDK 上使用，可能会造成方法区（永久代）内存溢出。在高版本 JDK 中，如果 string pool 设置太小而缓存的字符串过多，也会造成较大的性能开销。\r\n\r\n3）输出异常日志的时候，如果堆栈信息是明确的，可以取消输出详细堆栈，异常堆栈的构造是有成本的。注意：同一位置抛出大量重复的堆栈信息，JIT 会将其优化后成，直接抛出一个事先编译好的、类型匹配的异常，异常堆栈信息就看不到了。\r\n\r\n4）避免引用类型和基础类型之间无谓的拆装箱操作，请尽量保持一致，自动装箱发生太频繁，会非常严重消耗性能。\r\n\r\n<span class=\"img-wrap\">![](/img/bVbA4As)</span>\r\n\r\n5）Stream API 的选择。复杂和并行操作，推荐使用 Stream API，可以简化代码，同时发挥来发挥出 CPU 多核的优势，如果是简单操作或者 CPU 是单核，推荐使用显式迭代。\r\n\r\n6）根据业务场景，通过 ThreadPoolExecutor 手动创建线程池，结合任务的不同，指定线程数量和队列大小，规避资源耗尽的风险，统一命名后的线程也便于后续问题排查。\r\n\r\n7）根据业务场景，合理选择并发容器。如选择 Map 类型的容器时，如果对数据要求有强一致性，可使用 Hashtable 或者 「Map + 锁」 ；读远大于写，使用 CopyOnWriteArrayList；存取数据量小、对数据没有强一致性的要求、变更不频繁的，使用 ConcurrentHashMap；存取数据量大、读写频繁、对数据没有强一致性的要求，使用 ConcurrentSkipListMap。\r\n\r\n8）锁的优化思路有：减少锁的粒度、循环中使用锁粗化、减少锁的持有时间(读写锁的选择)等。同时，也考虑使用一些 JDK 优化后的并发类，如对一致性要求不高的统计场景中，使用 LongAdder 替代 AtomicLong 进行计数，使用 ThreadLocalRandom 替代 Random 类等。\r\n\r\n代码层的优化除了上面这些，还有很多就不一一列出了。我们可以观察到，在这些要点里，有**一些共性的优化思路**，是可以抽取出来的，譬如：\r\n\r\n1.  空间换时间：使用内存或者磁盘，换取更宝贵的CPU 或者网络，如缓存的使用；\r\n2.  时间换空间：通过牺牲部分 CPU，节省内存或者网络资源，如把一次大的网络传输变成多次；\r\n3.  其他诸如并行化、异步化、池化技术等。\r\n\r\n## **2. CPU 相关**\r\n\r\n前面讲到过，我们更应该关注 CPU 负载，CPU 利用率高一般不是问题，CPU 负载 是判断系统计算资源是否健康的关键依据。\r\n\r\n**2.1 CPU 利用率高&amp;&amp;平均负载高**\r\n\r\n这种情况常见于 CPU 密集型的应用，大量的线程处于可运行状态，I/O 很少，常见的大量消耗 CPU 资源的应用场景有：\r\n\r\n1.  正则操作\r\n2.  数学运算\r\n3.  序列化/反序列化\r\n4.  反射操作\r\n5.  死循环或者不合理的大量循环\r\n6.  基础/第三方组件缺陷\r\n\r\n**排查高 CPU 占用的一般思路：**通过 jstack 多次（&gt; 5次）打印线程栈，一般可以定位到消耗 CPU 较多的线程堆栈。或者通过 Profiling 的方式（基于事件采样或者埋点），得到应用在一段时间内的 on-CPU 火焰图，也能较快定位问题。\r\n\r\n还有一种可能的情况，此时应用存在频繁的 GC （包括 Young GC、Old GC、Full GC），这也会导致 CPU 利用率和负载都升高。排查思路：使用 jstat -gcutil 持续输出当前应用的 GC 统计次数和时间。频繁 GC 导致的负载升高，一般还伴随着可用内存不足，可用 free 或者 top 等命令查看下当前机器的可用内存大小。\r\n\r\nCPU 利用率过高，是否有可能是 CPU 本身性能瓶颈导致的呢？也是有可能的。可以进一步通过 vmstat 查看详细的 CPU 利用率。用户态 CPU 利用率（us）较高，说明用户态进程占用了较多的 CPU，如果这个值长期大于50%，应该着重排查应用本身的性能问题。内核态 CPU 利用率（sy）较高，说明内核态占用了较多的 CPU，所以应该着重排查内核线程或者系统调用的性能问题。如果 us + sy 的值大于 80%，说明 CPU 可能不足。\r\n\r\n<span class=\"img-wrap\">![](/img/bVbA4Av)</span>\r\n\r\n**2.2 CPU 利用率低&amp;&amp;平均负载高**\r\n\r\n如果CPU利用率不高，说明我们的应用并没有忙于计算，而是在干其他的事。CPU 利用率低而平均负载高，常见于 I/O 密集型进程，这很容易理解，毕竟平均负载就是 R 状态进程和 D 状态进程的和，除掉了第一种，就只剩下 D 状态进程了（产生 D 状态的原因一般是因为在等待 I/O，例如磁盘 I/O、网络 I/O 等）。\r\n\r\n**排查&amp;&amp;验证思路：**使用 vmstat 1 定时输出系统资源使用，观察 %wa(iowait) 列的值，该列标识了磁盘 I/O 等待时间在 CPU 时间片中的百分比，如果这个值超过30%，说明磁盘 I/O 等待严重，这可能是大量的磁盘随机访问或直接的磁盘访问（没有使用系统缓存）造成的，也可能磁盘本身存在瓶颈，可以结合 iostat 或 dstat 的输出加以验证，如 %wa(iowait) 升高同时观察到磁盘的读请求很大，说明可能是磁盘读导致的问题。\r\n\r\n此外，耗时较长的网络请求（即网络 I/O）也会导致 CPU 平均负载升高，如 MySQL 慢查询、使用 RPC 接口获取接口数据等。这种情况的排查一般需要结合应用本身的上下游依赖关系以及中间件埋点的 trace 日志，进行综合分析。\r\n\r\n**2.3 CPU 上下文切换次数变高**\r\n\r\n先用 vmstat 查看系统的上下文切换次数，然后通过 pidstat 观察进程的自愿上下文切换（cswch）和非自愿上下文切换（nvcswch）情况。自愿上下文切换，是因为应用内部线程状态发生转换所致，譬如调用 sleep()、join()、wait()等方法，或使用了 Lock 或 synchronized 锁结构；非自愿上下文切换，是因为线程由于被分配的时间片用完或由于执行优先级被调度器调度所致。\r\n\r\n如果自愿上下文切换次数较高，意味着 CPU 存在资源获取等待，比如说，I/O、内存等系统资源不足等。如果是非自愿上下文切换次数较高，可能的原因是应用内线程数过多，导致 CPU 时间片竞争激烈，频频被系统强制调度，此时可以结合 jstack 统计的线程数和线程状态分布加以佐证。\r\n\r\n<span class=\"img-wrap\">![](/img/bVbA4AH)</span>\r\n\r\n## **3. 内存相关**\r\n\r\n前面提到，内存分为系统内存和进程内存（含 Java 应用进程），一般我们遇到的内存问题，绝大多数都会落在进程内存上，系统资源造成的瓶颈占比较小。对于 Java 进程，它自带的内存管理自动化地解决了两个问题：如何给对象分配内存以及如何回收分配给对象的内存，其核心是垃圾回收机制。\r\n\r\n垃圾回收虽然可以有效地防止内存泄露、保证内存的有效使用，但也并不是万能的，不合理的参数配置和代码逻辑，依然会带来一系列的内存问题。此外，早期的垃圾回收器，在功能性和回收效率上也不是很好，过多的 GC 参数设置非常依赖开发人员的调优经验。比如，对于最大堆内存的不恰当设置，可能会引发堆溢出或者堆震荡等一系列问题。\r\n\r\n下面看看几个常见的内存问题分析思路。\r\n\r\n**3.1 系统内存不足**\r\n\r\nJava 应用一般都有单机或者集群的内存水位监控，如果单机的内存利用率大于 95%，或者集群的内存利用率大于80%，就说明可能存在潜在的内存问题（注：这里的内存水位是系统内存）。\r\n\r\n除了一些较极端的情况，一般系统内存不足，大概率是由 Java 应用引起的。使用 top 命令时，我们可以看到 Java 应用进程的实际内存占用，其中 RES 表示进程的常驻内存使用，VIRT 表示进程的虚拟内存占用，内存大小的关系为：VIRT &gt; RES &gt; Java 应用实际使用的堆大小。除了堆内存，Java 进程整体的内存占用，还有方法区/元空间、JIT 缓存等，主要组成如下：\r\n\r\nJava 应用内存占用 = Heap（堆区）+ Code Cache（代码缓存区) + Metaspace（元空间）+ Symbol tables（符号表）+ Thread stacks（线程栈区）+ Direct buffers（堆外内存）+ JVM structures（其他的一些 JVM 自身占用）+ Mapped files（内存映射文件）+ Native Libraries（本地库）+ ...\r\n\r\nJava 进程的内存占用，可以使用 jstat -gc 命令查看，输出的指标中可以得到当前堆内存各分区、元空间的使用情况。堆外内存的统计和使用情况，可以利用 NMT（Native Memory Tracking，HotSpot VM Java8 引入）获取。线程栈使用的内存空间很容易被忽略，虽然线程栈内存采用的是懒加载的模式，不会直接使用 +Xss 的大小来分配内存，但是过多的线程也会导致不必要的内存占用，可以使用 jstackmem 这个脚本统计整体的线程占用。\r\n\r\n**系统内存不足的排查思路：**\r\n\r\n1.  首先使用 free 查看当前内存的可用空间大小，然后使用 vmstat 查看具体的内存使用情况及内存增长趋势，这个阶段一般能定位占用内存最多的进程；\r\n2.  分析缓存 / 缓冲区的内存使用。如果这个数值在一段时间变化不大，可以忽略。如果观察到缓存 / 缓冲区的大小在持续升高，则可以使用 pcstat、cachetop、slabtop 等工具，分析缓存 / 缓冲区的具体占用；\r\n3.  排除掉缓存 / 缓冲区对系统内存的影响后，如果发现内存还在不断增长，说明很有可能存在内存泄漏。\r\n\r\n<span class=\"img-wrap\">![](/img/bVbA4AS)</span>\r\n\r\n**3.2 Java 内存溢出**\r\n\r\n内存溢出是指应用新建一个对象实例时，所需的内存空间大于堆的可用空间。内存溢出的种类较多，一般会在报错日志里看到 OutOfMemoryError 关键字。**常见内存溢出种类及分析思路如下：**\r\n\r\n1）java.lang.OutOfMemoryError: Java heap space。原因：堆中（新生代和老年代）无法继续分配对象了、某些对象的引用长期被持有没有被释放，垃圾回收器无法回收、使用了大量的 Finalizer 对象，这些对象并不在 GC 的回收周期内等。一般堆溢出都是由于内存泄漏引起的，如果确认没有内存泄漏，可以适当通过增大堆内存。\r\n\r\n2）java.lang.OutOfMemoryError：GC overhead limit exceeded。原因：垃圾回收器超过98%的时间用来垃圾回收，但回收不到2%的堆内存，一般是因为存在内存泄漏或堆空间过小。\r\n\r\n3）java.lang.OutOfMemoryError: Metaspace或java.lang.OutOfMemoryError: PermGen space。排查思路：检查是否有动态的类加载但没有及时卸载，是否有大量的字符串常量池化，永久代/元空间是否设置过小等。\r\n\r\n4）java.lang.OutOfMemoryError : unable to create new native Thread。原因：虚拟机在拓展栈空间时，无法申请到足够的内存空间。可适当降低每个线程栈的大小以及应用整体的线程个数。此外，系统里总体的进程/线程创建总数也受到系统空闲内存和操作系统的限制，请仔细检查。\r\n\r\n注：这种栈溢出，和 StackOverflowError 不同，后者是由于方法调用层次太深，分配的栈内存不够新建栈帧导致。此外，还有 Swap 分区溢出、本地方法栈溢出、数组分配溢出等 OutOfMemoryError 类型，由于不是很常见，就不一一介绍了。\r\n\r\n**3.3 Java 内存泄漏**\r\n\r\nJava 内存泄漏可以说是开发人员的噩梦，内存泄漏与内存溢出不同则，后者简单粗暴，现场也比较好找。内存泄漏的表现是：应用运行一段时间后，内存利用率越来越高，响应越来越慢，直到最终出现进程「假死」。\r\n\r\nJava 内存泄漏可能会造成系统可用内存不足、进程假死、OOM 等，**排查思路却不外乎下面两种：**\r\n\r\n1.  通过 jmap 定期输出堆内对象统计，定位数量和大小持续增长的对象；\r\n2.  使用 Profiler 工具对应用进行 Profiling，寻找内存分配热点。\r\n\r\n此外，在堆内存持续增长时，建议 dump 一份堆内存的快照，后面可以基于快照做一些分析。快照虽然是瞬时值，但也是有一定的意义的。\r\n\r\n**3.4 垃圾回收相关**\r\n\r\nGC（垃圾回收，下同）的各项指标，是衡量 Java 进程内存使用是否健康的重要标尺。垃圾回收最核心指标：GC Pause（包括 MinorGC 和 MajorGC） 的频率和次数，以及每次回收的内存详情，前者可以通过 jstat 工具直接得到，后者需要分析 GC 日志。需要注意的是，jstat 输出列中的 FGC/FGCT 表示的是一次老年代垃圾回收中，出现 GC Pause （即 Stop-the-World）的次数，譬如对于 CMS 垃圾回收器，每次老年代垃圾回收这个值会增加2（初始标记和重新标记着两个 Stop-the-World 的阶段，这个统计值会是 2。\r\n\r\n什么时候需要进行 GC 调优？这取决于应用的具体情况，譬如对响应时间的要求、对吞吐量的要求、系统资源限制等。一些经验：GC 频率和耗时大幅上升、GC Pause 平均耗时超过 500ms、Full GC 执行频率小于1分钟等，如果 GC 满足上述的一些特征，说明需要进行 GC 调优了。\r\n\r\n由于垃圾回收器种类繁多，针对不同的应用，调优策略也有所区别，**因此下面介绍几种通用的的 GC 调优策略。**\r\n\r\n**1）选择合适的 GC 回收器。**根据应用对延迟、吞吐的要求，结合各垃圾回收器的特点，合理选用。推荐使用 G1 替换 CMS 垃圾回收器，G1 的性能是在逐步优化的，在 8GB 内存及以下的机器上，其各方面的表现也在赶上甚至有超越之势。G1 调参较方便，而 CMS 垃圾回收器参数太过复杂、容易造成空间碎片化、对 CPU 消耗较高等弊端，也使其目前处于废弃状态。Java 11 里新引入的 ZGC 垃圾回收器，基本可用做到全阶段并发标记和回收，值得期待。\r\n\r\n**2）合理的堆内存大小设置。**堆大小不要设置过大，建议不要超过系统内存的 75%，避免出现系统内存耗尽。最大堆大小和初始化堆的大小保持一致，避免堆震荡。新生代的大小设置比较关键，我们调整 GC 的频率和耗时，很多时候就是在调整新生代的大小，包括新生代和老年代的占比、新生代中 Eden 区和 Survivor 区的比例等，这些比例的设置还需要考虑各代中对象的晋升年龄，整个过程需要考虑的东西还是比较多的。如果使用 G1 垃圾回收器，新生代大小这一块需要考虑的东西就少很多了，自适应的策略会决定每一次的回收集合（CSet）。新生代的调整是 GC 调优的核心，非常依赖经验，但是一般来说，Young GC 频率高，意味着新生代太小（或 Eden 区和 Survivor 配置不合理），Young GC 时间长，意味着新生代过大，这两个方向大体不差。\r\n\r\n**3）降低 Full GC 的频率。**如果出现了频繁的 Full GC 或者 老年代 GC，很有可能是存在内存泄漏，导致对象被长期持有，通过 dump 内存快照进行分析，一般能较快地定位问题。除此之外，新生代和老年代的比例不合适，导致对象频频被直接分配到老年代，也有可能会造成 Full GC，这个时候需要结合业务代码和内存快照综合分析。此外，通过配置 GC 参数，可以帮助我们获取很多 GC 调优所需的关键信息，如配置-XX:+PrintGCApplicationStoppedTime-XX:+PrintSafepointStatistics-XX:+PrintTenuringDistribution，分别可以获取 GC Pause 分布、安全点耗时统计、对象晋升年龄分布的信息，加上 -XX:+PrintFlagsFinal 可以让我们了解最终生效的 GC 参数等。\r\n\r\n<span class=\"img-wrap\">![](/img/bVbA4AW)</span>\r\n\r\n## **4. 磁盘I/O和网络I/O**\r\n\r\n**4.1 磁盘 I/O 问题排查思路：**\r\n\r\n1.  使用工具输出磁盘相关的输出的指标，常用的有 %wa（iowait）、%util，根据输判断磁盘 I/O 是否存在异常，譬如 %util 这个指标较高，说明有较重的 I/O 行为；\r\n2.  使用 pidstat 定位到具体进程，关注下读或写的数据大小和速率；\r\n3.  使用 lsof + 进程号，可查看该异常进程打开的文件列表（含目录、块设备、动态库、网络套接字等），结合业务代码，一般可定位到 I/O 的来源，如果需要具体分析，还可以使用 perf 等工具进行 trace 定位 I/O 源头。\r\n\r\n需要注意的是，%wa（iowait）的升高不代表一定意味着磁盘 I/O 存在瓶颈，这是数值代表 CPU 上 I/O 操作的时间占用的百分比，如果应用进程的在这段时间内的主要活动就是 I/O，那么也是正常的。\r\n\r\n**4.2 网络 I/O 存在瓶颈，可能的原因如下：**\r\n\r\n1.  一次传输的对象过大，可能会导致请求响应慢，同时 GC 频繁；\r\n2.  网络 I/O 模型选择不合理，导致应用整体 QPS 较低，响应时间长；\r\n3.  RPC 调用的线程池设置不合理。可使用 jstack 统计线程数的分布，如果处于 TIMED_WAITING 或 WAITING 状态的线程较多，则需要重点关注。举例：数据库连接池不够用，体现在线程栈上就是很多线程在竞争一把连接池的锁；\r\n4.  RPC 调用超时时间设置不合理，造成请求失败较多；\r\n\r\n**Java 应用的线程堆栈快照非常有用，除了上面提到的用于排查线程池配置不合理的问题，其他的一些场景，如 CPU 飙高、应用响应较慢等，都可以先从线程堆栈入手。**\r\n\r\n## **5. 有用的一行命令**\r\n\r\n这一小节给出若干在定位性能问题的命令，用于快速定位。\r\n\r\n**1）查看系统当前网络连接数**\r\n\r\n    netstat -n | awk \'/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}\'`</pre>\r\n\r\n    **2）查看堆内对象的分布 Top 50（定位内存泄漏）**\r\n\r\n    <pre>`jmap –histo:live $pid | sort-n -r -k2 | head-n 50`</pre>\r\n\r\n    **3）按照 CPU/内存的使用情况列出前10 的进程**\r\n\r\n    <pre>`#内存\r\n    ps axo %mem,pid,euser,cmd | sort -nr | head -10\r\n    #CPU\r\n    ps -aeo pcpu,user,pid,cmd | sort -nr | head -10`</pre>\r\n\r\n    **4）显示系统整体的 CPU利用率和闲置率**\r\n\r\n    <pre>`grep \"cpu \" /proc/stat | awk -F \' \' \'{total = $2 + $3 + $4 + $5} END {print \"idle \\t used\\n\" $5*100/total \"% \" $2*100/total \"%\"}\'`</pre>\r\n\r\n    **5）按线程状态统计线程数(加强版)**\r\n\r\n    <pre>`jstack $pid | grep java.lang.Thread.State:|sort|uniq -c | awk \'{sum+=$1; split($0,a,\":\");gsub(/^[ \\t]+|[ \\t]+$/, \"\", a[2]);printf \"%s: %s\\n\", a[2], $1}; END {printf \"TOTAL: %s\",sum}\';`</pre>\r\n\r\n    **6）查看最消耗 CPU 的 Top10 线程机器堆栈信息**\r\n\r\n    推荐大家使用 show-busy-java-threads 脚本，该脚本可用于快速排查 Java 的 CPU 性能问题(top us值过高)，自动查出运行的 Java 进程中消耗 CPU 多的线程，并打印出其线程栈，从而确定导致性能问题的方法调用，该脚本已经用于阿里线上运维环境。链接地址：[https://github.com/oldratlee/...](https://github.com/oldratlee/useful-scripts/)。\r\n\r\n    **7）火焰图生成（需要安装 perf、perf-map-agent、FlameGraph 这三个项目）：**\r\n\r\n    <pre>`# 1. 收集应用运行时的堆栈和符号表信息（采样时间30秒，每秒99个事件）；\r\n    sudo perf record -F 99 -p $pid -g -- sleep 30; ./jmaps\r\n\r\n    # 2. 使用 perf script 生成分析结果，生成的 flamegraph.svg 文件就是火焰图。\r\n    sudo perf script | ./pkgsplit-perf.pl | grep java | ./flamegraph.pl &gt; flamegraph.svg`</pre>\r\n\r\n    **8）按照 Swap 分区的使用情况列出前 10 的进程**\r\n\r\n    <pre>`for file in /proc/*/status ; do awk \'/VmSwap|Name|^Pid/{printf $2 \" \" $3}END{ print \"\"}\' $file; done | sort -k 3 -n -r | head -10`</pre>\r\n\r\n    **9）JVM 内存使用及垃圾回收状态统计**\r\n\r\n    <pre>`#显示最后一次或当前正在发生的垃圾收集的诱发原因\r\n    jstat -gccause $pid\r\n\r\n    #显示各个代的容量及使用情况\r\n    jstat -gccapacity $pid\r\n\r\n    #显示新生代容量及使用情况\r\n    jstat -gcnewcapacity $pid\r\n\r\n    #显示老年代容量\r\n    jstat -gcoldcapacity $pid\r\n\r\n    #显示垃圾收集信息（间隔1秒持续输出）\r\n    jstat -gcutil $pid 1000\r\n    `</pre>\r\n\r\n    **10）其他的一些日常命令**\r\n\r\n    <pre>`# 快速杀死所有的 java 进程\r\n    ps aux | grep java | awk \'{ print $2 }\' | xargs kill -9\r\n\r\n    # 查找/目录下占用磁盘空间最大的top10文件\r\n    find / -type f -print0 | xargs -0 du -h | sort -rh | head -n 10\r\n\r\n## **6. 总结**\r\n\r\n性能优化是一个很大的领域，这里面的每一个小点，都可以拓展为数十篇文章去阐述。对应用进行性能优化，除了上面介绍的之外，还有前端优化、架构优化（分布式、缓存使用等）、数据存储优化、代码优化（如设计模式优化）等，限于篇幅所限，在这里并未一一展开，本文的这些内容，只是起一个抛砖引玉的作用。同时，本文的东西是我的一些经验和知识，并不一定全对，希望大家指正和补充。\r\n\r\n性能优化是一个综合性的工作，需要不断地去实践，将工具学习、经验学习融合到实战中去，不断完善，形成一套属于自己的调优方法论。\r\n\r\n此外，虽然性能优化很重要，但是不要过早在优化上投入太多精力（当然完善的架构设计和编码是必要的），过早优化是万恶之源。一方面，提前做的优化工作，可能会不适用快速变化的业务需求，反倒给新需求、新功能起了阻碍的作用；另一方面，过早优化使得应用复杂性升高，降低了应用的可维护性。何时进行优化、优化到什么样的程度，是一个需要多方权衡的命题。\r\n\r\n**参考资料：**\r\n\r\n[1][https://github.com/superhj198...](https://github.com/superhj1987/awesome-scripts)\r\n[2][https://github.com/jvm-profil...](https://github.com/jvm-profiling-tools/perf-map-agent)\r\n[3][https://github.com/brendangre...](https://github.com/brendangregg/FlameGraph)\r\n[4][https://github.com/apangin/js...](https://github.com/apangin/jstackmem/blob/master/jstackmem.py)\r\n\r\n* * *\r\n\r\n本文作者：齐光\r\n\r\n[阅读原文](https://yq.aliyun.com/articles/737110?utm_content=g_1000091283)\r\n\r\n本文来自云栖社区合作伙伴“阿里技术”，如需转载请联系原作者。', 3, 0, 0, 0);
INSERT INTO `melog_article` VALUES (21, 3, 1, '你可能不知道的15个 Git 命令', '雨思', 'me', '', 5, '技术', 'Git 有时可能会令人生畏。因为有太多的命令和细节需要学习。不过虽然文档的内容很多，但阅读起来还是很轻松的。一旦你克服了最初不堪重负的感觉，就会感觉到有明显进展。以下是你可能还不知道的 15 个 Git 命令的列表，希望它们能帮助你熟练掌握Git。', '> 作者：zaiste\r\n> \r\n> 翻译：疯狂的技术宅\r\n> \r\n> 原文：[https://zaiste.net/15-git-com...](https://zaiste.net/15-git-commands-you-may-not-know/)\r\n> \r\n> **未经允许严禁转载**\r\n\r\n[Git](https://git-scm.com/) 有时可能会令人生畏。因为有太多的命令和细节需要学习。不过虽然[文档](https://git-scm.com/docs)的内容很多，但阅读起来还是很轻松的。一旦你克服了最初不堪重负的感觉，就会感觉到有明显进展。以下是你可能还不知道的 15 个 Git 命令的列表，希望它们能帮助你熟练掌握Git。\r\n\r\n## 1.修改最近的提交\r\n\r\n    git commit --amend`</pre>\r\n\r\n    `—-amend` 允许你把阶段性更改（例如添加被遗忘的文件）附加到上一次提交。添加 `--no-edit` 将会修改最后的提交但不更改它的提交消息。如果没有更改，`--amend` 将允许你重新输入最后的提交消息。\r\n\r\n    更多信息：`git help commit`。\r\n\r\n    ## 2.以交互方式添加文件的选定部分\r\n\r\n    <pre>`git add -p`</pre>\r\n\r\n    `-p` (或 `—patch`) 允许以交互的形式选择每个跟踪文件中要提交的部分。这样每次提交仅包含相关的更改。\r\n\r\n    更多信息：`git help add`\r\n\r\n    ## 3.以交互方式隐藏文件的选定部分\r\n\r\n    <pre>`git stash -p`</pre>\r\n\r\n    与 `git-add` 类似，你可以使用 `--patch` 选项以交互方式选择每个要跟踪文件的部分。\r\n\r\n    更多信息：`git help stash`\r\n\r\n    ## 4.隐藏未跟踪的文件\r\n\r\n    <pre>`git stash -u`</pre>\r\n\r\n    在默认情况下，存储时不包括那些未跟踪的文件。为了改变这种行为并包括那些文件，你需要使用 `-u` 参数。还有一个 `-a`（`-all`）参数可以存储所有未跟踪和忽略的文件，这种操作通常能是你不需要的。\r\n\r\n    ## 5.以交互方式还原文件的选定部分\r\n\r\n    <pre>`git checkout -p\r\n    --patch` can be also used to selectively discard parts of each tracked file. I aliased this command as `git discard`</pre>\r\n\r\n    更多信息：`git help checkout`\r\n\r\n    ## 6.切换到上一个分支\r\n\r\n    <pre>`git checkout -`</pre>\r\n\r\n    此命令使你可以快速切换到先前签出的分支。通常 `-` 是上一个分支的别名。它也可以与其他命令一起使用。我为 `checkout` 创建了一个别名 `co`，因此可以是 `git co -`\r\n\r\n    ## 7.恢复所有本地更改\r\n\r\n    <pre>`git checkout .`</pre>\r\n\r\n    如果你确定可以放弃本地所有更改，则可以用 `.` 一次完成。但是始终使用 `checkout --patch` 是一个好习惯。\r\n\r\n    ## 8.显示更改\r\n\r\n    <pre>`git diff --staged`</pre>\r\n\r\n    该命令显示所有已阶段化的更改（已添加到索引中的更改），而与 `git diff` 相比，后者仅显示工作目录中的更改（索引中没有更改）。\r\n\r\n    更多信息：`git help diff`\r\n\r\n    ## 9.在本地重命名分支\r\n\r\n    <pre>`git branch -m old-name new-name`</pre>\r\n\r\n    如果要重命名当前签出的分支，可以将命令缩短为以下形式：\r\n\r\n    <pre>`git branch -m new-name`</pre>\r\n\r\n    更多信息：`git help branch`\r\n\r\n    ## 10.远程重命名分支\r\n\r\n    为了远程重命名分支，在本地重命名分支后，你需要先远程删除该分支，然后再次推送重命名的分支。\r\n\r\n    <pre>`git push origin :old-name\r\n    git push origin new-name`</pre>\r\n\r\n    ## 11.一次打开所有有冲突的文件\r\n\r\n    重新设置基准可能会导致冲突，以下命令将打开需要你解决这些冲突的所有文件。\r\n\r\n    <pre>`git diff --name-only --diff-filter=U | uniq  | xargs $EDITOR`</pre>\r\n\r\n    ## 12.发生了什么变化？\r\n\r\n    <pre>`git whatchanged —-since=‘2 weeks ago’`</pre>\r\n\r\n    该命令将显示一个日志，其中包含最近两周内每次提交所引入的差异。\r\n\r\n    ## 13.从上一次提交中删除文件\r\n\r\n    你可以通过结合 `rm` 和 `commit --amend` 命令来从上一次提交中快速删除误提交的文件：\r\n\r\n    <pre>`git rm —-cached &lt;file-to-remove&gt;\r\n    git commit —-amend`</pre>\r\n\r\n    ## 14.查找分支\r\n\r\n    <pre>`git branch --contains &lt;commit&gt;`</pre>\r\n\r\n    该命令将显示包含特定提交的所有分支。\r\n\r\n    ## 15.在本地优化存储库\r\n\r\n    <pre>`git gc --prune=now --aggressive`</pre>\r\n\r\n    更多信息：`git help gc`\r\n\r\n    ## 总结\r\n\r\n    尽管我非常喜欢CLI，但还是强烈建议使用 [Magit](https://magit.vc/) 来进一步提高你使用 Git 的效率。它是我用过的最好的软件之一。\r\n\r\n    也可以通过 `help` 命令查看 Git 工作流程的精彩概述。请务必仔细阅读！\r\n\r\n    <pre>`git help workflows\r\n\r\n* * *\r\n\r\n#### 本文首发微信公众号：前端先锋\r\n\r\n#### 欢迎扫描二维码关注公众号，每天都给你推送新鲜的前端技术文章\r\n\r\n<span class=\"img-wrap\">![欢迎扫描二维码关注公众号，每天都给你推送新鲜的前端技术文章](/img/bVRyYe \"欢迎扫描二维码关注公众号，每天都给你推送新鲜的前端技术文章\")</span>\r\n\r\n* * *\r\n\r\n### 欢迎继续阅读本专栏其它高赞文章：\r\n\r\n*   [深入理解Shadow DOM v1](https://segmentfault.com/a/1190000019115050)\r\n*   [一步步教你用 WebVR 实现虚拟现实游戏](https://segmentfault.com/a/1190000019135847)\r\n*   [13个帮你提高开发效率的现代CSS框架](https://segmentfault.com/a/1190000019154021)\r\n*   [快速上手BootstrapVue](https://segmentfault.com/a/1190000019085935)\r\n*   [JavaScript引擎是如何工作的？从调用栈到Promise你需要知道的一切](https://segmentfault.com/a/1190000019205065)\r\n*   [WebSocket实战：在 Node 和 React 之间进行实时通信](https://segmentfault.com/a/1190000019216390)\r\n*   [关于 Git 的 20 个面试题](https://segmentfault.com/a/1190000019315509)\r\n*   [深入解析 Node.js 的 console.log](https://segmentfault.com/a/1190000019302858)\r\n*   [Node.js 究竟是什么？](https://segmentfault.com/a/1190000019283751)\r\n*   [30分钟用Node.js构建一个API服务器](https://segmentfault.com/a/1190000019268920)\r\n*   [Javascript的对象拷贝](https://segmentfault.com/a/1190000018903274)\r\n*   [程序员30岁前月薪达不到30K，该何去何从](https://segmentfault.com/a/1190000018224157)\r\n*   [14个最好的 JavaScript 数据可视化库](https://segmentfault.com/a/1190000018646425)\r\n*   [8 个给前端的顶级 VS Code 扩展插件](https://segmentfault.com/a/1190000018439250)\r\n*   [Node.js 多线程完全指南](https://segmentfault.com/a/1190000018660861)\r\n*   [把HTML转成PDF的4个方案及实现](https://segmentfault.com/a/1190000018701596)\r\n\r\n* * *\r\n\r\n*   [更多文章...](http://blog.yidengxuetang.com/)', 4, 0, 0, 0);
INSERT INTO `melog_article` VALUES (22, 1, 0, '微信购物入口「京喜」首页跨端开发与优化实践', '雨思', 'me', '', 107, '技术', '随着今年的双十一落下帷幕，京喜（原京东拼购）也迎来了首捷。双十一前夕微信购物一级入口切换为京喜小程序，项目顺利通过近亿级的流量考验，在此与大家分享一点自己参与的工作。', '<span class=\"img-wrap\">![Artboard.png](/img/bVbA4tV \"Artboard.png\")</span>\r\n\r\n## 背景介绍\r\n\r\n随着今年的双十一落下帷幕，京喜（原京东拼购）也迎来了首捷。双十一前夕微信购物一级入口切换为京喜小程序，项目顺利通过近亿级的流量考验，在此与大家分享一点自己参与的工作。\r\n\r\n在接手项目前，京喜业务已在线上稳定运行较长时间。但经过一段时间迭代维护后，发现首页存在以下问题：\r\n\r\n1.  H5 版本首页针对不同渠道开发了多套页面，对开发者维护和内容运营来说存在较大挑战，需投入大量人力成本；\r\n2.  项目技术栈不统一，分别有传统 H5 开发、原生小程序开发、wqVue 框架开发，严重影响项目复杂度，迭代过程苦不堪言；\r\n3.  H5、小程序以及 RN 三端存在各自构建和发布流程，涉及较多工具及复杂系统流程，影响业务交付效率。\r\n\r\n综上所述，京喜迎来一次改版契机。\r\n\r\n## 改版目标\r\n\r\n从前端角度来看，本次改版要实现以下目标：\r\n\r\n*   升级并统一项目技术栈，解决项目技术栈混乱的现状；\r\n*   使用一套代码，适配微信入口、手 Q 入口、微信小程序、京东 APP、京喜 APP、M 站六大业务场景，减少多套页面的维护成本，提升交付效率；\r\n*   通过让 RN 技术在业务上的落地，完善团队在 App 端的技术储备；\r\n*   优化页面性能及体验，为下沉市场用户提供优质的产品体验；\r\n\r\n## 技术选型\r\n\r\n京喜业务拥有非常丰富的产品形态，涵盖了 H5、微信小程序以及独立 APP 三种不同的端，对支持多端的开发框架有着天然的需求。\r\n\r\n<span class=\"img-wrap\">![京喜丰富的产品形态](/img/remote/1460000021189372 \"京喜丰富的产品形态\")</span>\r\n\r\n在技术选型上，我们选择团队自研的 [Taro](https://github.com/NervJS/taro/) 多端统一开发解决方案。\r\n\r\n> Taro 是一套遵循 React 语法规范的多端开发解决方案。\r\n> \r\n> 现如今市面上端的形态多种多样，Web、React-Native、微信小程序等各种端大行其道，当业务要求同时在不同的端都要求有所表现的时候，针对不同的端去编写多套代码的成本显然非常高，这时候只编写一套代码就能够适配到多端的能力就显得极为需要。\r\n> \r\n> 使用 Taro，我们可以只书写一套代码，再通过 Taro 的编译工具，将源代码分别编译出可以在不同端（微信/百度/支付宝/字节跳动/QQ 小程序、快应用、H5、React-Native 等）运行的代码。\r\n\r\n选它有两个原因，一来是 Taro 已经成熟，内部和外部都有大量实践，内部有京东 7FRESH、京东到家等，外部有淘票票、猫眼试用等多个案例，可以放心投入到业务开发；二来团队成员都拥有使用 Taro 来开发内部组件库的经验，对业务快速完成有保障。\r\n\r\n<span class=\"img-wrap\">![组件库](/img/remote/1460000021189373 \"组件库\")</span>\r\n\r\n## 开发实录\r\n\r\n由于首页改版的开发排期并不充裕，因此充分地复用已有基础能力（比如像请求、上报、跳转等必不可少的公共类库），能大量减少我们重复的工作量。话虽如此，但在三端统一开发过程中，我们仍遇到不少问题同时也带来解决方案，以下我们一一阐述。\r\n\r\n### H5 篇\r\n\r\n我们所有的页面都依赖现有业务的全局公共头尾及搜索栏等组件，这就不可避免的需要将 Taro 开发流程融入到现有开发和发布流程中去。同时公共组件都是通过 [SSI](https://en.wikipedia.org/wiki/Server_Side_Includes) 的方式引入和维护的，为了能在运行 `npm run dev:h5` 时预览到完整的页面效果，需要对 `index.html` 模版中的 SSI 语法进行解析，`index.html` 模版文件代码结构大致如下：\r\n\r\n    &lt;!DOCTYPE html&gt;\r\n    &lt;html lang=\"zh-CN\"&gt;\r\n    &lt;head&gt;\r\n      &lt;meta charset=\"UTF-8\"&gt;\r\n      &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover\"&gt;\r\n      &lt;title&gt;京喜&lt;/title&gt;\r\n      &lt;!--#include virtual=\"/sinclude/common/head_inc.shtml\"--&gt;\r\n    &lt;/head&gt;\r\n    &lt;body&gt;\r\n      &lt;div id=\"m_common_header\" style=\"display:none;\"&gt;&lt;/div&gt;\r\n      &lt;!--S 搜索框--&gt;\r\n      &lt;div id=\"search_block\" class=\"search_block\"&gt;&lt;/div&gt;\r\n      &lt;div id=\"smartboxBlock\" style=\"display:none;\"&gt;&lt;/div&gt;\r\n      &lt;!--E 搜索框--&gt;\r\n      &lt;div id=\"app\" class=\"wx_wrap\"&gt;&lt;/div&gt;\r\n      &lt;!--#include virtual=\"/sinclude/common/foot.shtml\"--&gt;\r\n    &lt;/body&gt;\r\n    &lt;/html&gt;`</pre>\r\n\r\n    可以看到模版中存在很多类似 `&lt;!--#include virtual=\"...\" --&gt;` 格式的代码，这些就是通过 SSI 方式引入的 H5 公共组件，它的 `virtual` 属性指向的文件不存在于本地而是存在于服务器上的，所以我们遇到的第一个问题就是在本地解析这些文件，确保能预览到完整的页面效果，不然开发调试起来就非常的低效。好在 Taro 有暴露出 webpack 的配置，我们可以通过引入自定义加载器（这里就叫 `ssi-loader`）来解析这些代码的路径，然后请求服务器上的文件内容并进行替换即可，要实现这个功能只需在项目的 `config/dev.js` 中加入如下代码即可：\r\n\r\n    <pre>`module.exports = {\r\n      h5: {\r\n        webpackChain(chain, webpack) {\r\n          chain.merge({\r\n            module: {\r\n              rule: {\r\n                ssiLoader: {\r\n                  test: /\\.html/,\r\n                  use: [\r\n                    {\r\n                      loader: \'html-loader\'\r\n                    },\r\n                    {\r\n                      loader: \'ssi-loader\',\r\n                      options: {\r\n                        locations: {\r\n                          include: \'https://wqs.jd.com\'\r\n                        }\r\n                      }\r\n                    }\r\n                  ]\r\n                }\r\n              }\r\n            }\r\n          })\r\n        }\r\n      }\r\n    }`</pre>\r\n\r\n    这样就解决了本地开发调试难点，然后开开心心的进行页面开发。\r\n\r\n    当页面开发完成之后，接下来遇到的问题就是如何将前端资源部署到测试和生产环境。由于现有开发和发布流程都是基于内部已有的平台，我们临时定制一套也不太现实，所以需要将它融入到 Taro 的流程中去，这里我们引入了 `gulp` 来整合各种构建和发布等操作，只要构建出符合发布平台规范的目录即可利用它的静态资源构建、版本控制及服务器发布等能力，这样我们就打通了整个开发和发布流程。\r\n\r\n    这套拼凑起来的流程还存在不少的问题，对于新接手的同学有一点小繁琐，有着不少改善的空间，这也是接下来的重点工作方向。另外 Taro 的 H5 端之前是基于 SPA 模式，对于有着多页开发需求的项目来说不太友好，当时反馈给 Taro 团队负责 H5 的同学，很快得到了响应，目前 Taro 已支持 H5 多页开发模式，支持非常迅速。\r\n\r\n    ### 小程序篇\r\n\r\n    由于开发完 H5 版之后，对应的业务逻辑就已经处理完了，接下来只需要处理小程序下的一些特殊逻辑（比如分享、前端测速上报等）即可，差异比较大的就是开发和发布流程。\r\n\r\n    这里讲一下如何在一个原生小程序项目中使用 Taro 进行开发，因为我们的 Taro 项目跟已有的原生小程序项目是独立的两个项目，所以需要将 Taro 项目的小程序代码编译到已有的原生小程序项目目录下，第一步要做的就是调整 Taro 配置 `config/index.js`，指定编译输出目录以及禁用 app 文件输出防止覆盖已有文件。\r\n\r\n    <pre>`const config = {\r\n      // 自定义输出根目录\r\n      outputRoot: process.argv[3] === \'weapp\' ? \'../.temp\' : \'dist\',\r\n      // 不输出 app.js 和 app.json 文件\r\n      weapp: {\r\n        appOutput: false\r\n      }\r\n    }`</pre>\r\n\r\n    由于京喜以前是主购小程序的一个栏目，后面独立成了独立的小程序，但是核心购物流程还是复用的主购小程序，所以这让情况变得更加复杂。这里还是通过 `gulp` 来进行繁琐的目录文件处理，比如我们的小程序页面和组件都需要继承主购小程序的 `JDPage` 和 `JDComponent` 基类，所以在进行文件复制之前需要进行代码替换，代码如下：\r\n\r\n    <pre>`// WEAPP\r\n    const basePath = `../.temp`\r\n    const destPaths = [`${basePath}/pages/index/`, `${basePath}/pages/components/`]\r\n    const destFiles = destPaths.map(item =&gt; `${item}**/*.js`)\r\n\r\n    /*\r\n     * 基类替换\r\n     */\r\n    function replaceBaseComponent (files) {\r\n      return (\r\n        gulp\r\n          .src(files || destFiles, { base: basePath })\r\n          .pipe(\r\n            replace(\r\n              /\\b(Page|Component)(\\(require\\([\'\"](.*? \"\'\"\")\\/npm\\/)(.*)(createComponent.*)/,\r\n              function(match, p1, p2, p3, p4, p5) {\r\n                const type =\r\n                  (p5 || \'\').indexOf(\'true\') != -1 ||\r\n                  (p5 || \'\').indexOf(\'!0\') != -1\r\n                    ? \'Page\'\r\n                    : \'Component\'\r\n                if (type == \'Page\') p5 = p5.replace(\'))\', \'), true)\') // 新：page.js基类要多传一个参数\r\n                const reservedParts = p2 + p4 + p5\r\n                // const type = p1\r\n                // const reservedParts = p2\r\n                const rootPath = p3\r\n\r\n                const clsName = type == \'Page\' ? \'JDPage\' : \'JDComponent\'\r\n                const baseFile = type == \'Page\' ? \'page.taro.js\' : \'component.js\'\r\n\r\n                console.log(\r\n                  `? Replace with \\`${clsName}\\` successfully: ${this.file.path.replace(\r\n                    /.*?wxapp\\//,\r\n                    \'wxapp/\'\r\n                  )}`\r\n                )\r\n                return `new (require(\"${rootPath}/bases/${baseFile}\").${clsName})${reservedParts}`\r\n              }\r\n            )\r\n          )\r\n          .pipe(gulp.dest(basePath))\r\n      )\r\n    }\r\n\r\n    // 基类替换\r\n    gulp.task(\'replace-base-component\', () =&gt; replaceBaseComponent())`</pre>\r\n\r\n    还有很多类似这样的骚操作，虽然比较麻烦，但是只需要处理一次，后续也很少改动。\r\n\r\n    ### RN 篇\r\n\r\n    对于 RN 开发，也是第一次将它落地到实际的业务项目中，所以大部分时候都是伴随着各种未知的坑不断前行，所以这里也友情提示一下，对于从未使用过的技术，还是需要一些耐心的，遇到问题勤查勤问。\r\n\r\n    由于京喜 APP 是复用京东技术中台的基础框架和 JDReact 引擎，所以整个的开发和部署都是遵循 JDReact 已有的流程，画了一张大致的流程图如下：\r\n\r\n    <span class=\"img-wrap\">![京喜开发发布流程](/img/remote/1460000021189375 \"京喜开发发布流程\")</span>\r\n\r\n    > JDReact 平台是在 Facebook ReactNative 开源框架基础上，进行了深度二次开发和功能扩展。不仅打通了 Android/iOS/Web 三端平台，而且对京东移动端基础业务能力进行了 SDK 级别的封装，提供了统一、易于开发的 API。业务开发者可以通过 JDReact SDK 平台进行快速京东业务开发，并且不依赖发版就能无缝集成到客户端(android/iOS)或者转换成 Web 页面进行线上部署，真正实现了一次开发，快速部署三端。\r\n\r\n    由于京喜 APP 的 JDReact 模块都是独立的 git 仓库，所以需要调整我们 Taro 项目配置 `config/index.js` 的编译输出路径如下：\r\n\r\n    <pre>`rn: {\r\n      outPath: \'../jdreact-jsbundle-jdreactpingouindex\'\r\n    }`</pre>\r\n\r\n    这样，当我们运行 `yarn run dev:rn` 进行本地开发时，文件自动编译到了 JDReact 项目，接下来我们就可以用模拟器或者真机来进行预览调试了。当我们在进行本地开发调试的时候，最高效的方式还是推荐用 Taro 官方提供的 [`taro-native-shell`](https://github.com/NervJS/taro-native-shell) 原生 React Native 壳子来启动我们的项目，详细的配置参照该项目的 README 进行配置即可。\r\n\r\n    由于 React Native 官方提供的 [Remote Debugger](https://facebook.github.io/react-native/docs/debugging.html#chrome-developer-tools) 功能非常弱，推荐使用 [React Native Debugger](https://github.com/jhen0409/react-native-debugger) 来进行本地 RN 调试，提供了更为丰富的功能，基本接近 H5 和小程序的调试体验。\r\n\r\n    <span class=\"img-wrap\">![React Native Debugger 界面](/img/remote/1460000021189374 \"React Native Debugger 界面\")</span>\r\n\r\n    这样我们就拥有了一个正常的开发调试环境，接下来就可以进行高效的开发了，由于我们前面在 H5 和小程序版本阶段已经完成了绝大部分的业务逻辑开发，所以针对 RN 版本的主要工作集中在 iOS 和安卓不同机型的样式和交互适配上。\r\n\r\n    在样式适配这块，不得不提下 Taro 针对我们常见的场景提供了一些最佳实践，可以作为布局参考：\r\n\r\n*   固定尺寸（按钮、文字大小、间距）：写 PX / Px / pX\r\n*   保持宽高比（比如 banner 图片）：`Image` 组件处理\r\n*   间距固定，内容自适应（比如产品卡片宽度）：使用 `flex` 布局\r\n*   按屏幕等比缩放：使用 px 单位，编译时处理（`scalePx2dp` 动态计算）\r\n\r\n    #### Taro RN 最佳实践集锦\r\n\r\n    在实际开发过程中也遇到不少兼容性问题，这里整理出来以供大家参考：\r\n\r\n*   文本要用 `&lt;Text&gt;` 标签包起来，因为 RN 没有 `textNode` 的概念；\r\n*   使用 Swiper 时在外面包一个 View，否则设置 `margin` 后会导致安卓下高度异常；\r\n*   `Cannot read property \'x\' of undefined`，Swiper 底层使用的 react-native-swiper 导致的问题，Disable Remote JS Debug 就不会出现。\r\n*   图片默认尺寸不对，RN 不会自动帮助设置图片尺寸，而是交给开发者自己处理，故意这样设计的；\r\n*   Image 组件上不可以设置 onClick\r\n*   实现基线对齐：`vertical-align: baseline`，用 `&lt;Text&gt;` 把需要基线对齐的组件包住即可。\r\n    <pre>`&lt;Text&gt;\r\n      &lt;Text style={{ fontSize: 20 }}&gt;abc&lt;/Text&gt;\r\n      &lt;Text style={{ fontSize: 40 }}&gt;123&lt;/Text&gt;\r\n    &lt;/Text&gt;`</pre>\r\n*   尽量避免使用 `line-height` ，在安卓和 iOS 下表现不一致，而且即使设置为与 `fontSize` 相同也会导致裁剪；\r\n*   android 调试生产环境的 bundle，摇手机，选 Dev Setting，取消勾选第一项 Dev 即可；\r\n*   iOS 调试生产环境的 bundle，`AppDelegate.m` 中增加一行语句关闭 dev 即可：\r\n    <pre>`  [[RCTBundleURLProvider sharedSettings] setEnableDev:false];\r\n      // 找到这行，并在它的上面增加上面这行\r\n      jsCodeLocation = [[RCTBundleURLProvider sharedSettings] jsBundleURLForBundleRoot:@\"index\" fallbackResource:nil];`</pre>\r\n*   `&lt;Text&gt;` 与 `&lt;View&gt;` 支持的 style 属性不相同。\r\n    <pre>`&gt; [Text Style Props](https://facebook.github.io/react-native/docs/text-style-props \"Text Style Props\") &amp; [View Style Props](https://facebook.github.io/\r\n    `</pre>\r\n    react-native/docs/view-style-props)\r\n*   render 方法中不要返回空字符串\r\n    下面的代码在 android 下会报错（empty_string 内容为空字符串）\r\n    <pre>`&lt;View&gt;\r\n      {empty_string &amp;&amp; &lt;Text&gt;&lt;/Text&gt;}\r\n    &lt;/View&gt;`</pre>\r\n    因为 `empty_string &amp;&amp; &lt;Text&gt;&lt;/Text&gt;` 的返回值是空字符串，RN 尝试把字符串添加到 View 的 children 时在安卓环境下会报错：\r\n    <pre>`Error: Cannot add a child that doesn\'t have a YogaNode`</pre>\r\n*   `border-radius` 导致背景色异常，单独给某个角设置圆角时，没有设置圆角的边会出现一块与背景色颜色相同，但半透明的色块。\r\n\r\n        1.  添加外层容器设置圆角与超出隐藏\r\n    2.  全部角都设置圆角然后使用 `transform:tanslate()` 藏起不想要的圆角\r\n*   透明 View 无法点击的问题，给设置了 onClick 的元素添加透明背景色即可：`style={{ backgroundColor: \'transparent\' }}`，不可以用 scss 写，只有写在 JSX 上的才有效，Taro 编译时可能把透明背景色忽略了。\r\n*   一像素缝隙问题\r\n    可能是 RN 布局引擎的问题，或单位转换以及浏览器渲染中的精度损失问题。可以调整页面结构来绕过。\r\n    或者简单粗暴一点，设置负 margin 值盖住缝隙。\r\n\r\n    ### 跨平台开发\r\n\r\n    #### JS 文件\r\n\r\n    ##### 1、文件拆分的方式\r\n\r\n    要\"完美\"的编译出三端代码，首先要解决的是公共类库的适配问题，好在兄弟业务团队已经沉淀有完成度较高的三端公共类库，利用 Taro 提供的跨平台开发能力，抹平三端方法名和参数不统一的情况，即可很好的解决公共类库的适配问题，如下所示：\r\n\r\n    <pre>`.\r\n    ├── goto.h5.js\r\n    ├── goto.rn.js\r\n    ├── goto.weapp.js\r\n    ├── request.h5.js\r\n    ├── request.rn.js\r\n    ├── request.weapp.js\r\n    └── ...`</pre>\r\n\r\n    以 `request` 公共组件为例，三端代码如下：\r\n\r\n    request.h5.js\r\n\r\n    <pre>`import request from \'@legos/request\'\r\n    export { request }`</pre>\r\n\r\n    request.rn.js\r\n\r\n    <pre>`import request from \'@wqvue/jdreact-request\'\r\n    export { request }`</pre>\r\n\r\n    request.weapp.js（由于小程序的公共组件没有发布至 npm，这里引用的本地项目源文件）\r\n\r\n    <pre>`import { request } from \'../../../common/request/request.js\'\r\n    export { request }`</pre>\r\n\r\n    如遇到需要适配的方法参数不一致或者增加额外处理的情况，可进行再包装确保最终输出的接口一致，如下：\r\n\r\n    goto.rn.js\r\n\r\n    <pre>`import jump from \'@wqvue/jdreact-jump\'\r\n\r\n    function goto(url, params = {}, options = {}) {\r\n      jump(url, options.des || \'m\', options.source || \'JDPingou\', params)\r\n    }\r\n\r\n    export default goto`</pre>\r\n\r\n    文件引入的时候我们正常使用就好，Taro 在编译的时候为我们编译对应的平台的文件\r\n\r\n    <pre>`import goto from \'./goto.js\'`</pre>\r\n\r\n    ##### 2、条件编译的方式\r\n\r\n    解决了公共类库适配之后，接下来就可以专注于业务代码开发了，同样业务代码在三端也可能存差异的情况，可以用 Taro 提供的环境变量来达到目的，示例代码如下：\r\n\r\n    <pre>`if (process.env.TARO_ENV === \'h5\') {\r\n      this.speedReport(8) // [测速上报] 首屏渲染完成\r\n    } else if (process.env.TARO_ENV === \'weapp\') {\r\n      speed.mark(6).report() // [测速上报] 首屏渲染完成\r\n    } else if (process.env.TARO_ENV === \'rn\') {\r\n      speed.mark(7).report() // [测速上报] 首屏渲染完成\r\n    }`</pre>\r\n\r\n    #### CSS 文件\r\n\r\n    以上是 js 的代码处理方式，对于 css 文件及代码，同样也有类似的处理。\r\n\r\n    ##### 1、文件拆分的方式\r\n\r\n    比如 RN 相对于 H5 和小程序的样式就存在比较大的差异，RN 支持的样式是 CSS 的子集，所以很多看起来很常见的样式是不支持的，可以通过以下方式进行差异化处理：\r\n\r\n    <pre>`├── index.base.scss\r\n    ├── index.rn.scss\r\n    ├── index.scss`</pre>\r\n\r\n    这里以 `index.base.scss` 作为三端都能兼容的公共样式（名字可以任取，不一定为 xxx.base.scss），`index.rn.scss` 则为 RN 端独特的样式，`index.scss` 则为 H5 和小程序独特的样式，因为 H5 和小程序样式基本上没有什么差异，这里合为一个文件处理。\r\n\r\n    ##### 2、条件编译的方式\r\n\r\n    Taro 也支持样式文件内的条件编译，语法如下：\r\n\r\n    <pre>`/* #ifdef %PLATFORM% */\r\n    // 指定平台保留\r\n    /* #endif */\r\n\r\n    /* #ifndef %PLATFORM% */\r\n    // 指定平台剔除\r\n    /* #endif */`</pre>\r\n\r\n    `%PLATFORM%` 的取值请参考 [Taro 内置环境变量](https://nervjs.github.io/taro/docs/envs.html)\r\n\r\n    以下为示例代码：\r\n\r\n    <pre>`.selector {\r\n      color: #fff;\r\n      /* #ifndef RN */\r\n      box-shadow: 1px 1px 1px rgba(0, 0, 0, .1);\r\n      /* #endif */\r\n    }`</pre>\r\n\r\n    编译为 H5 和小程序的样式为：\r\n\r\n    <pre>`.selector {\r\n      color: #fff;\r\n      box-shadow: 1px 1px 1px rgba(0, 0, 0, .1);\r\n    }`</pre>\r\n\r\n    RN 的样式为：\r\n\r\n    <pre>`.selector {\r\n      color: #fff;\r\n    }\r\n\r\n两种方式选其一即可，这样就能开开心心的编写业务代码了。\r\n\r\n有些许遗憾的是产品经理对这次新版首页有着明确的上线优先级：先 H5 版，再微信小程序版，最后是 RN 版，这就为后续 RN 版本跟 H5 和 小程序版本分道扬镳埋下了伏笔，条件允许的话建议优先以 RN 版本为基准进行开发，以免开发完成 H5 和小程序之后发现对结构和样式进行大的调整，因为 RN 对样式确实会弱一些。\r\n\r\n### 性能优化\r\n\r\n#### 图片优化\r\n\r\n电商性质的网站，会存在大量的素材或商品图片， 往往这些会对页面造成较大的性能影响。得益于京东图床服务，提供强大的图片定制功能，让我们在图片优化方面省去大量工作。以引入商品图片 `\"https://img10.360buyimg.com/mobilecms/s355x355_jfs/t1/55430/24/116/143859/5cd27c99E71cc323f/0e8da8810fb49796.jpg!q70.dpg.webp\"` 为样本，我们对图片应用做了部分优化：\r\n\r\n*   根据容器大小适当裁剪图片尺寸：s355x355_jfs\r\n*   根据网络环境设置图片品质参数：0e8da8810fb49796.jpg!q70\r\n*   根据浏览器环境合理选择图片类型：0e8da8810fb49796.jpg!q70.dpg.webp\r\n\r\n为 Image 标签设置 lazyload 属性，这样可以在 H5 和小程序下获得懒加载功能。\r\n\r\n#### 接口聚合直出\r\n\r\n起初京喜首页的首屏数据涉及的后端接口多达 20 余个，导致整体数据返回时间较长；为了此项痛点，我们联合后端团队，独立开发首屏专用的**聚合直出接口**。一方面，将众多接口请求合并成一个，减少接口联动请求带来的性能损耗；另一方面，将复杂的业务逻辑挪到后端处理，前端只负责视图渲染和交互即可，减少前端代码复杂度；通过此项优化，页面性能和体验得到极大改善。\r\n\r\n#### 缓存优先策略\r\n\r\n由于京喜业务主要围绕下沉市场，其用户群体的网络环境会更加复杂，要保障页面的性能，减少网络延时是一项重要措施。\r\n\r\n为了提升用户二次访问的加载性能，我们决定采用**缓存优先策略**。即用户每次访问页面时所请求的主接口数据写入本地缓存，同时用户每次访问都优先加载缓存数据，形成一套规范的数据读取机制。通过优先读取本地缓存数据，可让页面内容在极短时间内完成渲染；另外，本地缓存数据亦可作为页面兜底数据，在用户网络超时或故障时使用，可避免页面空窗的情景出现。\r\n\r\n<span class=\"img-wrap\">![缓存优先策略](/img/remote/1460000021189376 \"缓存优先策略\")</span>\r\n\r\n#### 高性能瀑布流长列表\r\n\r\n首页紧接着首屏区域的是一个支持下滑加载的瀑布流长列表，每次滑到底部都会异步拉取 20 条数据，总计会拉取将近 500 条数据，这在 iOS 下交互体验还比较正常。但是在配置较低的安卓机型下，当滑动到 2 到 3 屏之后就开始出现严重卡顿，甚至会闪退。\r\n\r\n针对这种场景也尝试过用 FlatList 和 SectionList 组件来优化，但是它们都要求规则等高的列表条目，于是不得不自己来实现不规则的瀑布流无限滚动加载。其核心思路是通过判断列表的条目是否在视窗内来决定图片是否渲染，要优化得更彻底些得话，甚至可以移除条目内所有内容只保留容器，以达到减少内容节点以及内存占用，不过在快速进行滑动时比较容易出现一片白框，算是为了性能损失一些体验，整体上来说是可以接受得。\r\n\r\n由于 RN 下在获取元素坐标偏移等数据相对 H5 和小程序要麻烦得到，具体的实现细节可以查看抽离出来的简单实现[Taro 高性能瀑布流组件（for RN）](https://github.com/aNd1coder/taro-waterfall)。\r\n\r\n## 写在最后\r\n\r\n<span class=\"img-wrap\">![三端达到像素级别的还原](/img/remote/1460000021189377 \"三端达到像素级别的还原\")</span>\r\n\r\n这篇文章从技术选型、开发实录再到性能优化三个维度对京喜首页改版做了简单总结。整个项目实践下来，证实 Taro 开发框架 已完全具备投入大型商业项目的条件。虽在多端开发适配上耗费了一些时间，但仍比各端独立开发维护工作量要少。\r\n\r\n在前端资源匮乏的今天，选择成熟的开发工具来控制成本、提升效率，已是各团队的首要工作目标。 同时，京喜作为京东战略级业务，拥有千万级别的流量入口，我们对页面的体验优化和性能改进远不止于此，希望每一次微小的改动能为用户带来愉悦的感受，始终为用户提供优质的产品体验。\r\n\r\n欢迎关注凹凸实验室博客：[aotu.io](https://aotu.io/)\r\n\r\n或者关注凹凸实验室公众号（AOTULabs），不定时推送文章：\r\n\r\n<span class=\"img-wrap\">![13-横_1575377567139.jpg](/img/bVbA4t5 \"13-横_1575377567139.jpg\")</span>', 1576553843, 0, 0, 0);
INSERT INTO `melog_article` VALUES (23, 1, 1, '使用 JS 来动态操作 css ，你知道几种方法？', '雨思', 'me', '', 245, '技术', 'JavaScript 可以说是交互之王，它作为脚本语言加上许多 Web Api 进一步扩展了它的特性集，更加丰富界面交互的可操作性。这类 API 的例子包括WebGL API、Canvas API、DOM API，还有一组不太为人所知的 CSS API。', '> 作者：areknawo\r\n> 译者：前端小智\r\n> 来源：css-tricks.com\r\n\r\n* * *\r\n\r\nJavaScript 可以说是交互之王，它作为脚本语言加上许多 **Web Api** 进一步扩展了它的特性集，更加丰富界面交互的可操作性。这类 **API** 的例子包括**WebGL API**、**Canvas API**、**DOM API**，还有一组不太为人所知的 **CSS API**。\r\n\r\n由于`JSX`和无数`JS框架`的出现，使通过**JS API**与**DOM**交互的想法真正流行起来，但是在 CSS 中使用类似技术似乎并没有很多。 当然，存在像**CSS-in-JS**这类解决方案，但是最流行的解决方案还是基于**转译**(transpilation)，无需额外运行即可生成 CSS。 这肯定对性能有好处，因为**CSS API**的使用可能导致额外的重绘，这与`DOM API`的使用一样。 但这不是咱们想要的。 如果哪天公司要求咱们，既要操纵 DOM 元素的样式和 CSS 类，还要像使用 HTML 一样使用 JS 创建完整的样式表，该怎么办？\r\n\r\n* * *\r\n\r\n**阿里云`双12`已开启，新老用户均可参与，2核1G云服务器仅需`79元`，，更多服务器配置及价格请关注：[Hi拼团](https://www.aliyun.com/minisite/goods?userCode=pxuujn3r&share_source=copy_link)，或点此了解[“云上爆款1折特惠活动”](https://www.aliyun.com/minisite/goods?userCode=pxuujn3r&share_source=copy_link)。同时，建议在购买阿里云相关产品前[先领取阿里云2000元代金券](https://www.aliyun.com/minisite/goods?userCode=pxuujn3r&share_source=copy_link)会更优惠哦。**\r\n\r\n* * *\r\n\r\n## 内联样式\r\n\r\n在咱们深入一些复杂的知识之前，先回来顾一下一些基础知识。例如，咱们可以通过修改它的`.style`属性来编辑给定的`HTMLElement`的内联样式。\r\n\r\n    const el = document.createElement(\'div\')\r\n\r\n    el.style.backgroundColor = \'red\'\r\n    // 或者 \r\n    el.style.cssText = \'background-color: red\'\r\n    // 或者\r\n    el.setAttribute(\'style\', \'background-color: red\')\r\n\r\n    `</pre>\r\n\r\n    直接在`.style`对象上设置样式属性将需要使用**驼峰式**命名作为属性键，而不是使用`短横线命名`。 如果咱们需要设置更多的内联样式属性，则可以通过设置`.style.cssText`属性，以更加高效的方式进行设置 。 \r\n\r\n    **请记住**，**给cssText设置后原先的css样式被清掉了，**因此，要求咱们一次死一堆样式 。\r\n\r\n    如果这种设置内联样式过于繁琐，咱们还可以考虑将`.style`与`Object.assign()`一起使用，以一次设置多个样式属性。\r\n\r\n    <pre>`// ...\r\n    Object.assign(el.style, {\r\n        backgroundColor: \"red\",\r\n        margin: \"25px\"\r\n    })\r\n    `</pre>\r\n\r\n    这些“基本知识”比咱们想象的要多得多。`.style`对象实现`CSSStyleDeclaration`接口。 这说明它带还有一些有趣的属性和方法，这包括刚刚使用的`.cssText`，还包括`.length`（设置属性的数量），以及`.item()`、`.getPropertyValue()`和`.setPropertyValue()`之类的方法：\r\n\r\n    <pre>`// ...\r\n    const propertiesCount = el.style.length\r\n    for(let i = 0; i < propertiesCount; i++) {\r\n        const name = el.style.item(i) // \'background-color\'\r\n        const value = el.style.getPropertyValue(name) // \'re\'\r\n        const priority = el.style.getPropertyPriority(name) // \'important\'\r\n\r\n        if(priority === \'important\') {\r\n            el.style.removeProperty()\r\n        }\r\n    }\r\n    `</pre>\r\n\r\n    这里有个小窍门-在遍历过程中`.item()`方法具有按索引访问形式的备用语法。\r\n\r\n    <pre>`// ...\r\n    el.style.item(0) === el.style[0]; // true\r\n    `</pre>\r\n\r\n    ## CSS 类\r\n\r\n    接着，来看看更高级的结构——**CSS类**，它在检索和设置时具有字符串形式是`.classname`。\r\n\r\n    <pre>`// ...\r\n    el.className = \"class-one class-two\";\r\n    el.setAttribute(\"class\", \"class-one class-two\");\r\n    `</pre>\r\n\r\n    设置类字符串的另一种方法是设置`class`属性（与检索相同）。 但是，就像使用`.style.cssText`属性一样，设置`.className`将要求咱们在字符串中包括给定元素的所有类，包括已更改和未更改的类。 \r\n\r\n    当然，可以使用一些简单的字符串操作来完成这项工作，还有一种就是使用较新的`.classList`属性，这个属性，**IE9 不支持它，而 IE10 和 IE11 仅部分支持它**。\r\n\r\n    `classlist`属性实现了`DOMTokenList`，有一大堆有用的方法。例如`.add()`、`.remove()`、.toggle()和`.replace()`允许咱们更改当前的 CSS 类集合，而其他的，例如`.item()`、`.entries()`或`.foreach()`则可以简化这个索引集合的遍历过程。\r\n\r\n    <pre>`// ...\r\n    const classNames = [\"class-one\", \"class-two\", \"class-three\"];\r\n    classNames.forEach(className => {\r\n        if(!el.classList.contains(className)) {\r\n            el.classList.add(className);\r\n        }\r\n    });\r\n\r\n    `</pre>\r\n\r\n    ## Stylesheets\r\n\r\n    一直以来，Web Api 还有一个`StyleSheetList`接口，该接口由`document.styleSheets`属性实现。 `document.styleSheets` 只读属性，返回一个由 `StyleSheet` 对象组成的 `StyleSheetList`，每个 `StyleSheet` 对象都是一个文档中链接或嵌入的样式表。\r\n\r\n    <pre>`for(styleSheet of document.styleSheets){\r\n        console.log(styleSheet);\r\n    }`</pre>\r\n\r\n    通过打印结果咱们可以知道，每次循环打印的是 **CSSStyleSheet** 对象，每个 CSSStyleSheet 对象由下列属性组成：\r\n\r\n    <table>\r\n    <thead><tr>\r\n    <th>属性</th>\r\n    <th>描述</th>\r\n    </tr></thead>\r\n    <tbody>\r\n    <tr>\r\n    <td>media</td>\r\n    <td>获取当前样式作用的媒体。</td>\r\n    </tr>\r\n    <tr>\r\n    <td>disabled</td>\r\n    <td>打开或禁用一张样式表。</td>\r\n    </tr>\r\n    <tr>\r\n    <td>href</td>\r\n    <td>返回 CSSStyleSheet 对象连接的样式表地址。</td>\r\n    </tr>\r\n    <tr>\r\n    <td>title</td>\r\n    <td>返回 CSSStyleSheet 对象的title值。</td>\r\n    </tr>\r\n    <tr>\r\n    <td>type</td>\r\n    <td>返回 CSSStyleSheet 对象的type值，通常是text/css。</td>\r\n    </tr>\r\n    <tr>\r\n    <td>parentStyleSheet</td>\r\n    <td>返回包含了当前样式表的那张样式表。</td>\r\n    </tr>\r\n    <tr>\r\n    <td>ownerNode</td>\r\n    <td>返回CSSStyleSheet对象所在的DOM节点，通常是<link>或<style>。</td>\r\n    </tr>\r\n    <tr>\r\n    <td>cssRules</td>\r\n    <td>返回样式表中所有的规则。</td>\r\n    </tr>\r\n    <tr>\r\n    <td>ownerRule</td>\r\n    <td>如果是通过@import导入的，属性就是指向表示导入的规则的指针，否则值为null。IE不支持这个属性。</td>\r\n    </tr>\r\n    </tbody>\r\n    </table>\r\n\r\n    **CSSStyleSheet对象方法:**\r\n\r\n    <table>\r\n    <thead><tr>\r\n    <th>方法</th>\r\n    <th>描述</th>\r\n    </tr></thead>\r\n    <tbody>\r\n    <tr>\r\n    <td>insertRule()</td>\r\n    <td>在当前样式表的 cssRules 对象插入CSS规则。</td>\r\n    </tr>\r\n    <tr>\r\n    <td>deleteRule()</td>\r\n    <td>在当前样式表删除 cssRules 对象的CSS规则。</td>\r\n    </tr>\r\n    </tbody>\r\n    </table>\r\n\r\n    有了`StyleSheetList`的全部内容，咱们来`CSSStyleSheet`本身。 在这里就有点意思了， `CSSStyleSheet`扩展了`StyleSheet`接口，并且只有这种只读属性，如`.ownerNode`，`.href`，`.title`或`.type`，它们大多直接从声明给定样式表的地方获取。回想一下加载外部CSS文件的标准HTML代码，咱们就会明白这句话是啥意思：\r\n\r\n    <pre>`<head>\r\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"style.css\" title=\"Styles\">\r\n    </head>\r\n    `</pre>\r\n\r\n    现在，咱们知道HTML文档可以包含多个样式表，所有这些样式表都可以包含不同的规则，甚至可以包含更多的样式表(当使用`@import`时)。`CSSStyleSheet`有两个方法:`、.insertrule()`和`.deleterule()` 来增加和删除 Css 规则。\r\n\r\n    <pre>`// ...\r\n    const ruleIndex = styleSheet.insertRule(\"div {background-color: red}\");\r\n    styleSheet.deleteRule(ruleIndex);\r\n    `</pre>\r\n\r\n    `.insertRule(rule,index)`:此函数可以在`cssRules`规则集合中插入一个指定的规则，参数`rule`是标示规则的字符串，参数`index`是值规则字符串插入的位置。\r\n\r\n    `deleteRule(index)`:此函数可以删除指定索引的规规则，参数`index`规定规则的索引。\r\n\r\n    `CSSStyleSheet`也有自己的两个属性：`.ownerRule`和`.cssRule`。虽然`.ownerRule`与`@import`相关，但比较有趣的是`.cssRules `。简单地说，它是`CSSRuleList`的`CSSRule`，可以使用前面提到的`.insertrule()`和`.deleterule()`方法修改它。请记住，有些浏览器可能会阻止咱们从不同的来源(域)访问外部CSSSt`y`leSheet的`.cssRules`属性。\r\n\r\n    那么什么是 `CSSRuleList`？\r\n\r\n    `CSSRuleList`是一个数组对象包含着一个有序的`CSSRule`对象的集合。每一个`CSSRule`可以通过`rules.item(index)`的形式访问, 或者`rules[index]`。 这里的`rules`是一个实现了`CSSRuleList`接口的对象， `index`是一个基于`0`开始的，顺序与`CSS`样式表中的顺序是一致的。样式对象的个数是通过`rules.length`表达。\r\n\r\n    对于**CSSStyleRule**对象:\r\n\r\n    每一个样式表`CSSStyleSheet`对象可以包含若干`CSSStyleRule`对象，也就是css样式规则，如下:\r\n\r\n    <pre>`<style type=\"text/css\">\r\n      h1{color:red}\r\n      div{color:green}\r\n    </style>\r\n    `</pre>\r\n\r\n    在上面的代码中`style`标签是一个`CSSStyleSheet`样式表对象，这个样式表对象包含两个`CSSStyleRule`对象，也就是两个css样式规则。\r\n\r\n    `CSSStyleRule`对象具有下列属性:\r\n\r\n    **1.`type`:返回`0-6`的数字，表示规则的类型，类型列表如下:**\r\n\r\n    0：CSSRule.UNKNOWN_RULE。\r\n\r\n    1：CSSRule.STYLE_RULE （定义一个CSSStyleRule对象）。\r\n\r\n    2：CSSRule.CHARSET_RULE （定义一个CSSCharsetRule对象，用于设定当前样式表的字符集，默认与当前网页相同）。\r\n\r\n    3：CSSRule.IMPORT_RULE （定义一个CSSImportRule对象，就是用@import引入其他的样式表）\r\n\r\n    4：CSSRule.MEDIA_RULE （定义一个CSSMediaRule对象，用于设定此样式是用于显示器，打印机还是投影机等等）。\r\n\r\n    5：CSSRule.FONT_FACE_RULE （定义一个CSSFontFaceRule对象，CSS3的@font-face）。\r\n\r\n    6：CSSRule.PAGE_RULE （定义一个CSSPageRule对象）。\r\n\r\n    **2.`cssText`:返回一个字符串，表示的是当前规则的内容，例如:**\r\n\r\n    <pre>`div{color:green}\r\n    `</pre>\r\n\r\n    **3.`parentStyleSheet`:返回所在的`CSSStyleRule`对象。**\r\n\r\n    **4.`parentRule`:如果规则位于另一规则中，该属性引用另一个CSSRule对象。**\r\n\r\n    **5.`selectorText`:返回此规则的选择器，如上面的div就是选择器。**\r\n\r\n    **6.`style`:返回一个`CSSStyleDeclaration`对象。**\r\n\r\n    <pre>`// ...\r\n    const ruleIndex = styleSheet.insertRule(\"div {background-color: red}\");\r\n    const rule = styleSheet.cssRules.item(ruleIndex);\r\n\r\n    rule.selectorText; // \"div\"\r\n    rule.style.backgroundColor; // \"red\"\r\n    `</pre>\r\n\r\n    ## 实现\r\n\r\n    现在，咱们对 CSS 相关的 **JS Api**有了足够的了解，可以创建咱们自己的、小型的、基于运行时的`CSS-in-JS`实现。咱们的想法是创建一个函数，它传递一个简单的样式配置对象，生成一个新创建的CSS类的哈希名称供以后使用。\r\n\r\n    实现流程很简单，咱们需要一个能够访问某种样式表的函数，并且只需使用`.insertrule()`方法和样式配置就可以运行了。先从样式表部分开始：\r\n\r\n    <pre>`function createClassName(style) {\r\n      // ...\r\n      let styleSheet;\r\n      for (let i = 0; i < document.styleSheets.length; i++) {\r\n        if (document.styleSheets[i].CSSInJS) {\r\n          styleSheet = document.styleSheets[i];\r\n          break;\r\n        }\r\n      }\r\n      if (!styleSheet) {\r\n        const style = document.createElement(\"style\");\r\n        document.head.appendChild(style);\r\n        styleSheet = style.sheet;\r\n        styleSheet.CSSInJS = true;\r\n      }\r\n      // ...\r\n    }\r\n    `</pre>\r\n\r\n    如果你使用的是**ESM**或任何其他类型的JS模块系统，则可以在函数外部安全地创建样式表实例，而不必担心其他人对其进行访问。 但是，为了演示例，咱们将`stylesheet`上的`.CSSInJS`属性设置为标志的形式，通过标志来判断是否要使用它。\r\n\r\n    现在，如果如果还需要创建一个新的样式表怎么办？  最好的选择是创建一个新的`<style/>`标记，并将其附加到HTML文档的`<head/>`上。 这会自动将新样式表添加到`document.styleSheets`列表，并允许咱们通过`<style/>`标记的`.sheet`属性对其进行访问，是不是很机智？\r\n\r\n    <pre>`function createRandomName() {\r\n      const code = Math.random().toString(36).substring(7);\r\n      return `css-${code}`;\r\n    }\r\n\r\n    function phraseStyle(style) {\r\n      const keys = Object.keys(style);\r\n      const keyValue = keys.map(key => {\r\n        const kebabCaseKey = \r\n            key.replace(/([a-z])([A-Z])/g, \"$1-$2\").toLowerCase();\r\n        const value = \r\n            `${style[key]}${typeof style[key] === \"number\" ? \"px\" : \"\"}`;\r\n\r\n        return `${kebabCaseKey}:${value};`;\r\n      });\r\n\r\n      return `{${keyValue.join(\"\")}}`;\r\n    }\r\n    `</pre>\r\n\r\n    除了上面的小窍门之外。 自然，咱们首先需要一种为CS​​S类生成新的随机名称的方法。 然后，将样式对象正确地表达为可行的CSS字符串的形式。 这包括驼峰命名和短横线全名之间的转换，以及可选的像素单位（px）转换的处理。\r\n\r\n    <pre>`function createClassName(style) {\r\n      const className = createRandomName();\r\n      let styleSheet;\r\n      // ...\r\n      styleSheet.insertRule(`.${className}${phraseStyle(style)}`);\r\n      return className;\r\n    }\r\n    `</pre>\r\n\r\n    完整代码如下：\r\n\r\n    **HTML**\r\n\r\n    <pre>`<div id=\"el\"></div>\r\n    `</pre>\r\n\r\n    **JS**\r\n\r\n    <pre>`function createRandomName() {\r\n      const code = Math.random().toString(36).substring(7);\r\n      return `css-${code}`;\r\n    }\r\n\r\n    function phraseStyle(style) {\r\n      const keys = Object.keys(style);\r\n      const keyValue = keys.map(key => {\r\n        const kebabCaseKey = key.replace(/([a-z])([A-Z])/g, \"$1-$2\").toLowerCase();\r\n        const value = `${style[key]}${typeof style[key] === \"number\" ? \"px\" : \"\"}`;\r\n        return `${kebabCaseKey}:${value};`;\r\n      });\r\n      return `{${keyValue.join(\"\")}}`;\r\n    }\r\n\r\n    function createClassName(style) {\r\n      const className = createRandomName();\r\n      let styleSheet;\r\n      for (let i = 0; i < document.styleSheets.length; i++) {\r\n        if (document.styleSheets[i].CSSInJS) {\r\n          styleSheet = document.styleSheets[i];\r\n          break;\r\n        }\r\n      }\r\n      if (!styleSheet) {\r\n        const style = document.createElement(\"style\");\r\n        document.head.appendChild(style);\r\n        styleSheet = style.sheet;\r\n        styleSheet.CSSInJS = true;\r\n      }\r\n      styleSheet.insertRule(`.${className}${phraseStyle(style)}`);\r\n      return className;\r\n    }\r\n\r\n    const el = document.getElementById(\"el\");\r\n\r\n    const redRect = createClassName({\r\n      width: 100,\r\n      height: 100,\r\n      backgroundColor: \"red\"\r\n    });\r\n\r\n    el.classList.add(redRect);\r\n\r\n运行效果：\r\n\r\n<span class=\"img-wrap\">![clipboard.png](/img/bVbA38I \"clipboard.png\")</span>\r\n\r\n## 总结\r\n\r\n正如本文咱们所看到的，使用 JS 操作CSS 是一件非常有趣的事，咱们可以挖掘很多好用的 API,上面的例子只是冰山一角，在**CSS API**(或者更确切地说是API)中还有更多方法，它们正等着被揭开神秘面纱。\r\n\r\n* * *\r\n\r\n原文：[https://css-tricks.com/an-int...](https://css-tricks.com/an-introduction-and-guide-to-the-css-object-model-cssom/)\r\n\r\n**编辑中可能存在的bug没法实时知道，事后为了解决这些bug,花了大量的时间进行log 调试，这边顺便给大家推荐一个好用的BUG监控工具 [Fundebug](https://www.fundebug.com/?utm_source=xiaozhi)。**\r\n\r\n* * *\r\n\r\n## 交流\r\n\r\n干货系列文章汇总如下，觉得不错点个Star，欢迎 加群 互相学习。\r\n\r\n> [https://github.com/qq449245884/xiaozhi](https://github.com/qq449245884/xiaozhi)\r\n\r\n因为篇幅的限制，今天的分享只到这里。如果大家想了解更多的内容的话，可以去扫一扫每篇文章最下面的二维码，然后关注咱们的微信公众号，了解更多的资讯和有价值的内容。\r\n\r\n<span class=\"img-wrap\">![clipboard.png](/img/bVbthgQ \"clipboard.png\")</span>', 1576589843, 1582031084, 16, 0);
INSERT INTO `melog_article` VALUES (25, 1, 1, '看完Webpack源码，我学到了这些dd', '雨思', 'me', '', 80, 'Webpack', '诚然Webpack这是一个前端工程化工具，理解容易， 使用简单，似乎没有深入研究的必要。那为什么还要费心费力阅读其源码？', '继React,Vue，这是第三个着重阅读源码的前端项目-Webpack。本文主要以：\r\n\r\n- WHY: 为何要看Webpack源码\r\n- HOW: 如何阅读Webpack源码\r\n- WHAT: 看完源码后学到了什么\r\n- 三个方向展开。\r\n\r\n```javascript\r\n// node.js, 用“类”的方式：\r\nvar MarkdownIt = require(\'markdown-it\'),\r\n    md = new MarkdownIt();\r\nvar result = md.render(\'# markdown-it rulezz!\');\r\n\r\n// 还是 node.js, 但使用更爽的方式：\r\nvar md = require(\'markdown-it\')();\r\nvar result = md.render(\'# markdown-it rulezz!\');\r\n\r\n// 没有 AMD 的浏览器环境，在 js 脚本加载时才添加到“window”\r\n// 注意，“markdownit” 中没有破折号。\r\nvar md = window.markdownit();\r\nvar result = md.render(\'# markdown-it rulezz!\');\r\n```\r\n\r\n> 欢迎Star和订阅我的博客。\r\n\r\n## WHY\r\n\r\n诚然Webpack这是一个前端工程化工具，理解容易， 使用简单，似乎没有深入研究的必要。那为什么还要费心费力阅读其源码？这，把正在写此篇文章的我也问住了。理提纲时，认为WHY最好写，几句话就可带过，但事实证明真要较真这一块还值得一说。\r\n擅自揣测下会阅读Webpack源码伙伴可能的动机：\r\n\r\n- 丰富工作经验\r\n- 技术真爱粉，知其然亦须知其所以然，同时学习方法\r\n- 与工作或个人项目相关，参考学习\r\n- 看有人写相关文章，也看看了解下\r\n\r\n作者最先是原因是4，然后是1，2。当然，1，2应该是大多数人看项目源码的动机。\r\n\r\n## 搭建源码调试环境\r\n\r\n要阅读源码，首先拿到源码，然后最后能边调试边阅读。当然，如果智力和推理能力惊人，大可以直接在Github上在线阅读。\r\n\r\n有2中方法下载源码。一种是最常见的git clone,将Github上webpack项目clone到本地，pull后与webpack官方最新代码保持一致，一劳永逸。不过作者尝试第一种方法时，总是clone不下来，很大可能是由于webpack源文件过大且github服务器clone一直很慢。\r\n\r\n于是退而求其次，使用第二种方法：下载Webpack源码release版本。选择一个打算阅读的webpack源码版本，直接下载\"Source code(zip)\"即可。速度非常快，因为不包含.git。\r\n\r\nIDE作者使用VSCode,调试node很方便。拿到源码后，在目录新建一个文件夹，写一个简单的webpack案例，然后使用VSCode进行调试。\r\n\r\n不过，在实际操作中，直接使用下载源码中的webpack.js调试可能会出现报错Cannot find module \'json-parse-better-errors\'或Cannot find module \'webpack/lib/RequestShortener\'，只需运行npm install webpack webpack-cli --save-dev，即可解决报错，且不影响调试源码。\r\n\r\n此附作者在调试时使用版本参考，下载后使用VSCode打开webpack-4.41.4(modified)，安装依赖，安装webpack和webpack-cli，按F5即可启动调试。\r\n\r\n## 调试，理清大致脉路走向\r\n\r\nWebpack源码量庞大，把每一行代码都读懂确实没有必要，但是我们至少要知道它的整体运行流程，知道它反复用到的核心代码，以及各个模块的生命周期如何运转。\r\n\r\n## 找核心功能源码\r\n\r\n代码量大，想要在走整体流程时恰好找核心功能的源码，困难重重，至少对于webpack源码是这样，因为其独特的插件和回调结构。\r\n\r\n不过，我们可以根据每一个想要了解的核心功能，单独去寻找和阅读相关源码。比如，如果我们想看webpack如何打包生成bundle.js，可通过webpack一定会调用NodeJS文件系统输出文件方法，全局搜索\"writeFile\"找到相关代码，或通过bundle.js中的关键字\"// Check if module is in cache\"进行搜索。\r\n\r\n## What\r\n\r\n通过边调试边阅读代码，了解代码整体走向以及webpack如何打包生成bundle.js，作者学到了以下内容：\r\n\r\n- tapable插件机制\r\n- 简化版Webpack运行流程\r\n- bundle.js内容如何生成', 0, 1581751960, 0, 0);
INSERT INTO `melog_article` VALUES (26, 1, 1, '文章美文', '雨思', 'me', '', 0, '文章美文', '文章美文', '文章美文文章美文文章美文文章美文文章美文文章美文文章美文文章美文', 1581751991, 1582031009, 0, 1);

-- ----------------------------
-- Table structure for melog_cate
-- ----------------------------
DROP TABLE IF EXISTS `melog_cate`;
CREATE TABLE `melog_cate`  (
  `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '栏目ID',
  `cate_name` varchar(150) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '栏目名字',
  `cate_dir` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '栏目文件夹',
  `description` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '栏目简介',
  `keywords` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '栏目关键词',
  `sort` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '栏目排序',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `sort`(`sort`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 7 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of melog_cate
-- ----------------------------
INSERT INTO `melog_cate` VALUES (1, '文章大全', 'archives', '文章大全文章大全文章大全文章大全2', '文章', 0);
INSERT INTO `melog_cate` VALUES (2, '图片欣赏', 'image', '图片欣赏图片欣赏图片欣赏图片欣赏图片欣赏图片欣赏', '图片', 0);
INSERT INTO `melog_cate` VALUES (3, '随笔日记', 'diary', '随笔日记随笔日记随笔日记随笔日记随笔日记', '随笔,日记', 0);
INSERT INTO `melog_cate` VALUES (4, '关于', 'about', '关于我关于我关于我关于我关于我关于我', '关于', 0);
INSERT INTO `melog_cate` VALUES (5, '网站技术', 'web', '网站技术网站技术网站技术', '', 0);

-- ----------------------------
-- Table structure for melog_comment
-- ----------------------------
DROP TABLE IF EXISTS `melog_comment`;
CREATE TABLE `melog_comment`  (
  `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '评论ID',
  `pid` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '父ID',
  `comment_id` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '评论ID',
  `article_id` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '文章ID',
  `user_id` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '用户ID',
  `uname` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '昵称',
  `email` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '邮箱',
  `url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '链接',
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '评论内容',
  `ip` char(16) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '来源IP',
  `add_time` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '添加时间',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `comment`(`id`, `pid`, `article_id`) USING BTREE,
  INDEX `comment_id`(`comment_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Table structure for melog_link
-- ----------------------------
DROP TABLE IF EXISTS `melog_link`;
CREATE TABLE `melog_link`  (
  `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT 'ID',
  `pid` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '父ID',
  `lname` varchar(150) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '标题',
  `icon` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '图标',
  `url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '链接',
  `sort` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '排序',
  `add_time` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '添加时间',
  `update_time` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '更新时间',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `pid`(`pid`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 6 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of melog_link
-- ----------------------------
INSERT INTO `melog_link` VALUES (1, 0, '友情链接', 'layui-icon-link', '', 0, 0, 0);
INSERT INTO `melog_link` VALUES (2, 0, '底部链接', '/favicon.ico', '', 0, 0, 0);
INSERT INTO `melog_link` VALUES (3, 1, 'me', '', 'https://me.i-i.me/', 0, 0, 0);
INSERT INTO `melog_link` VALUES (4, 3, '测试子链', '', '', 0, 0, 0);
INSERT INTO `melog_link` VALUES (5, 2, 'melog使用手册', '', 'https://me.i-i.me/melog/', 0, 0, 0);

-- ----------------------------
-- Table structure for melog_site
-- ----------------------------
DROP TABLE IF EXISTS `melog_site`;
CREATE TABLE `melog_site`  (
  `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT 'ID',
  `group` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '分类',
  `type` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '类型',
  `sname` varchar(30) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '名字',
  `intro` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '标题',
  `value` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '内容',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = MyISAM AUTO_INCREMENT = 32 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of melog_site
-- ----------------------------
INSERT INTO `melog_site` VALUES (1, 'web', 'input', 'basehost', '网站根网址', 'http://127.0.0.1:3001');
INSERT INTO `melog_site` VALUES (2, 'web', 'input', 'admin_alias', '后台目录别名', 'admin');
INSERT INTO `melog_site` VALUES (3, 'web', 'input', 'webname', '网站名字', 'melog');
INSERT INTO `melog_site` VALUES (4, 'other', 'input', 'upload', '文件上传目录', '/upload');
INSERT INTO `melog_site` VALUES (5, 'web', 'input', 'keywords', '关键词', 'melog,简单,轻量,iijs');
INSERT INTO `melog_site` VALUES (6, 'web', 'textarea', 'description', '网站简介', '一个基于iijs构建的简单轻量级blog系统');
INSERT INTO `melog_site` VALUES (7, 'web', 'textarea', 'beian', '网站备案信息', '<a href=\"https://icp.gov.moe/?keyword=20200002\" rel=\"nofollow\" target=\"_blank\">萌ICP备 20200002号</a> <script type=\"text/javascript\" src=\"https://js.users.51.la/17667763.js\"></script>');
INSERT INTO `melog_site` VALUES (15, 'other', 'input', 'img_width', '图片限制宽度', '800');
INSERT INTO `melog_site` VALUES (16, 'other', 'input', 'img_height', '图片限制高度', '2000');
INSERT INTO `melog_site` VALUES (19, 'other', 'input', 'list_rows', '列表显示行数', '10');
INSERT INTO `melog_site` VALUES (22, 'self', 'input', 'keyname', '自定义参数', 'keyvalue');
INSERT INTO `melog_site` VALUES (31, 'other', 'input', 'is_comment', '开启评论(1/0)', '1');

-- ----------------------------
-- Table structure for melog_user
-- ----------------------------
DROP TABLE IF EXISTS `melog_user`;
CREATE TABLE `melog_user`  (
  `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '用户ID',
  `uname` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '昵称',
  `tname` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '名字',
  `email` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '邮箱',
  `password` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '密码',
  `salt` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '加盐',
  `add_time` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '添加时间',
  `update_time` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '更新时间',
  `login_time` int(10) UNSIGNED NOT NULL DEFAULT 0 COMMENT '登录时间',
  `is_lock` tinyint(1) NOT NULL DEFAULT -5 COMMENT '账号锁定',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 2 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of melog_user
-- ----------------------------
INSERT INTO `melog_user` VALUES (1, 'melog', '', 'melog@i-i.me', '5b9e018e16920c57b631725adde60524', 'lEVzte3E', 0, 0, 1582004259, -5);

SET FOREIGN_KEY_CHECKS = 1;
